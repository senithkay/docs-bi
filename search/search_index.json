{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"WSO2 Integrator: BI is a low-code integration solution built on Ballerina, enabling fast and efficient integration development with minimal coding. The WSO2 Integrator: BI extension for Visual Studio Code (VS Code) provides a familiar, AI-assisted environment that streamlines tasks and enhances accuracy, accelerating digital transformation efforts.          Get Started \ud83d\ude80 <ul> <li> Quick Start Guide </li> <li> Install WSO2 Integrator: BI </li> <li> Develop Integration as API </li> <li> Develop Automation </li> <li> Develop File Integration </li> <li> Develop Event Integration </li> <li> Develop AI Agent </li> </ul> Developer Guides \ud83d\udee0\ufe0f  <ul> <li> Design the Integrations </li> <li> Data Mapping </li> <li> Migration Tools </li> </ul> AI \ud83e\udd16 <ul> <li> AI Agents and other Gen AI Integrations </li> <li> AI for Integration </li> </ul> Integration Guides \ud83d\udcda <ul> <li> AI Agents and other Gen AI Integrations </li> <li> Integration as API </li> <li> File Integration </li> </ul> Deploy \u2699\ufe0f <ul> <li> Overview </li> <li> Deploy to Devant </li> <li> Containerized Deployment </li> <li> VM-based Deployment </li> <li> Managing Configurations </li> </ul> Observability and Monitoring \ud83d\udcc8  <ul> <li> Overview </li> <li> Monitoring with WSO2 Integrator: ICP </li> <li> Observability with Devant </li> <li> Supporting Observability Tools and Platforms </li> </ul> References \ud83d\udcd6 <ul> <li> Enterprise Integration Patterns </li> </ul> Community &amp; Support \u2753 <ul> <li> GitHub </li> <li> Discord </li> <li> Enterprise Support </li> </ul>"},{"location":"page-not-found/","title":"Page not found","text":"<p>Try one of the navigation links above or use the search engine in the top right corner.</p>"},{"location":"deploy/deploy-to-devant/","title":"Deploy to Devant","text":"<p>Devant is a powerful IPaaS with first-class AI support. Incorporate AI agents into the integrations you build in low-code and pro-code, and move away from siloed systems to intelligent digital experiences with Devant by WSO2\u2014the AI iPaaS that your AI Agents can call 'home'. BI provides a seamless integration experience with Devant. You can deploy your integrations to Devant with just a few clicks.</p>"},{"location":"deploy/deploy-to-devant/#step-1-login-and-create-a-project-in-devant","title":"Step 1: Login and Create a project in Devant","text":"<ul> <li> <p>Navigate to the Visualizer view by clicking on the BI icon on the sidebar.</p> </li> <li> <p>On the right hand side, under <code>Deployment Options</code> select <code>Deploy to Devant</code>.</p> </li> </ul> <p></p> <ul> <li>Login to Devant organization and create a project</li> </ul> <p> </p>"},{"location":"deploy/deploy-to-devant/#step-2-initialize-the-source-as-a-git-repository-and-push-the-changes","title":"Step 2: Initialize the source as a Git repository and push the changes","text":"<p>Go to the <code>Source Control</code> view and follow the steps to create a Git repository and commit your changes.</p> <p> </p>"},{"location":"deploy/deploy-to-devant/#step-3-create-the-integration-on-devant","title":"Step 3: Create the integration on Devant","text":"<p>Once the source is pushed to GitHub, you can configure the build details and create the integration in Devant.</p> <p></p>"},{"location":"deploy/deploy-to-devant/#step-4-view-the-integration-on-devant","title":"Step 4: View the integration on Devant","text":"<p>Once the integration is deployed to Devant, the <code>Deployment Options</code> panel displays a <code>View in Devant</code> link. This opens the Devant overview page, where you can view logs, update configurations, test the integration, promote it to higher environments, and perform many other management tasks.</p> <p></p>"},{"location":"deploy/managing-configurations/","title":"Managing Configurations","text":"<p>Configurability in WSO2 Integrator: BI allows users to modify integration behavior using external inputs without changing the source code. It is powered by Ballerina\u2019s built-in support for configurable variables, enabling runtime configuration of module-level values.</p> <p>Consider the following step-by-step guide to configuring a Ballerina package that contains an HTTP service.</p>"},{"location":"deploy/managing-configurations/#step-1-create-an-http-service-using-the-default-configurations","title":"Step 1: Create an HTTP service using the default configurations","text":""},{"location":"deploy/managing-configurations/#step-2-create-required-types-and-configurable-variables","title":"Step 2: Create required types and configurable variables","text":"<ul> <li> <p>Create a type <code>Greeting</code> that holds the greeting information.</p> </li> <li> <p>Create a configurable variable to hold the greeting to be sent when invoking the API endpoint. This can be done by adding a <code>Configuration</code> in <code>WSO2 Integrator: BI</code> design view.</p> </li> </ul> <p></p>"},{"location":"deploy/managing-configurations/#step-3-run-the-integration","title":"Step 3: Run the integration","text":"<ul> <li>You'll be prompted to create a <code>Config.toml</code>. This file can contain the greeting information. This allows configuring the values externally during the runtime.</li> </ul> <p>This concept of configurables can be used to hold environment specific variables that needs to be updated at the time of execution.</p>"},{"location":"deploy/overview/","title":"Overview","text":""},{"location":"deploy/overview/#deployment-options","title":"Deployment Options","text":"<p>WSO2 Integrator: BI supports flexible deployment models that can be grouped into two main categories:</p> <ol> <li> <p>Environment-Based Deployment</p> <ul> <li> <p>Local Deployment:  Ideal for development and testing, this mode allows you to run integrations directly on your local machine using the built-in runtime. It offers quick feedback loops, easier debugging, and is often used in early stages of integration development.</p> </li> <li> <p>Cloud Deployment:  Designed for scalable, production-grade environments, this option allows BI built integrations to be deployed in private or public cloud infrastructures. It integrates seamlessly with cloud-native tools for monitoring, auto-scaling, load balancing, and resilience.</p> </li> </ul> </li> <li> <p>Infrastructure-Based Deployment</p> <ul> <li> <p>VM-Based Deployment:  Suited for on-premises or tightly controlled environments, BI built integrations can be deployed on virtual machines using traditional infrastructure provisioning. This model provides full control over the runtime environment but may require more manual effort in scaling and management.</p> </li> <li> <p>Containerized Deployment:  Best for modern, automated environments, BI built integrations run in Docker containers or on Kubernetes clusters. This mode enables improved portability, orchestration, and tight integration with CI/CD pipelines for continuous delivery and infrastructure automation.</p> </li> </ul> </li> </ol> Note<p>Use local and VM-based deployments for early-stage development, PoCs, or controlled environments. Move to containerized or cloud deployments for scalability, high availability, and production readiness. Each option can be adapted to meet your performance, availability, and operational needs.</p>"},{"location":"deploy/overview/#deployment-patterns","title":"Deployment Patterns","text":"<p>To address different architectural and operational requirements, WSO2 Integrator: BI supports both centralized and decentralized deployment patterns:</p> <ul> <li> <p>Centralized Deployment: Consolidates multiple BI artifacts into a single deployable unit. This pattern simplifies deployment, reduces resource consumption, and is ideal for tightly coupled integration solutions.</p> </li> <li> <p>Decentralized Deployment: Each BI component is packaged and deployed independently. This allows teams to iterate and release components separately, improving agility and scalability in microservice-oriented environments.</p> </li> </ul> <p>You can choose a pattern based on your team's workflows, size of the integration solution, and deployment control requirements.</p>"},{"location":"deploy/overview/#hot-deployment-strategies","title":"Hot Deployment Strategies","text":"<p>Hot deployments refer to the process of updating or redeploying software components with zero downtime and maintaining high availability in production systems.</p> <p>Here the hot deployment strategy works by orchestrating multiple service instances through a NGINX load balancer, allowing you to update and restart services without interrupting user traffic. The load balancer automatically routes requests away from instances undergoing updates and back to them once they are healthy again.</p>"},{"location":"deploy/overview/#common-load-balancing-strategies","title":"Common Load Balancing Strategies:","text":""},{"location":"deploy/overview/#1-active-active","title":"1. Active-Active","text":"<p>All instances actively serve traffic simultaneously. NGINX uses passive health monitoring through <code>max_fails</code> and <code>fail_timeout</code> directives. When an instance fails to respond successfully <code>max_fails</code> times within the <code>fail_timeout</code> window, NGINX temporarily removes it from the load balancing pool.</p> <p>This passive approach relies on actual client requests to detect server failures, meaning the load balancer only discovers problems when real traffic encounters them. Passive monitoring is reactive and depends on the natural flow of requests to identify unhealthy servers. The default load balancing method is round-robin, distributing requests evenly across all available servers, though this can be changed to other algorithms like least connections or IP hash based on application requirements.</p> <p>Failed requests are automatically retried on other available instances, as a fault tolerance mechanism.</p>"},{"location":"deploy/overview/#nginx-configuration","title":"NGINX configuration","text":"<pre><code>events {}\n\nhttp {\nupstream backend {\nserver 127.0.0.1 max_fails=3 fail_timeout=30s;\nserver 127.0.0.2 max_fails=3 fail_timeout=30s;\n}\n\nserver {\nlocation / {\nproxy_pass http://backend;\n}\n}\n}\n</code></pre>"},{"location":"deploy/overview/#2-active-active-with-health-checks","title":"2. Active-Active (With health checks)","text":"<p>This configuration requires NGINX Plus, which supports active health checks. NGINX proactively polls a specified health endpoint (e.g., /health) on each instance to determine availability.</p> <p>Unlike passive health checks that only detect failures when client requests fail, active health checks continuously monitor server health in the background, providing faster failure detection and more reliable service availability. This proactive approach allows NGINX to remove unhealthy servers from the pool before they impact user requests, significantly reducing the mean time to detection and improving overall system reliability.</p>"},{"location":"deploy/overview/#nginx-configuration_1","title":"NGINX configuration","text":"<pre><code>events {}\n\nhttp {\nupstream backend {\nserver 127.0.0.1 max_fails=3 fail_timeout=30s;\nserver 127.0.0.2 max_fails=3 fail_timeout=30s;\n}\n\nserver {\nlisten 80;\nlocation / {\nproxy_pass http://backend;\nhealth_check uri=/health interval=5s;\n}\n}\n}\n</code></pre>"},{"location":"deploy/overview/#3-active-passive","title":"3. Active-Passive","text":"<p>Primary server handles all traffic, backup only activates on failure. The backup server remains idle until the primary fails, ensuring you always have a failover target.</p> <p>When the primary server fails to send a response, the load balancer immediately redirects the request to backup server. This failover process is automatic and transparent to the client, occurring within milliseconds of detecting the failure. The backup server must be pre-configured with identical application code and dependencies.</p> <p>Nginx tracks failed requests against <code>max_fails</code> threshold and after reaching threshold, server is marked as unavailable for <code>fail_timeout</code> duration. And then keep sending request to one of the backup servers. Once a server is marked as unavailable, Nginx will not attempt to send requests to it until the <code>fail_timeout</code> period expires, ensuring that the backup server handles all incoming traffic consistently. If multiple backup servers are configured, Nginx will select the first available backup server in the order they are defined, maintaining the single-active-server principle of active-passive architecture.</p> <p>After <code>fail_timeout</code> period, Nginx attempts to route traffic back to primary server. If successful, primary server resumes active role and backup servers return to standby mode. This recovery process is gradual and intelligent - Nginx sends a small number of test requests to the recovered primary server before fully transitioning traffic back. If the primary server successfully handles these test requests without errors, it regains its active status and the backup server automatically transitions back to standby mode. However, if the primary server continues to fail during the recovery attempt, it remains marked as unavailable for another <code>fail_timeout</code> period, and the backup server continues to handle all traffic until the next recovery cycle.</p>"},{"location":"deploy/overview/#nginx-configuration_2","title":"NGINX configuration","text":"<pre><code>events {}\n\nhttp {\nupstream backend {\nserver 127.0.0.1 max_fails=3 fail_timeout=30s;\nserver 127.0.0.2 max_fails=3 fail_timeout=30s;\n}\n\nserver {\nlisten 80;\n\nlocation / {\nproxy_pass http://backend;\n}\n}\n}\n</code></pre> Best Practice<p>Ensure identical configurations across all instances and automate deployments for consistency.</p> <p>You can visit the following sections to get an understanding on the possible deployment and configuration options.</p> <ul> <li>Deploy to Devant</li> <li>Containerized Deployment</li> <li>VM-based Deployment</li> <li>Managing Configurations</li> </ul>"},{"location":"deploy/containerized-deployment/deploy-as-docker-image/","title":"Deploy as a Docker Image","text":"<p>This guide explains how to deploy an integration as a Docker image.</p> <ul> <li>Navigate to the Visualizer view by clicking on the BI icon on the sidebar.</li> <li>Click on the Deploy with Docker under the Deployment Options section in the right panel.</li> <li> <p>Click Create Docker Image button.      </p> </li> <li> <p>The integration will be built as a Docker image and the image will be available in the local Docker registry.</p> </li> </ul>"},{"location":"deploy/containerized-deployment/deploy-on-kubernetes/","title":"Deploy on Kubernetes","text":"<p>This guide explains how to deploy an integration in a Kubernetes cluster.</p>"},{"location":"deploy/containerized-deployment/deploy-on-kubernetes/#step-1-enable-kubernetes-artifact-build","title":"Step 1: Enable Kubernetes artifact build","text":"<pre><code>- Navigate to the Visualizer view by clicking on the BI icon on the sidebar.\n- Go to the `Explorer` view and add the following to `Ballerina.toml` to enable building artifacts for Kubernetes.\n\n```toml\n[build-options]\ncloud = \"k8s\"\n```\n\n- Specify the container image details by creating a `Cloud.toml` file.\n\n```\n[container.image]\nrepository=\"wso2inc\" # Docker hub repository name.\nname=\"greeter\" # container name\ntag=\"latest\"\n```\n\n&lt;a href=\"https://wso2.github.io/docs-bi/assets/img/deploy/k8s_1.gif\"&gt;&lt;img src=\"https://wso2.github.io/docs-bi/assets/img/deploy/k8s_1.gif\" alt=\"Update k8s build configurations\" width=\"70%\"&gt;&lt;/a&gt;</code></pre>"},{"location":"deploy/containerized-deployment/deploy-on-kubernetes/#step-2-build-the-artifacts","title":"Step 2: Build the artifacts","text":"<pre><code>Go to the terminal in VSCode and build the executable using `bal build`. You'll get an output as follows.\n\n```\n    Compiling source\n            example/greeter:0.1.0\n\n    Generating executable\n\n    Generating artifacts\n\n            @kubernetes:Service\n            @kubernetes:ConfigMap\n            @kubernetes:Secret\n            @kubernetes:Deployment\n            @kubernetes:HPA\n\n    Building the docker image\n\n    Execute the below command to deploy the Kubernetes artifacts: \n            kubectl apply -f /home/example/greeter/target/kubernetes/greeter\n```\n\n&lt;a href=\"https://wso2.github.io/docs-bi/assets/img/deploy/k8s_2.gif\"&gt;&lt;img src=\"https://wso2.github.io/docs-bi/assets/img/deploy/k8s_2.gif\" alt=\"Build k8s artifacts\" width=\"70%\"&gt;&lt;/a&gt;\n\n???+ Info\n    This generates the cloud artifacts inside the `target/` directory.</code></pre>"},{"location":"deploy/containerized-deployment/deploy-on-kubernetes/#step-3-push-the-docker-image","title":"Step 3:  Push the Docker image","text":"<pre><code>Execute the command below to push the created Docker image into Docker Hub for the cluster to get access to the previously built container.\n```\n$ docker push wso2inc/greeter:latest\n```\n\n???+ Note\n    Replace `wso2inc` with your repository name.\n\nYou view the output below.\n\n```\nThe push refers to repository [docker.io/wso2inc/greeter]\nlatest: digest: sha256:c1acf5165848d70c347a970d6b5c32f63669cdbb0d4c1daca2c91cfbe32f61b2 size: 13718\n```</code></pre>"},{"location":"deploy/containerized-deployment/deploy-on-kubernetes/#step-4-deploy-on-kubernetes","title":"Step 4:  Deploy on Kubernetes","text":"<pre><code>Execute the command below to deploy the application into the Kubernetes cluster.\n\n```\n$ kubectl apply -f /home/example/greeter/target/kubernetes/greeter\n```\nYou view the output below.\n\n```ballerina\nservice/greeter-svc created\ndeployment.apps/greeter-deployment created\nhorizontalpodautoscaler.autoscaling/greeter-hpa created\n```</code></pre>"},{"location":"deploy/containerized-deployment/overview/","title":"Introduction to Containerized Deployment","text":"<p>Integrations developed with BI can be deployed using modern containerization technologies, such as Docker and Kubernetes, enabling consistent, scalable, and portable application deployments across environments.</p> <p>Containerized deployment simplifies the process of packaging your integration artifacts along with their dependencies into a lightweight, self-contained image. This image can be run on any platform that supports containers, eliminating environmental inconsistencies and easing the transition from development to production.</p> <p>There are two primary approaches to containerized deployment:</p> <ul> <li> <p>Docker Deployment:   Ideal for local development, testing, or simple production environments. The integration runtime is encapsulated in a Docker image, which can be built, run, and managed using standard Docker tools.</p> </li> <li> <p>Kubernetes Deployment:   Suitable for orchestrating containerized applications at scale. Kubernetes provides advanced capabilities like auto-scaling, service discovery, rolling updates, and self-healing, making it the preferred choice for cloud-native and enterprise-grade deployments.</p> </li> </ul> <p>Containerized deployment ensures:</p> <ul> <li>Environment consistency across development, testing, and production.</li> <li>Faster deployment cycles and simplified updates.</li> <li>Better resource utilization and scalability.</li> <li>Easier integration with CI/CD pipelines and cloud infrastructure.</li> </ul> <p>In the following sections, you will learn how to package and deploy your BI projects using Docker and Kubernetes, along with best practices and configuration options.</p> <ul> <li>Deploy as Docker Image</li> <li>Deploy on Kubernetes</li> </ul>"},{"location":"deploy/vm-based-deployment/centralized-deployment/","title":"Centralized Deployment","text":"<p>Managing a large number of BI artifacts across different environments can become complex over time. Each integration flow or service, if deployed independently, can lead to higher operational overhead and increased resource consumption. Centralized deployment simplifies this by bundling all related integration artifacts into a single deployable unit, enabling more efficient resource utilization and streamlined deployments. This approach is ideal when multiple integration solutions need to be deployed and managed together across environments.</p> <p>Centralized deployment typically involves two repositories:</p>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#source-repository-ci","title":"Source Repository (CI)","text":"<p>Typically, a single integration can consist of multiple components, each implemented as a separate BI project. These components can represent distinct functionalities or services that collectively form the complete integration solution. By organizing the integration into multiple projects, the source repository ensures modularity, reusability, and easier maintenance. Each project can be developed, tested, and published independently, allowing teams to work on different components in parallel while maintaining a clear separation of concerns.</p> <p>The source repository is responsible for the continuous integration (CI) process, which includes:</p>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#steps-in-the-ci-process","title":"Steps in the CI Process:","text":""},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-1-prepare-server-environment","title":"Step 1: Prepare Server Environment","text":"<pre><code>- Provision the VM or Bare Metal Server.\n- Ensure the server meets the hardware requirements for your application (CPU, memory, disk space, etc.).\n- Configure the server OS (Linux is recommended for production).</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-2-install-prerequisites","title":"Step 2: Install prerequisites","text":"<pre><code> - Visual Studio Code: Install &lt;a href=\"https://code.visualstudio.com/\"&gt;Visual Studio Code&lt;/a&gt; if you don't have it already.\n - WSO2 Integrator: BI Extension: Install the WSO2 Integrator: BI extension. Refer to &lt;a href=\"../install-wso2-integrator-bi/\"&gt;Install WSO2 Integrator: BI&lt;/a&gt; for detailed instructions.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-3-create-and-implement-bi-projects","title":"Step 3: Create and Implement BI Projects","text":"<pre><code>- Create a new integration project using the BI VS Code extension.\n- Implement business logic using the drag-and-drop designer or by writing Ballerina/DSL code.\n\n???+ Tip\n    Use shared modules or libraries for common logic and avoid duplication.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-4-add-tests","title":"Step 4: Add Tests","text":"<pre><code> - Use the `Test Explorer` to create integration tests for services and connectors.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-5-build-the-artifacts","title":"Step 5: Build the Artifacts","text":"<pre><code> - Package the project using the BI toolchain to generate deployable `.zip` or `.jar` artifacts.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-6-publish-artifacts","title":"Step 6: Publish Artifacts","text":"<pre><code>- Push the generated artifacts to a shared artifact repository (e.g., GitHub Packages, Nexus, or internal registry).\n\n???+ Tip\n    Automate the above CI steps using GitHub Actions or your preferred CI tool.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#deployment-repository-cd","title":"Deployment Repository (CD)","text":"<p>The deployment repository acts as the central hub for production-ready integration artifacts. It collects and consolidates the required applications from one or more source repositories, enabling centralized configuration and deployment. This repository streamlines the deployment process by orchestrating the integration of these applications and preparing them for deployment to the target environment. By centralizing deployment management, it simplifies configuration, enhances maintainability, and ensures consistency across environments.</p>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#steps-in-the-cd-process","title":"Steps in the CD Process:","text":""},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-1-prepare-the-runtime-environment","title":"Step 1: Prepare the Runtime Environment","text":"<pre><code>- Provision a server or containerized environment (e.g., Kubernetes, Docker).\n- Install WSO2 Integrator runtime.\n- Ensure external dependencies (databases, message brokers, etc.) are configured.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-2-fetch-and-consolidate-artifacts","title":"Step 2: Fetch and Consolidate Artifacts","text":"<pre><code>- Go to the terminal on VSCode and install the `Ballerina consolidate packages` tool\n\n```\n$ bal tool pull consolidate-packages\n```\n\n- Pull integration artifacts from the source/artifact repositories to create a consolidated project\n\n```\n$ bal consolidate-packages new --package-path &lt;consolidated-project-path&gt; &lt;comma-separated-list-of-package-names&gt;\n```\n\n???+ Tip\n    Visit the [Consolidate-packages tool](/learn/consolidate-packages-tool) for more information on how to consolidate Ballerina packages.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-3-add-integration-tests-to-the-consolidated-project","title":"Step 3: Add integration tests to the consolidated project","text":"<pre><code>- Use the `Test Explorer` of BI to write and execute tests for the consolidated project.</code></pre>"},{"location":"deploy/vm-based-deployment/centralized-deployment/#step-4-create-the-executable-jar-for-the-project","title":"Step 4: Create the executable JAR for the project","text":"<pre><code>- Navigate to the Visualizer view by clicking on the BI icon on the sidebar.\n- Click on the **Deploy on VM** under the **Deployment Options** section in the right panel.\n- Click **Create Executable** button.       \n    &lt;a href=\"https://wso2.github.io/docs-bi/assets/img/deploy/jar.gif\"&gt;&lt;img src=\"https://wso2.github.io/docs-bi/assets/img/deploy/jar.gif\" alt=\"Build JAR\" width=\"70%\"&gt;&lt;/a&gt; \n- The integration will be built as an executable JAR, and the JAR file will be available in the `target\\bin` directory of the project.</code></pre> <p>The generated Ballerina artifact can be deployed to the target environment, configuring necessary environment variables and system settings.</p>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/","title":"De-centralized Deployment","text":"<p>The de-centralized deployment offers a straightforward approach, ideal for simpler applications or when direct control over individual deployments is preferred. In this method, BI artifacts are developed and published to a registry (a storage location for deployable components). The deployment process retrieves these artifacts and deploys them to the target environment, ensuring all necessary dependencies and configurations are included.</p>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#continuous-integration-ci","title":"Continuous Integration (CI)","text":"<p>Continuous Integration (CI) in de-centralized deployment streamlines development by automating the building, testing, and publishing of individual BI artifacts, ensuring faster feedback and fewer integration issues.</p> <p>The following steps outline the CI process of the de-centralized deployment:</p>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#step-1-prepare-the-server-environment","title":"Step 1: Prepare the Server Environment","text":"<ul> <li>Provision the VM or Bare Metal Server.</li> <li>Ensure the server meets the hardware requirements for your application (CPU, memory, disk space, etc.).</li> <li>Configure the server OS (Linux is recommended for production).</li> </ul>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#step-2-install-prerequisites","title":"Step 2: Install prerequisites","text":"<pre><code> - Visual Studio Code: Install &lt;a href=\"https://code.visualstudio.com/\"&gt;Visual Studio Code&lt;/a&gt; if you don't have it already.\n - WSO2 Integrator: BI Extension: Install the WSO2 Integrator: BI extension. Refer to &lt;a href=\"../install-wso2-integrator-bi/\"&gt;Install WSO2 Integrator: BI&lt;/a&gt; for detailed instructions.</code></pre>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#step-3-create-and-implement-bi-projects","title":"Step 3: Create and Implement BI Projects","text":"<pre><code>- Create a new integration project using the BI VS Code extension.\n- Implement business logic using the drag-and-drop designer or by writing Ballerina/DSL code.\n\n???+ Tip\n    Use shared modules or libraries for common logic and avoid duplication.</code></pre>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#step-4-add-integration-tests-to-the-consolidated-project","title":"Step 4: Add integration tests to the consolidated project","text":"<pre><code>- Use the `Test Explorer` of BI to write and execute tests for the consolidated project.</code></pre>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#step-5-create-the-executable-jar-for-the-project","title":"Step 5: Create the executable JAR for the project","text":"<pre><code>- Navigate to the Visualizer view by clicking on the BI icon on the sidebar.\n- Click on the **Deploy on VM** under the **Deployment Options** section in the right panel.\n- Click **Create Executable** button.       \n    &lt;a href=\"https://wso2.github.io/docs-bi/assets/img/deploy/jar.gif\"&gt;&lt;img src=\"https://wso2.github.io/docs-bi/assets/img/deploy/jar.gif\" alt=\"Build JAR\" width=\"70%\"&gt;&lt;/a&gt; \n- The integration will be built as an executable JAR and the JAR file will be available in the `target\\bin` directory of the project.</code></pre>"},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#step-6-publish-the-artifacts-to-the-registry","title":"Step 6: Publish the artifacts to the registry.","text":""},{"location":"deploy/vm-based-deployment/de-centralized-deployment/#continuous-deployment-cd","title":"Continuous Deployment (CD)","text":"<p>The Continuous Deployment (CD) process in a de-centralized setup involves automating the deployment of Ballerina artifacts to the target environment. This typically involves using a deployment workflow or pipeline to retrieve the built artifacts from the registry, configure the target environment, deploy the application, and verify its successful deployment.</p>"},{"location":"deploy/vm-based-deployment/deploy-on-vm-as-executable-jar/","title":"Deploy on a VM as an Executable JAR","text":"<p>This guide explains how to deploy an integration as an executable JAR file.</p> <ul> <li>Navigate to the Visualizer view by clicking on the BI icon on the sidebar.</li> <li>Click on the Deploy on VM under the Deployment Options section in the right panel.</li> <li> <p>Click Create Executable button.      </p> </li> <li> <p>The integration will be built as an executable JAR and the JAR file will be available in the <code>target\\bin</code> directory of the project.</p> </li> </ul>"},{"location":"deploy/vm-based-deployment/github-action-for-cicd/","title":"GitHub Action for CICD","text":""},{"location":"deploy/vm-based-deployment/github-action-for-cicd/#github-action-for-cicd-integration","title":"GitHub Action for CI/CD integration","text":"<p>The Ballerina GitHub Action enables seamless automation of CI/CD workflows for WSO2 Integrator: BI projects hosted on GitHub. This action can be used to build and push Ballerina packages that serve as integration artifacts in WSO2 Integrator: BI.</p> <p>The following sample GitHub Actions workflow demonstrates how to automate the build and publish process for a Ballerina-based integration using WSO2 Integrator: BI. The workflow uses the Ballerina GitHub Action to build the integration and publish it to Ballerina Central.</p> <pre><code>name: Ballerina publish example\n\non: [workflow_dispatch]\n\njobs:\nbuild:\n\nruns-on: ubuntu-latest\n\nsteps:\n- name: Checkout\nuses: actions/checkout@v1\n\n- name: Ballerina Build\nuses: ballerina-platform/ballerina-action@master\nwith:\nargs: pack\n\n- name: Ballerina Push\nuses: ballerina-platform/ballerina-action@master\nwith:\nargs: push env: BALLERINA_CENTRAL_ACCESS_TOKEN: ${{ secrets.BallerinaToken }}\n</code></pre>"},{"location":"deploy/vm-based-deployment/overview/","title":"Introduction to VM-based Deployment","text":"<p>Integrations developed with BI can be deployed on virtual machines (VMs), offering a flexible and familiar option for organizations operating in traditional IT environments or requiring fine-grained control over their infrastructure.</p> <p>VM-based deployment involves provisioning virtualized compute resources\u2014either on-premises or in the cloud\u2014and manually configuring the environment to host the BI runtime and its dependencies. This approach is well-suited for setups where containerization is not feasible or where integration with existing VM-based infrastructure is required.</p> <p>There are two common scenarios for VM-based deployment:</p> <ul> <li> <p>On-Premises VMs:   Ideal for environments with strict data residency, security, or compliance requirements. Organizations can deploy and manage BI on VMs running in a controlled internal network.</p> </li> <li> <p>Cloud-hosted VMs:   Suitable for leveraging cloud scalability while maintaining control over the OS and runtime environment. Popular platforms like AWS EC2, Azure Virtual Machines, or Google Compute Engine allow BI to run within customized VM instances.</p> </li> </ul> <p>VM-based deployment offers:</p> <ul> <li>Greater control over operating system, networking, and runtime configurations.</li> <li>Compatibility with legacy systems and hybrid infrastructure models.</li> <li>Easier adoption for teams already using VM-based workflows.</li> <li>A viable alternative where containerization is restricted or unsupported.</li> </ul> <p>In the following sections, you will learn how to set up, configure, and manage BI deployments on virtual machines, including environment preparation, runtime installation, and deployment automation strategies.</p> <ul> <li>Centralized Deployment</li> <li>De-centralized Deployment</li> <li>Deploy on VM as Executable Jar</li> <li>GitHub Action for CICD</li> </ul>"},{"location":"developer-guides/create-a-project/","title":"Create a Project","text":"<p>Project is the foundational unit where you define and manage your integration artifacts. Follow the below steps to create an integration project using the WSO2 Integrator: BI.</p> <ol> <li> <p>Launch Visual Studio Code with the WSO2 Integrator: BI extension installed.</p> <p>Info</p> <p>Follow the Install WSO2 Integrator: BI documentation for a complete installation guide.</p> </li> <li> <p>Click on the BI icon on the Activity Bar of the VS Code editor.</p> <p></p> </li> <li> <p>Next, click on Create New Integration. </p> <p></p> <p>Then enter a suitable name for the integration project and provide a location for it.</p> </li> <li> <p>It will open the home page of BI.</p> <p></p> </li> </ol> <p>Now, you can start creating your integration by developing artifacts. See the WSO2 Integrator: BI Artifacts to learn about the integration artifacts.</p> <p>Additionally, you can enhance your experience by incorporating AI-powered assistance with WSO2 Copilot.</p>"},{"location":"developer-guides/data-mapping/","title":"Data Mapping","text":"<p>The following instructions demonstrate how to build an integration that transforms a JSON payload into a different JSON structure using WSO2 Integrator: BI Data Mapper. An HTTP service with a single resource (<code>transform</code>) will be created to receive a JSON payload and return the transformed result.</p>"},{"location":"developer-guides/data-mapping/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>Transformer</code>.</li> <li>Select project directory location by clicking on the Select Location button.</li> <li> <p>Click on the Create New Integration button to create the integration project.  </p> <p></p> </li> </ol>"},{"location":"developer-guides/data-mapping/#step-2-define-input-and-output-types","title":"Step 2: Define input and output types","text":"<ol> <li>Click on the Add Artifacts button and select Type in the Other Artifacts section.</li> <li> <p>Click on + Add Type to add a new type.  </p> <p></p> </li> <li> <p>Generate record types corresponding to the input and output JSON payloads given below.</p> </li> <li> <p>Select Is Separate Record Definitions and click on the Import button.</p> <p>Input <pre><code>{\n\"user\": {\n\"firstName\": \"John\",\n\"lastName\": \"Doe\",\n\"email\": \"john.doe@example.com\",\n\"address\": {\n\"street\": \"123 Elm St\",\n\"city\": \"San Francisco\",\n\"state\": \"CA\",\n\"postalCode\": 94107\n},\n\"phoneNumbers\": [\"123-456-7890\", \"098-765-4321\"]\n},\n\"account\": {\n\"accountNumber\": \"A123456789\",\n\"balance\": 2500,\n\"lastTransaction\": \"2023-10-15T14:30:00Z\"\n}\n}\n</code></pre></p> <p>Output <pre><code>{\n\"fullName\": \"John Doe\",\n\"contactDetails\": {\n\"email\": \"john.doe@example.com\",\n\"primaryPhone\": \"123-456-7890\"\n},\n\"location\": {\n\"city\": \"San Francisco\",\n\"state\": \"CA\",\n\"zipCode\": \"94107\"\n},\n\"accountInfo\": {\n\"accountNumber\": \"A123456789\",\n\"balance\": 2500\n},\n\"transactionDate\":  \"2023-10-15T14:30:00Z\"\n}\n</code></pre> 5. The final types will look like below. The source view can be accessed by clicking on the <code>&lt;/&gt;</code> button in the top right corner.</p> <p></p> </li> </ol>"},{"location":"developer-guides/data-mapping/#step-3-create-a-http-service","title":"Step 3: Create a HTTP service","text":"<ol> <li>Click on <code>Home</code> button to navigate back to the design view</li> <li>In the design view, click on the Add Artifact button.</li> <li>Select HTTP Service under the Integration as API category.</li> <li>Select the + Listeners option from the Listeners dropdown to add a new listener.</li> <li>Enter the listener name as <code>transformListener</code>, <code>8290</code> as the port and click on the Save button.</li> <li>Add the service base path as <code>/</code> and select the Design from Scratch option as the The contract of the service.</li> <li> <p>Click on the Create button to create the new service with the specified configurations.</p> <p></p> </li> </ol>"},{"location":"developer-guides/data-mapping/#step-4-update-the-resource-method","title":"Step 4: Update the resource method","text":"<ol> <li>Click on <code>Edit Resource</code> button</li> <li>Change the resource HTTP method to POST.</li> <li>Change the resource name as <code>transform</code>.</li> <li>Add a payload parameter named <code>input</code> to the resource of type <code>Input</code>. </li> <li>Change the response status code to <code>201</code> and the return type to <code>Output</code>.</li> <li> <p>Click on the Save button to update the resource with the specified configurations. </p> <p></p> </li> </ol> <p>Resource Method</p> <p>To learn more about resources, see Ballerina Resources.</p>"},{"location":"developer-guides/data-mapping/#step-5-add-data-mapper","title":"Step 5: Add data mapper","text":"<ol> <li>Click on the <code>transform</code> resource to navigate to the resource implementation designer view.</li> <li>Delete the existing Return node in the flow diagram.</li> <li>Hover to the arrow after start and click the \u2795 button to add a new action to the resource.</li> <li>Select Map Data from the node panel and click on Create Data Mapper button. </li> <li> <p>Fill in the required fields with the values given below and <code>Create Mapping</code> button to start data mapping.</p> Field Value Data Mapper Name <code>transformed</code> Input <code>Input input</code> Output <code>Output</code> <p></p> <p> </p> </li> </ol>"},{"location":"developer-guides/data-mapping/#step-6-create-mappings","title":"Step 6: Create mappings","text":"<ol> <li>First click on the input field and then click on the desired output field to create a mapping.</li> <li>When you are done click on the Go Back Button to return to the flow diagram.</li> </ol>"},{"location":"developer-guides/data-mapping/#create-simple-mapping","title":"Create simple mapping","text":""},{"location":"developer-guides/data-mapping/#auto-mapping","title":"Auto mapping","text":""},{"location":"developer-guides/data-mapping/#many-to-one-mapping","title":"Many-to-one mapping","text":""},{"location":"developer-guides/data-mapping/#edit-mapping-expression","title":"Edit mapping expression","text":""},{"location":"developer-guides/data-mapping/#resolving-errors","title":"Resolving errors","text":""},{"location":"developer-guides/data-mapping/#step-7-return-the-transformed-payload","title":"Step 7: Return the transformed payload","text":"<ol> <li>Hover to the arrow after the Data Mapper node in the flow diagram and click the \u2795 button.</li> <li> <p>Select Return from the node panel. </p> <p></p> </li> <li> <p>Provide <code>output</code> as the return expression.</p> </li> <li> <p>The final code will look like below. The source view can be accessed by clicking on the <code>&lt;/&gt;</code> button in the top right corner. </p> <pre><code>import ballerina/http;\n\nlistener http:Listener transformListner = new (port = 8290);\n\nservice / on transformListner {\n    resource function post transform(@http:Payload Input input) returns http:InternalServerError|Output|error {\n        do {\n            Output output = transform(input);\n            return output;\n\n        } on fail error err {\n            // handle error\n            return error(\"Not implemented\", err);\n        }\n    }\n}\n</code></pre> </li> </ol>"},{"location":"developer-guides/data-mapping/#step-8-run-the-integration","title":"Step 8: Run the integration","text":"<ol> <li>Click on the Run button in the top-right corner to run the integration.</li> <li>The integration will start and the service will be available at http://localhost:8290/transform.</li> <li> <p>The service can be tested using a tool like Postman or cURL by sending a POST request with a JSON payload to the service endpoint.</p> <pre><code>curl -X POST \"http://localhost:8290/transform\" -H \"Content-Type: application/json\" -d '{\n    \"user\": {\n        \"firstName\": \"John\",\n        \"lastName\": \"Doe\",\n        \"email\": \"john.doe@example.com\",\n        \"address\": {\n            \"street\": \"123 Elm St\",\n            \"city\": \"San Francisco\",\n            \"state\": \"CA\",\n            \"postalCode\": 94107\n        },\n        \"phoneNumbers\": [\"123-456-7890\", \"098-765-4321\"]\n    },\n    \"account\": {\n        \"accountNumber\": \"A123456789\",\n        \"balance\": 2500,\n        \"lastTransaction\": \"2023-10-15T14:30:00Z\"\n    } \n}'\n</code></pre> </li> <li> <p>The response will be the transformed JSON payload. <pre><code>{\n\"fullName\": \"John Doe\",\n\"contactDetails\": {\n\"email\": \"john.doe@example.com\",\n\"primaryPhone\": \"123-456-7890\"\n},\n\"location\": {\n\"city\": \"San Francisco\",\n\"state\": \"CA\",\n\"zipCode\": \"94107\"\n},\n\"accountInfo\": {\n\"accountNumber\": \"A123456789\",\n\"balance\": 2500\n},\n\"transactionDate\":  \"2023-10-15T14:30:00Z\"\n}\n</code></pre></p> </li> </ol>"},{"location":"developer-guides/debug-the-integrations/","title":"Debug the Integration","text":""},{"location":"developer-guides/design-the-integrations/","title":"Design the Integrations","text":"<p>WSO2 Integrator: BI provides intuitive tools to design, analyze, and manage integration flows. Whether you're creating new integrations or reviewing existing ones, the visualizer offers a clear and structured view of system behavior to streamline development and maintenance.</p>"},{"location":"developer-guides/design-the-integrations/#design-view","title":"Design view","text":"<p>The Design View in BI provides an intuitive, visual interface for developing integration projects. It helps you model, understand, and manage integration flows without needing to write or view code directly.</p> <p>Design View helps you:</p> <ul> <li>Visually model complex integration logic.</li> <li>Quickly understand the structure and behavior of your integrations.</li> <li>Accelerate development with drag-and-drop simplicity and AI-powered assistance.</li> <li>Manage deployment and documentation from a unified interface.</li> </ul> <p></p> <p>Key areas of the design view are as follows. </p>"},{"location":"developer-guides/design-the-integrations/#project-explorer","title":"Project explorer","text":"<p>The left sidebar displays the structure of your integration project. It organizes key elements, including:</p> <ul> <li>Entry Points \u2013 Define how your integration is triggered (for example, HTTP services or events).</li> <li>Listeners \u2013 Define the underlying protocols or transports used to receive incoming requests or events.</li> <li>Connections \u2013 Represent external systems that the integration interacts with, such as APIs or databases.</li> <li>Types, Functions, and Data Mappers \u2013 Contain reusable definitions and logic for handling data.</li> <li>Configurations \u2013 Hold externalized values like API keys or secrets.</li> <li>Local Connectors \u2013 Include reusable custom components.</li> </ul>"},{"location":"developer-guides/design-the-integrations/#canvas","title":"Canvas","text":"<p>The central design panel provides a visual representation of the integration flow. Each element is represented as a node, showing how services, listeners, and connections interact with one another. You can view service endpoints and how data moves through the integration.</p>"},{"location":"developer-guides/design-the-integrations/#toolbar","title":"Toolbar","text":"<p>Located at the top of the canvas, the toolbar offers quick actions to:</p> <ul> <li>Generate parts of the integration using AI assistance.</li> <li>Add an Artifact to insert services, events, or other integration elements.</li> </ul>"},{"location":"developer-guides/design-the-integrations/#deployment-options","title":"Deployment options","text":"<p>The panel on the right shows available deployment methods and the status of current deployments. You can choose to:</p> <ul> <li>Deploy to WSO2 Devant.</li> <li>Deploy using Docker or on a virtual machine (VM).</li> <li>Enable the Integration Control Plane (ICP) to monitor and manage deployments.</li> </ul>"},{"location":"developer-guides/design-the-integrations/#readme-panel","title":"README panel","text":"<p>This panel provides contextual documentation about the integration. It\u2019s used to describe the integration\u2019s purpose, features, usage instructions, and external references such as GitHub repositories.</p>"},{"location":"developer-guides/design-the-integrations/#functionautomation-logic-view","title":"Function/Automation logic view","text":"<p>When working with Functions and Automations in BI, you can explore and edit the internal logic using two interactive visual modes\u2014Flow and Sequence. These modes provide complementary perspectives to help understand and manage the behavior of your logic components effectively.</p>"},{"location":"developer-guides/design-the-integrations/#flow-diagram","title":"Flow diagram","text":"<p>The Flow mode presents a high-level, graphical layout of the execution path. It emphasizes clarity by organizing actions vertically in the order in which they are executed.</p> <ul> <li>Shows each step, such as service calls, variable declarations, conditionals, and returns.</li> <li>Includes a visual Error Handler block for defining error management logic.</li> <li>Highlights the end-to-end logic in a simplified, linear format.</li> <li>Helps you quickly understand and edit the logic.</li> </ul> <p></p>"},{"location":"developer-guides/design-the-integrations/#editing-capabilities-in-the-flow-diagram","title":"Editing capabilities in the flow diagram","text":"<p>The Flow mode in BI provides an intuitive, interactive interface for visually editing integration logic. It allows you to design and refine integration flows by interacting directly with the diagram.</p> <p>Interaction Options on Hover</p> <p>When you hover over a connector line between two nodes, the following options become available:</p> <ul> <li>Use AI Assistance: Enter a prompt to generate the next set of nodes using AI assistance. This helps accelerate integration development with contextual suggestions.</li> <li>Add a Comment: Attach comments to document your flow design or explain decisions.</li> <li>Insert Artifacts: Add new artifacts (e.g., functions, conditions, connectors) from the artifact panel between connected nodes.</li> </ul> <p>Node-Level actions</p> <p>Each node in the flow diagram provides a menu with the following actions:</p> <ul> <li>Edit: Modify the operation or configuration of the node.</li> <li>Delete: Remove the node from the diagram.</li> <li>Add Breakpoint: Insert a breakpoint to pause execution at runtime for debugging.</li> <li>View Source: Open and inspect the corresponding source code of the node.</li> </ul> <p>These features make it easy to build, understand, and troubleshoot integrations in a highly visual way.</p> <p></p>"},{"location":"developer-guides/design-the-integrations/#sequence-mode","title":"Sequence mode","text":"<p>The Sequence mode offers a more structured, detailed view closer to traditional sequence diagrams and helps to understand integration behaviours. It emphasizes the sequence of message exchanges across different components in the system.</p> <ul> <li>Displays the flow of invocations between services, clients, and functions.</li> <li>Clearly represents input/output calls and the order of execution.</li> <li>Useful for analyzing integration logic from an operational or interaction standpoint.</li> </ul> <p></p>"},{"location":"developer-guides/design-the-integrations/#types-diagram","title":"Types diagram","text":"<p>The Types Diagram shows a clear visual of how types are defined and connected in the application, allowing for visually adding and editing types. It makes it easier to design data models and understand nested structures by showing their relationships graphically. You can open the Types diagram by clicking on a type in the left panel. </p> <p></p>"},{"location":"developer-guides/design-the-integrations/#source-code-view","title":"Source code view","text":"<p>In addition to the visual views, BI provides a source code view for directly editing the underlying Ballerina code.</p> <p>You can switch to this view by clicking the <code>&lt;/&gt;</code> icon located in the top-right corner of the editor interface. This opens the full source code corresponding to your integration logic.</p> Generate with AI<p>The underlying code is generated in Ballerina, a cloud-native programming language designed for integration. This view is especially useful for users who prefer text-based editing or need fine-grained control over the implementation.</p> <p>Changes made in the Design View or the Source Code View stay in sync, allowing for a seamless switch between visual and code-based development.</p> <p></p>"},{"location":"developer-guides/test-the-integrations/","title":"Test the Integration","text":""},{"location":"developer-guides/try-the-integration/","title":"Try the Integration","text":"<p>Once you have completed building your integration with the WSO2 Integrator: BI, you can quickly test it right from the design interface. This section walks you through how to run and try your integration project using the built-in tooling.</p>"},{"location":"developer-guides/try-the-integration/#run-the-integration","title":"Run the integration","text":"<ol> <li> <p>Click Run on the top-right title bar of the editor.</p> <p></p> </li> <li> <p>If the required configuration values are missing, a prompt will appear as shown below, indicating that the <code>Config.toml</code> file is missing.</p> <p>You\u2019ll be given three options:</p> <ul> <li>Create Config.toml \u2013 Recommended to generate and populate the required configuration file.</li> <li>Run Anyway \u2013 Proceed without the config file (not recommended for integrations requiring config values).</li> <li>Cancel \u2013 Abort the run operation.</li> </ul> <p>Make sure to choose Create Config.toml and fill in the necessary values before continuing.</p> <p></p> </li> <li> <p>This will launch the integration terminal.</p> </li> </ol>"},{"location":"developer-guides/try-the-integration/#try-the-services","title":"Try the services","text":"<p>The Try It window on the right side of the BI interface provides a built-in way to test your HTTP services without leaving the development environment. </p> <p></p>"},{"location":"developer-guides/wso2-integrator-bi-artifacts/","title":"WSO2 Integrator: BI Artifacts","text":"<p>WSO2 Integrator: BI supports a range of artifact types that enable developers to build powerful, event-driven, API-based, and file-based integration solutions. Each artifact type defines how an integration is triggered and how it behaves in various runtime environments.</p> <p></p> <p>Below is an overview of the available artifact types in the BI.</p>"},{"location":"developer-guides/wso2-integrator-bi-artifacts/#automation","title":"Automation","text":"<p>Create an automation that can be triggered manually or scheduled to run periodically. Automations are ideal for time-based or on-demand processes such as data synchronization, report generation, or cleanup jobs.</p>"},{"location":"developer-guides/wso2-integrator-bi-artifacts/#ai-agent","title":"AI agent","text":"<p>Create an intelligent agent that can be accessed via chat or exposed as an API. AI Agents are useful when you want to embed LLM-backed reasoning or decision-making capabilities into your integration workflows.</p>"},{"location":"developer-guides/wso2-integrator-bi-artifacts/#integration-as-api","title":"Integration as API","text":"<p>Create an integration that exposes services over various protocols such as HTTP, GraphQL, or TCP. This artifact type is used when building services that must interact with external systems through standard APIs.</p>"},{"location":"developer-guides/wso2-integrator-bi-artifacts/#event-integration","title":"Event integration","text":"<p>Create an event-driven integration that is triggered by external events. These can include message brokers, third-party services, or cloud-based event sources.</p> <p>Supported event sources:</p> <ul> <li>Kafka</li> <li>RabbitMQ</li> <li>MQTT</li> <li>Azure Service Bus</li> <li>Salesforce</li> <li>GitHub</li> </ul>"},{"location":"developer-guides/wso2-integrator-bi-artifacts/#file-integration","title":"File integration","text":"<p>Create a file-based integration that reacts to the availability or changes in files within a file system or over FTP. This artifact type is useful for legacy systems or industries that rely on batch file exchanges.</p> <p>Supported file triggers:</p> <ul> <li>FTP services</li> <li>Directory services (local or mounted volumes)</li> </ul> <p>Each artifact type is designed to simplify the creation of integrations suited for a specific kind of use case or trigger. You can combine multiple artifacts within a single solution to cover a wide range of integration needs.</p>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/","title":"Build an HTTP Service With WSO2 Copilot","text":"<p>In this tutorial, you\u2019ll create an HTTP service to add key-value pairs to a Redis database. The integrated AI-assistant will help you generate the integration flow.</p>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker installed on your machine.</li> </ul>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>RedisService</code>.</li> <li>Select project directory location by clicking on the Select Location button.</li> <li>Click on the Create New Integration button to create the integration project.</li> </ol>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-2-create-a-new-integration","title":"Step 2: Create a new integration","text":"<ol> <li>In the design view click on the Generate with AI button.</li> <li> <p>Enter the following prompt and press <code>Enter</code>:    <pre><code> Create an integration service with a base path of /cache and a POST resource at /add that accepts key-value pairs and adds them to Redis.\n</code></pre></p> <p></p> </li> <li> <p>Click on + Add to Ingeration button to add the generated integration to the project.</p> </li> <li> <p>The generated integration will look like below:  </p> <p></p> </li> </ol>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-3-add-a-resource-to-get-value","title":"Step 3:  Add a resource to get value","text":"<ol> <li>Add the following prompt and press <code>Enter</code>:    <pre><code> Add a resource to get the value of a key from Redis.\n</code></pre></li> <li>Click on + Add to Ingeration button to add the generated integration to the project.</li> <li> <p>The generated integration will look like below:  </p> <p></p> </li> </ol>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-4-start-the-redis-server","title":"Step 4: Start the Redis server","text":"<ol> <li>Start the Redis server by running the following command:    <pre><code>docker run --name some-redis -d -p 6379:6379 redis\n</code></pre></li> <li> <p>The redis server will start on port <code>6379</code> without password protection. </p> <p></p> </li> </ol>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-6-configure-the-redis-client","title":"Step 6:  Configure the Redis client","text":"<ol> <li>In the <code>Integrator overview</code>, click on the Configurations.</li> <li>Set <code>redisHost</code> value to <code>localhost</code>.</li> <li> <p>Set <code>redisPort</code> value to <code>6379</code>.   </p> <p></p> </li> </ol>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-5-generate-the-curl-commands","title":"Step 5: Generate the curl commands","text":"<ol> <li> <p>Add the following prompt and press <code>Enter</code> to generate the curl command to add key-value pairs to the Redis server.:    <pre><code> Generate a curl command to add key-value pairs to the Redis server.\n</code></pre></p> <p></p> </li> <li> <p>Add the following prompt and press <code>Enter</code> to generate the curl command to get the value of a key from the Redis server.:    <pre><code> Generate a curl command to get the value of a key from the Redis server.\n</code></pre></p> </li> </ol>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-6-test-the-integration","title":"Step 6: Test the integration","text":"<ol> <li>Click on the Run button to start the integration.</li> <li>Execute the generated <code>curl</code> commands to add a key-value pair.    <pre><code>   curl -X POST http://localhost:8080/cache/add \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"key\": \"BI\", \"value\": \"BI is an AI-assisted integration platform.\"}' \n</code></pre></li> <li>Execute the generated <code>curl</code> command to get the value of the key.    <pre><code>   curl http://localhost:8080/cache/get?key=BI\n</code></pre></li> <li>The response will be the value of the key <code>BI</code> stored in the Redis server.    <pre><code>BI is an AI-assisted integration platform.%\n</code></pre></li> </ol>"},{"location":"developer-guides/ai-for-integration/build-an-http-service-with-wso2-copilot/#step-7-stop-the-integration","title":"Step 7: Stop the integration","text":"<ol> <li>Click on the Stop button to stop the integration.</li> <li>Stop the Redis server by running the following command:    <pre><code>docker stop some-redis\n</code></pre></li> </ol>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/","title":"MuleSoft Migration Tool","text":"<p>This guide explains how to use the migrate-mule tool to convert  MuleSoft applications into Ballerina packages compatible with the WSO2 Integrator: BI.</p>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#tool-overview","title":"Tool overview","text":"<p>The tool accepts either a MuleSoft project directory, a standalone Mule <code>.xml</code> configuration file, or a directory containing multiple MuleSoft projects as input. It generates equivalent Ballerina packages that can be opened in WSO2 Integrator: BI. </p> <p>Multi-project conversion is supported via the <code>--multi-root</code> option, allowing batch migration of several Mule projects in one run. </p> <p>For migration assessment, the <code>--dry-run</code> option is available. This generates a detailed migration assessment report (<code>migration_report.html</code>) without actually converting the project, helping teams evaluate migration feasibility, estimate effort, and identify manual conversion requirements before committing to a full migration.</p>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#supported-mule-versions","title":"Supported Mule versions","text":"<p>The migration tool supports both Mule 3.x and Mule 4.x projects.</p>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#installation","title":"Installation","text":"<p>To install the <code>migrate-mule</code> tool from Ballerina Central, run the following command: <pre><code>$ bal tool pull migrate-mule\n</code></pre></p>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#implementation","title":"Implementation","text":"<p>Follow the steps below to migrate your MuleSoft application.</p>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#step-1-prepare-your-input","title":"Step 1: Prepare your input","text":"<p>You can migrate a complete MuleSoft project, a standalone Mule <code>.xml</code> configuration file, or a directory containing multiple MuleSoft projects:</p> <ul> <li>For MuleSoft projects: Ensure your project follows the standard structure with configuration XML files located under:</li> <li>Mule 3.x: <code>mule-project/src/main/app</code></li> <li>Mule 4.x: <code>mule-project/src/main/mule</code></li> <li>For standalone XML files: You can directly use any valid Mule XML configuration file.</li> <li>For multiple MuleSoft projects: To use multi-project migration, organize your MuleSoft projects so that each project is a separate directory directly inside a single parent directory. The parent directory should contain only the individual MuleSoft project folders (not nested further). The tool can process all projects in batch using the <code>--multi-root</code> option.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#step-2-run-the-migration-tool","title":"Step 2: Run the migration tool","text":"<p>Use one of the following commands based on your needs:</p> <ol> <li> <p>To convert a MuleSoft project with default output location:</p> <p><pre><code>$ bal migrate-mule /path/to/mule-project\n</code></pre> This will create a Ballerina package inside <code>/path/to/mule-project</code> directory.</p> </li> <li> <p>To convert a MuleSoft project with a custom output location:</p> <p><pre><code>$ bal migrate-mule /path/to/mule-project --out /path/to/output-dir\n</code></pre> This will create a Ballerina package at <code>/path/to/output-dir</code>.</p> </li> <li> <p>To convert multiple Mule projects with multi-root mode:</p> <p><pre><code>$ bal migrate-mule /path/to/projects-directory --multi-root\n</code></pre>    Each child directory is treated as a separate Mule project and converted. An aggregated report <code>aggregate_migration_report.html</code> will be generated summarizing migration results for all projects.</p> </li> <li> <p>To run in dry-run mode:     <pre><code>$ bal migrate-mule /path/to/mule-project --dry-run\n</code></pre>     This will run the parsing and analysis phases and generate a detailed migration assessment report (<code>migration_report.html</code>) without actually converting the project. The report helps teams evaluate migration feasibility, estimate effort, and identify manual conversion requirements before committing to a full migration.</p> </li> <li> <p>To convert a standalone Mule XML file:</p> <p><pre><code>$ bal migrate-mule /path/to/mule-flow.xml\n</code></pre> This will create a Ballerina package in the same directory as the input XML file.</p> </li> <li> <p>To force Mule version during migration:     <pre><code>$ bal migrate-mule /path/to/mule-project --force-version 3\n$ bal migrate-mule /path/to/mule-project --force-version 4\n</code></pre>    The migration tool intelligently detects the Mule version (3.x or 4.x) from your project or XML file. However, if automatic detection fails, you can use the <code>--force-version</code> flag to explicitly specify the Mule version for migration.</p> </li> <li> <p>To preserve Mule project structure during conversion:     <pre><code>$ bal migrate-mule /path/to/mule-project --keep-structure\n</code></pre>     By default, the Mule project is converted using the standard Ballerina Integration (BI) file structure. If you use the <code>--keep-structure</code> flag, each Mule config XML file will be converted into a separate <code>.bal</code> file named after the XML file, preserving the original Mule project structure instead of the standard BI layout.</p> </li> <li> <p>To convert with verbose output:     <pre><code>$ bal migrate-mule /path/to/mule-project --verbose\n</code></pre>     This will convert the project with detailed logging during the conversion process.</p> </li> </ol>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#step-3-review-migration-output","title":"Step 3: Review migration output","text":"<ul> <li>By default, a new Ballerina package is created with same source MuleSoft project name or standalone XML file name, appended with a <code>_ballerina</code> suffix, following the standard Ballerina Integration (BI) file structure. The <code>migration_report.html</code> can be found inside the created Ballerina package summarizing the migration.</li> <li>In the <code>--multi-root</code> case, Ballerina packages are generated for each project inside their respective project directories. The <code>migration_report.html</code> can be found inside each Ballerina package summarizing each individual migration, and <code>aggregate_migration_report.html</code> can be found in the root projects directory summarizing all individual project reports.</li> <li>If the <code>--out</code> flag is used, the generated Ballerina package(s) and report(s) can be found in the specified output directory instead of the default location.</li> <li>If the <code>--keep-structure</code> flag is used, each Mule config XML file is converted into a separate <code>.bal</code> file named after the XML file, preserving the original Mule project structure instead of the standard BI layout. Directory structure within the Mule config directory is reflected in the corresponding <code>.bal</code> file name.</li> <li>If the <code>--dry-run</code> flag is used, no Ballerina package is generated. Instead, a detailed migration assessment report (<code>migration_report.html</code> or <code>aggregate_migration_report.html</code> for multi-root) is produced.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#step-4-review-the-migration-summary","title":"Step 4: Review the migration summary","text":"<ul> <li>The migration assessment/summary report provides the following percentages:<ol> <li>Component Conversion Percentage - Shows the proportion of MuleSoft components successfully converted to Ballerina.</li> <li>DataWeave Conversion Percentage - Reflects the success rate of converting DataWeave scripts.</li> <li>Overall Project Conversion Percentage \u2013 Combines both component and DataWeave conversion rates to indicate the total migration success.</li> </ol> </li> <li>The report includes a Manual Work Estimation section, which provides an estimated time required to review the migrated code, address TODOs, and complete the migration process.</li> <li>The report also features sections for Element Blocks that Require Manual Conversion and DataWeave Expressions that Require Manual Conversion, listing all Mule component blocks and DataWeave scripts unsupported by the current tool version and requiring manual conversion. These items are marked as TODOs in the appropriate locations within the generated Ballerina package, unless you use the <code>--dry-run</code> option, which only generates the report without producing code.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#step-5-address-the-todo-items","title":"Step 5: Address the TODO items","text":"<p>During conversion, if there are any unsupported Mule XML tags, they are included in the generated Ballerina code as TODO comments. You may need to do the conversion for them manually.</p> <pre><code>public function endpoint(Context ctx) returns http:Response|error {\n\n    // TODO: UNSUPPORTED MULE BLOCK ENCOUNTERED. MANUAL CONVERSION REQUIRED.\n    // ------------------------------------------------------------------------\n    // &lt;db:select-unsupported config-ref=\"MySQL_Configuration\" xmlns:doc=\"http://www.mulesoft.org/schema/mule/documentation\" doc:name=\"Database\" xmlns:db=\"http://www.mulesoft.org/schema/mule/db\"&gt;\n    //             &lt;db:parameterized-query&gt;&lt;![CDATA[SELECT * from users;]]&gt;&lt;/db:parameterized-query&gt;\n    //         &lt;/db:select-unsupported&gt;\n    // ------------------------------------------------------------------------\n\n    log:printInfo(string `Users details: ${ctx.payload.toString()}`);\n\n    ctx.inboundProperties.response.setPayload(ctx.payload);\n    return ctx.inboundProperties.response;\n}\n</code></pre>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#example-converting-a-standalone-mule-xml-file","title":"Example: Converting a standalone Mule XML file","text":"<p>Let's walk through an example of migrating a MuleSoft standalone sample <code>.xml</code> configuration to Ballerina.</p> <p>Here's a sample MuleSoft XML file (<code>users-database-query.xml</code>) that gets invoked via an HTTP listener and performs a database operation:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n\n&lt;mule xmlns:db=\"http://www.mulesoft.org/schema/mule/db\" xmlns:json=\"http://www.mulesoft.org/schema/mule/json\" xmlns:tracking=\"http://www.mulesoft.org/schema/mule/ee/tracking\" xmlns:http=\"http://www.mulesoft.org/schema/mule/http\" xmlns=\"http://www.mulesoft.org/schema/mule/core\" xmlns:doc=\"http://www.mulesoft.org/schema/mule/documentation\"\nxmlns:spring=\"http://www.springframework.org/schema/beans\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-current.xsd\nhttp://www.mulesoft.org/schema/mule/core http://www.mulesoft.org/schema/mule/core/current/mule.xsd\nhttp://www.mulesoft.org/schema/mule/http http://www.mulesoft.org/schema/mule/http/current/mule-http.xsd\nhttp://www.mulesoft.org/schema/mule/ee/tracking http://www.mulesoft.org/schema/mule/ee/tracking/current/mule-tracking-ee.xsd\nhttp://www.mulesoft.org/schema/mule/db http://www.mulesoft.org/schema/mule/db/current/mule-db.xsd\nhttp://www.mulesoft.org/schema/mule/json http://www.mulesoft.org/schema/mule/json/current/mule-json.xsd\"&gt;\n&lt;http:listener-config name=\"config\" host=\"0.0.0.0\" port=\"8081\"  doc:name=\"HTTP Listener Configuration\" basePath=\"demo\"/&gt;\n&lt;db:mysql-config name=\"MySQL_Configuration\" host=\"localhost\" port=\"3306\" user=\"root\" password=\"admin123\" database=\"test_db\" doc:name=\"MySQL Configuration\"/&gt;\n&lt;flow name=\"demoFlow\"&gt;\n&lt;http:listener config-ref=\"config\" path=\"/users\" allowedMethods=\"GET\" doc:name=\"HTTP\"/&gt;\n&lt;db:select config-ref=\"MySQL_Configuration\" doc:name=\"Database\"&gt;\n&lt;db:parameterized-query&gt;&lt;![CDATA[SELECT * FROM users;]]&gt;&lt;/db:parameterized-query&gt;\n&lt;/db:select&gt;\n&lt;/flow&gt;\n&lt;/mule&gt;\n</code></pre>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#run-the-migration-tool","title":"Run the Migration Tool","text":"<p>To convert the Mule XML file using the <code>migrate-mule</code> tool execute the following command:</p> <pre><code>$ bal migrate-mule /path/to/users-database-query.xml --force-version 3\n</code></pre>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#examine-the-generated-ballerina-code","title":"Examine the Generated Ballerina Code","text":"<p>The tool generates a Ballerina package named <code>users-database-query-ballerina</code> inside <code>/path/to</code> with the following structure (Standard BI layout):</p> <pre><code>users-database-query-ballerina/\n\u251c\u2500\u2500 Ballerina.toml\n\u251c\u2500\u2500 Config.toml\n\u251c\u2500\u2500 configs.bal\n\u251c\u2500\u2500 connections.bal\n\u251c\u2500\u2500 functions.bal\n\u251c\u2500\u2500 main.bal\n\u251c\u2500\u2500 types.bal\n\u2514\u2500\u2500 migration_report.html\n</code></pre> <p>The bal file contains the Ballerina translation of the original MuleSoft XML configuration. It sets up an HTTP service that listens on port 8081 and responds to <code>GET</code> <code>/users</code> requests by querying the MySQL database and returning the results as the response payload.</p> <p>For illustration purposes, the combined code from multiple Ballerina files in the package is summarized below.</p> <pre><code>import ballerina/http;\nimport ballerina/sql;\nimport ballerinax/mysql;\nimport ballerinax/mysql.driver as _;\n\npublic type Record record {\n};\n\nmysql:Client MySQL_Configuration = check new (\"localhost\", \"root\", \"admin123\", \"test_db\", 3306);\npublic listener http:Listener config = new (8081);\n\nservice /demo on config {\n    Context ctx;\n\n    function init() {\n        self.ctx = {payload: (), inboundProperties: {response: new, request: new, uriParams: {}}};\n    }\n\n    resource function get users(http:Request request) returns http:Response|error {\n        self.ctx.inboundProperties.request = request;\n        return invokeEndPoint0(self.ctx);\n    }\n}\n\npublic function invokeEndPoint0(Context ctx) returns http:Response|error {\n\n    // database operation\n    sql:ParameterizedQuery dbQuery0 = `SELECT * FROM users;`;\n    stream&lt;Record, sql:Error?&gt; dbStream0 = MySQL_Configuration-&gt;query(dbQuery0);\n    Record[] dbSelect0 = check from Record _iterator_ in dbStream0\n        select _iterator_;\n    ctx.payload = dbSelect0;\n\n    ctx.inboundProperties.response.setPayload(ctx.payload);\n    return ctx.inboundProperties.response;\n}\n</code></pre> <p>You can check out the <code>migration_report.html</code> for overview of the migration.</p> <p>This example demonstrates how to migrate a MuleSoft application that performs database operations to Ballerina using the migration tool. The migration tool automatically converts the database configuration and SQL query to the equivalent Ballerina code using the <code>ballerinax/mysql</code> module.</p>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#supported-mule-components","title":"Supported Mule components","text":"<p>The migration tool currently supports a wide range of Mule components for both Mule 3.x and Mule 4.x. For a full list of supported components and their mappings, see: - Mule 3.x Components - Mule 4.x Components</p>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#supported-dataweave-transformations","title":"Supported DataWeave Transformations","text":"<p>The migration tool supports both DataWeave 1.0 (Mule 3.x) and DataWeave 2.0 (Mule 4.x) transformations. For details and conversion samples, see: - DataWeave 1.0 Mappings - DataWeave 2.0 Mappings</p>"},{"location":"developer-guides/tools/migration-tools/mulesoft-migration-tool/#limitations","title":"Limitations","text":"<ul> <li>Some moderate to advanced MuleSoft features may require manual adjustments after migration.</li> </ul> Disclaimer<p>MuleSoft: \"MuleSoft\", Mulesoft's \"Anypoint Platform\", and \"DataWeave\" are trademarks of MuleSoft LLC, a Salesforce company. All product, company names and marks mentioned herein are the property of their respective owners and are mentioned for identification purposes only.</p>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/","title":"TIBCO BusinessWorks Migration Tool","text":"<p>This guide explains how to use the migrate-tibco tool to convert TIBCO BusinessWorks integrations into Ballerina packages compatible with the WSO2 Integrator: BI.</p>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#tool-overview","title":"Tool overview","text":"<p>The tool accepts either a BusinessWorks project directory or a standalone process file as input and generates an equivalent Ballerina package that can be opened in the BI.</p>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#installation","title":"Installation","text":"<p>Execute the command below to pull the <code>migrate-tibco</code> tool from Ballerina Central <pre><code>$ bal tool pull migrate-tibco\n</code></pre></p>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#usage","title":"Usage","text":""},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#command-syntax","title":"Command syntax","text":"<pre><code>$ bal migrate-tibco &lt;source-project-directory-or-file&gt; [-o|--out &lt;output-directory&gt;] [-k|--keep-structure] [-v|--verbose] [-d|--dry-run] [-m|--multi-root]\n</code></pre>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#parameters","title":"Parameters","text":"<ul> <li>source-project-directory-or-file - Required. The TIBCO BusinessWorks project directory or process file needs to be migrated.</li> <li>-o or --out - Optional. The directory where the new Ballerina package will be created. If the directory does not exist, the tool will create it for you. If not provided,</li> <li>If source-project-directory-or-file is a directory it will create new directory named <code>${source-project-directory-or-file}_converted</code> in the root of source-project-directory-or-file.</li> <li>if source-project-directory-or-file is a file, it will create a new directory named <code>${root}_converted</code> in the parent of the root directory where root is the directory containing the given file.</li> <li>-k or --keep-structure - Optional. If specified, preserves the original process structure during migration. By default, this option is disabled.</li> <li>-v or --verbose - Optional. Enable verbose output during conversion.</li> <li>-d or --dry-run - Optional. Run the parsing and analysis phases and generate the <code>report.html</code> file without generating the Ballerina package.</li> <li>-m or --multi-root - Optional. Treat each child directory as a separate project and convert all of them. The source must be a directory containing multiple TIBCO projects.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#examples","title":"Examples","text":""},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#migrating-tibco-businessworks-5-process","title":"Migrating TIBCO BusinessWorks 5 process","text":""},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-1-pull-the-migration-tool","title":"Step 1: Pull the migration tool","text":"<ol> <li> <p>Pull <code>migrate-tibco</code> tool for Ballerina Central using the following command.</p> <pre><code>$ bal tool pull migrate-tibco\n</code></pre> </li> </ol>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-2-run-the-migration-tool","title":"Step 2: Run the migration tool","text":"<ol> <li> <p>Create new directory named <code>tibco-hello-world</code> with following two files.</p> helloworld.process<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;pd:ProcessDefinition xmlns:pd=\"http://xmlns.tibco.com/bw/process/2003\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:ns=\"http://www.tibco.com/pe/EngineTypes\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"&gt;\n&lt;pd:name&gt;Processes/simpleResponse&lt;/pd:name&gt;\n&lt;pd:startName&gt;HTTP Receiver&lt;/pd:startName&gt;\n&lt;pd:starter name=\"HTTP Receiver\"&gt;\n&lt;pd:type&gt;com.tibco.plugin.http.HTTPEventSource&lt;/pd:type&gt;\n&lt;pd:resourceType&gt;httppalette.httpEventSource&lt;/pd:resourceType&gt;\n&lt;config&gt;\n&lt;outputMode&gt;String&lt;/outputMode&gt;\n&lt;inputOutputVersion&gt;5.3.0&lt;/inputOutputVersion&gt;\n&lt;sharedChannel&gt;GeneralConnection.sharedhttp&lt;/sharedChannel&gt;\n&lt;parsePostData&gt;true&lt;/parsePostData&gt;\n&lt;Headers/&gt;\n&lt;/config&gt;\n&lt;pd:inputBindings/&gt;\n&lt;/pd:starter&gt;\n&lt;pd:endName&gt;End&lt;/pd:endName&gt;\n&lt;pd:errorSchemas/&gt;\n&lt;pd:processVariables/&gt;\n&lt;pd:targetNamespace&gt;http://xmlns.example.com/simpleResponse&lt;/pd:targetNamespace&gt;\n&lt;pd:activity name=\"HTTP Response\"&gt;\n&lt;pd:type&gt;com.tibco.plugin.http.HTTPResponseActivity&lt;/pd:type&gt;\n&lt;pd:resourceType&gt;httppalette.httpResponseActivity&lt;/pd:resourceType&gt;\n&lt;config&gt;\n&lt;responseHeader&gt;\n&lt;header name=\"Content-Type\"&gt;text/xml; charset=UTF-8&lt;/header&gt;\n&lt;/responseHeader&gt;\n&lt;httpResponseCode&gt;200&lt;/httpResponseCode&gt;\n&lt;/config&gt;\n&lt;pd:inputBindings&gt;\n&lt;ResponseActivityInput&gt;\n&lt;asciiContent&gt;\n&lt;response&gt;hello world&lt;/response&gt;\n&lt;/asciiContent&gt;\n&lt;/ResponseActivityInput&gt;\n&lt;/pd:inputBindings&gt;\n&lt;/pd:activity&gt;\n\n&lt;pd:transition&gt;\n&lt;pd:from&gt;HTTP Receiver&lt;/pd:from&gt;\n&lt;pd:to&gt;HTTP Response&lt;/pd:to&gt;\n&lt;pd:lineType&gt;Default&lt;/pd:lineType&gt;\n&lt;/pd:transition&gt;\n\n&lt;pd:transition&gt;\n&lt;pd:from&gt;HTTP Response&lt;/pd:from&gt;\n&lt;pd:to&gt;End&lt;/pd:to&gt;\n&lt;pd:lineType&gt;Default&lt;/pd:lineType&gt;\n&lt;/pd:transition&gt;\n&lt;/pd:ProcessDefinition&gt;\n</code></pre> GeneralConnection.sharedhttp<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;ns0:httpSharedResource xmlns:ns0=\"www.tibco.com/shared/HTTPConnection\"&gt;\n&lt;config&gt;\n&lt;Host&gt;localhost&lt;/Host&gt;\n&lt;Port&gt;9090&lt;/Port&gt;\n&lt;/config&gt;\n&lt;/ns0:httpSharedResource&gt;\n</code></pre> </li> <li> <p>Execute the following command. This will create the <code>converted</code> directory and create a Ballerina package inside it.</p> <pre><code>bal migrate-tibco &lt;tibco-hello-world&gt; -o converted\n</code></pre> </li> </ol>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-3-open-in-bi","title":"Step 3: Open in BI","text":"<ol> <li>Open VS Code inside the <code>converted</code> directory     <pre><code>$ code ./converted\n</code></pre></li> <li>Click the BI icon on the left side bar to open the Ballerina package in BI.</li> </ol>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#migrating-tibco-businessworks-6-process","title":"Migrating TIBCO BusinessWorks 6 process","text":""},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-1-pull-the-migration-tool_1","title":"Step 1: Pull the migration tool","text":"<ol> <li> <p>Pull <code>migrate-tibco</code> tool for Ballerina Central using the following command.</p> <pre><code>$ bal tool pull migrate-tibco\n</code></pre> </li> </ol>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-2-run-the-migration-tool_1","title":"Step 2: Run the migration tool","text":"<ol> <li> <p>Create new directory named <code>tibco-hello-world</code> with following process file.</p> main.bwp<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;bpws:process exitOnStandardFault=\"no\"\nname=\"test.api.MainProcess\" suppressJoinFailure=\"yes\"\ntargetNamespace=\"http://xmlns.example.com/test/api\"\nxmlns:bpws=\"http://docs.oasis-open.org/wsbpel/2.0/process/executable\"\nxmlns:info=\"http://www.tibco.com/bw/process/info\"\nxmlns:ns=\"http://www.tibco.com/pe/EngineTypes\"\nxmlns:ns0=\"http://xmlns.example.com/test/api/wsdl\"\nxmlns:ns1=\"http://xmlns.example.com/test/api\"\nxmlns:sca=\"http://docs.oasis-open.org/ns/opencsa/sca/200912\"\nxmlns:sca-bpel=\"http://docs.oasis-open.org/ns/opencsa/sca-bpel/200801\"\nxmlns:tibex=\"http://www.tibco.com/bpel/2007/extensions\"\nxmlns:tibprop=\"http://ns.tibco.com/bw/property\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"&gt;\n&lt;tibex:Types&gt;\n&lt;xs:schema attributeFormDefault=\"unqualified\"\nelementFormDefault=\"qualified\"\ntargetNamespace=\"http://www.tibco.com/pe/EngineTypes\"\nxmlns:tns=\"http://www.tibco.com/pe/EngineTypes\" xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"&gt;\n&lt;xs:complexType block=\"extension restriction\"\nfinal=\"extension restriction\" name=\"ProcessContext\"&gt;\n&lt;xs:sequence&gt;\n&lt;xs:element\nblock=\"extension restriction substitution\"\nform=\"unqualified\" name=\"JobId\" type=\"xs:string\"/&gt;\n&lt;xs:element\nblock=\"extension restriction substitution\"\nform=\"unqualified\" name=\"ApplicationName\" type=\"xs:string\"/&gt;\n&lt;xs:element\nblock=\"extension restriction substitution\"\nform=\"unqualified\" name=\"EngineName\" type=\"xs:string\"/&gt;\n&lt;xs:element\nblock=\"extension restriction substitution\"\nform=\"unqualified\" name=\"ProcessInstanceId\" type=\"xs:string\"/&gt;\n&lt;xs:element\nblock=\"extension restriction substitution\"\nform=\"unqualified\" minOccurs=\"0\"\nname=\"CustomJobId\" type=\"xs:string\"/&gt;\n&lt;xs:element\nblock=\"extension restriction substitution\"\nform=\"unqualified\" maxOccurs=\"unbounded\"\nminOccurs=\"0\" name=\"TrackingInfo\" type=\"xs:string\"/&gt;\n&lt;/xs:sequence&gt;\n&lt;/xs:complexType&gt;\n&lt;xs:element block=\"extension restriction substitution\"\nfinal=\"extension restriction\" name=\"ProcessContext\" type=\"tns:ProcessContext\"/&gt;\n&lt;/xs:schema&gt;\n&lt;xs:schema attributeFormDefault=\"unqualified\"\nelementFormDefault=\"qualified\"\ntargetNamespace=\"http://xmlns.example.com/test/api\"\nxmlns:tns=\"http://xmlns.example.com/test/api\" xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"&gt;\n&lt;xs:complexType name=\"TestRequestType\"&gt;\n&lt;xs:sequence&gt;\n&lt;xs:element name=\"request\" type=\"xs:string\"/&gt;\n&lt;/xs:sequence&gt;\n&lt;/xs:complexType&gt;\n&lt;xs:complexType name=\"TestResponseType\"&gt;\n&lt;xs:sequence&gt;\n&lt;xs:element name=\"response\" type=\"xs:string\"/&gt;\n&lt;/xs:sequence&gt;\n&lt;/xs:complexType&gt;\n&lt;xs:element name=\"TestRequest\" type=\"tns:TestRequestType\"/&gt;\n&lt;xs:element name=\"TestResponse\" type=\"tns:TestResponseType\"/&gt;\n&lt;/xs:schema&gt;\n&lt;wsdl:definitions\ntargetNamespace=\"http://xmlns.example.com/test/api/wsdl\"\nxmlns:extns=\"http://tns.tibco.com/bw/REST\"\nxmlns:extns1=\"http://xmlns.example.com/test/api\"\nxmlns:plnk=\"http://docs.oasis-open.org/wsbpel/2.0/plnktype\"\nxmlns:tibex=\"http://www.tibco.com/bpel/2007/extensions\"\nxmlns:tns=\"http://xmlns.example.com/test/api/wsdl\"\nxmlns:vprop=\"http://docs.oasis-open.org/wsbpel/2.0/varprop\"\nxmlns:wsdl=\"http://schemas.xmlsoap.org/wsdl/\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"&gt;\n&lt;plnk:partnerLinkType name=\"partnerLinkType\"&gt;\n&lt;plnk:role name=\"use\" portType=\"tns:testapi\"/&gt;\n&lt;/plnk:partnerLinkType&gt;\n&lt;wsdl:import namespace=\"http://tns.tibco.com/bw/REST\"/&gt;\n&lt;wsdl:import namespace=\"http://xmlns.example.com/test/api\"/&gt;\n&lt;wsdl:message name=\"postRequest\"&gt;\n&lt;wsdl:part element=\"extns1:TestRequest\"\nname=\"item\" tibex:hasMultipleNamespaces=\"false\"/&gt;\n&lt;wsdl:part element=\"extns:httpHeaders\"\nname=\"httpHeaders\" tibex:source=\"bw.rest\"/&gt;\n&lt;/wsdl:message&gt;\n&lt;wsdl:message name=\"postResponse\"&gt;\n&lt;wsdl:part element=\"extns1:TestResponse\"\nname=\"item\" tibex:hasMultipleNamespaces=\"false\"/&gt;\n&lt;/wsdl:message&gt;\n&lt;wsdl:message name=\"post4XXFaultMessage\"&gt;\n&lt;wsdl:part element=\"extns:client4XXError\" name=\"clientError\"/&gt;\n&lt;/wsdl:message&gt;\n&lt;wsdl:message name=\"post5XXFaultMessage\"&gt;\n&lt;wsdl:part element=\"extns:server5XXError\" name=\"serverError\"/&gt;\n&lt;/wsdl:message&gt;\n&lt;wsdl:portType name=\"testapi\"\ntibex:bw.rest.apipath=\"/test\"\ntibex:bw.rest.basepath=\"TestAPI\"\ntibex:bw.rest.resource=\"Service Descriptors/test.api.MainProcess-TestAPI.json\"\ntibex:bw.rest.resource.source=\"generated\" tibex:source=\"bw.rest.service\"&gt;\n&lt;wsdl:documentation&gt;Simple REST API with test endpoint.&lt;/wsdl:documentation&gt;\n&lt;wsdl:operation name=\"post\"&gt;\n&lt;wsdl:input message=\"tns:postRequest\" name=\"postInput\"/&gt;\n&lt;wsdl:output message=\"tns:postResponse\" name=\"postOutput\"/&gt;\n&lt;wsdl:fault message=\"tns:post4XXFaultMessage\" name=\"clientFault\"/&gt;\n&lt;wsdl:fault message=\"tns:post5XXFaultMessage\" name=\"serverFault\"/&gt;\n&lt;/wsdl:operation&gt;\n&lt;/wsdl:portType&gt;\n&lt;/wsdl:definitions&gt;\n&lt;/tibex:Types&gt;\n&lt;tibex:ProcessInfo callable=\"false\" createdBy=\"heshan\"\ncreatedOn=\"Mon Dec 16 00:00:00 PST 2024\" description=\"\"\nextraErrorVars=\"true\" modifiers=\"public\"\nproductVersion=\"6.5.0 V63 2018-08-08\" scalable=\"true\"\nsingleton=\"true\" stateless=\"true\" type=\"IT\"/&gt;\n&lt;tibex:ProcessInterface context=\"\" input=\"\" output=\"\"/&gt;\n&lt;tibex:ProcessTemplateConfigurations/&gt;\n&lt;tibex:NamespaceRegistry enabled=\"true\"&gt;\n&lt;tibex:namespaceItem\nnamespace=\"http://xmlns.example.com/test/api\" prefix=\"tns\"/&gt;\n&lt;tibex:namespaceItem\nnamespace=\"http://xmlns.example.com/test/api/wsdl\" prefix=\"tns1\"/&gt;\n&lt;/tibex:NamespaceRegistry&gt;\n&lt;bpws:import importType=\"http://www.w3.org/2001/XMLSchema\" namespace=\"http://tns.tibco.com/bw/REST\"/&gt;\n&lt;bpws:import importType=\"http://www.w3.org/2001/XMLSchema\" namespace=\"http://xmlns.example.com/test/api\"/&gt;\n&lt;bpws:partnerLinks&gt;\n&lt;bpws:partnerLink myRole=\"use\" name=\"testapi\"\npartnerLinkType=\"ns0:partnerLinkType\"\nsca-bpel:ignore=\"false\" sca-bpel:service=\"testapi\"/&gt;\n&lt;/bpws:partnerLinks&gt;\n&lt;bpws:variables&gt;\n&lt;bpws:variable element=\"ns:ProcessContext\"\nname=\"_processContext\" sca-bpel:internal=\"true\"/&gt;\n&lt;bpws:variable messageType=\"ns0:postRequest\" name=\"post\" sca-bpel:internal=\"true\"/&gt;\n&lt;bpws:variable messageType=\"ns0:postResponse\"\nname=\"postOut-input\" sca-bpel:internal=\"true\"/&gt;\n&lt;bpws:variable element=\"ns1:TestResponse\" name=\"RenderOutput-output\" sca-bpel:internal=\"true\"/&gt;\n&lt;/bpws:variables&gt;\n&lt;bpws:extensions&gt;\n&lt;bpws:extension mustUnderstand=\"no\" namespace=\"http://www.eclipse.org/gmf/runtime/1.0.2/notation\"/&gt;\n&lt;bpws:extension mustUnderstand=\"no\" namespace=\"http://www.tibco.com/bw/process/info\"/&gt;\n&lt;bpws:extension mustUnderstand=\"no\" namespace=\"http://docs.oasis-open.org/ns/opencsa/sca-bpel/200801\"/&gt;\n&lt;bpws:extension mustUnderstand=\"no\" namespace=\"http://docs.oasis-open.org/ns/opencsa/sca/200912\"/&gt;\n&lt;bpws:extension mustUnderstand=\"no\" namespace=\"http://ns.tibco.com/bw/property\"/&gt;\n&lt;bpws:extension mustUnderstand=\"no\" namespace=\"http://www.tibco.com/bpel/2007/extensions\"/&gt;\n&lt;/bpws:extensions&gt;\n&lt;bpws:scope name=\"scope\"&gt;\n&lt;bpws:flow name=\"flow\"&gt;\n&lt;bpws:links/&gt;\n&lt;bpws:pick createInstance=\"yes\" name=\"pick\"&gt;\n&lt;bpws:onMessage operation=\"post\"\npartnerLink=\"testapi\"\nportType=\"ns0:testapi\"\nvariable=\"post\"&gt;\n&lt;bpws:scope name=\"scope1\"&gt;\n&lt;bpws:flow name=\"flow1\"&gt;\n&lt;bpws:links&gt;\n&lt;bpws:link name=\"JSONPayloadOut\" tibex:linkType=\"SUCCESS\"/&gt;\n&lt;/bpws:links&gt;\n&lt;bpws:extensionActivity&gt;\n&lt;tibex:activityExtension name=\"RenderOutput\" outputVariable=\"RenderOutput\"\nxmlns:tibex=\"http://www.tibco.com/bpel/2007/extensions\"&gt;\n&lt;bpws:targets/&gt;\n&lt;bpws:sources&gt;\n&lt;bpws:source linkName=\"JSONPayloadOut\"/&gt;\n&lt;/bpws:sources&gt;\n&lt;tibex:inputBindings&gt;\n&lt;tibex:inputBinding expression=\"&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt;&amp;#xa;&amp;lt;xsl:stylesheet xmlns:xsl=&amp;quot;http://www.w3.org/1999/XSL/Transform&amp;quot; xmlns:tns=&amp;quot;http://xmlns.example.com/test/api&amp;quot; version=&amp;quot;2.0&amp;quot;&gt;&amp;#xa;    &amp;lt;xsl:template name=&amp;quot;RenderOutput-input&amp;quot; match=&amp;quot;/&amp;quot;&gt;&amp;#xa;        &amp;lt;tns:TestResponse&gt;&amp;#xa;            &amp;lt;tns:response&gt;Hello world&amp;lt;/tns:response&gt;&amp;#xa;        &amp;lt;/tns:TestResponse&gt;&amp;#xa;    &amp;lt;/xsl:template&gt;&amp;#xa;&amp;lt;/xsl:stylesheet&gt;\" expressionLanguage=\"urn:oasis:names:tc:wsbpel:2.0:sublang:xslt1.0\"/&gt;\n&lt;/tibex:inputBindings&gt;\n&lt;tibex:config&gt;\n&lt;bwext:BWActivity activityTypeID=\"bw.restjson.JsonRender\"\nxmlns:activityconfig=\"http://tns.tibco.com/bw/model/activityconfig\"\nxmlns:bwext=\"http://tns.tibco.com/bw/model/core/bwext\"\nxmlns:restjson=\"http://ns.tibco.com/bw/palette/restjson\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt;\n&lt;activityConfig&gt;\n&lt;properties name=\"config\" xsi:type=\"activityconfig:EMFProperty\"&gt;\n&lt;type href=\"http://ns.tibco.com/bw/palette/restjson#//JsonRender\"/&gt;\n&lt;value jsonOutputStyle=\"None\" schemaType=\"Xsd\" xsi:type=\"restjson:JsonRender\"&gt;\n&lt;inputEditorElement href=\"Schema.xsd#//TestResponse;XSDElementDeclaration\"/&gt;\n&lt;/value&gt;\n&lt;/properties&gt;\n&lt;/activityConfig&gt;\n&lt;/bwext:BWActivity&gt;\n&lt;/tibex:config&gt;\n&lt;/tibex:activityExtension&gt;\n&lt;/bpws:extensionActivity&gt;\n&lt;bpws:extensionActivity&gt;\n&lt;tibex:activityExtension\ninputVariable=\"RenderOutput\"\nname=\"SendHTTPResponse\"\nxmlns:tibex=\"http://www.tibco.com/bpel/2007/extensions\"&gt;\n&lt;bpws:targets&gt;\n&lt;bpws:target linkName=\"JSONPayloadOut\"/&gt;\n&lt;/bpws:targets&gt;\n&lt;tibex:inputBindings&gt;\n&lt;tibex:inputBinding\nexpression=\"&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt;&amp;#xa;&amp;lt;xsl:stylesheet xmlns:xsl=&amp;quot;http://www.w3.org/1999/XSL/Transform&amp;quot; xmlns:tns1=&amp;quot;http://tns.tibco.com/bw/activity/sendhttpresponse/xsd/input+3847aa9b-8275-4b15-9ea8-812816768fa4+ResponseActivityInput&amp;quot; version=&amp;quot;2.0&amp;quot;&gt;&amp;#xa;    &amp;lt;xsl:template name=&amp;quot;SendHTTPResponse-input&amp;quot; match=&amp;quot;/&amp;quot;&gt;&amp;#xa;        &amp;lt;tns1:ResponseActivityInput&gt;&amp;#xa;            &amp;lt;asciiContent&gt;&amp;#xa;                &amp;lt;xsl:value-of select=&amp;quot;/jsonString&amp;quot;/&gt;&amp;#xa;            &amp;lt;/asciiContent&gt;&amp;#xa;            &amp;lt;Headers&gt;&amp;#xa;                &amp;lt;Content-Type&gt;&amp;#xa;                    &amp;lt;xsl:value-of select=&amp;quot;&amp;amp;quot;application/json&amp;amp;quot;&amp;quot;/&gt;&amp;#xa;                &amp;lt;/Content-Type&gt;&amp;#xa;            &amp;lt;/Headers&gt;&amp;#xa;        &amp;lt;/tns1:ResponseActivityInput&gt;&amp;#xa;    &amp;lt;/xsl:template&gt;&amp;#xa;&amp;lt;/xsl:stylesheet&gt;\"\nexpressionLanguage=\"urn:oasis:names:tc:wsbpel:2.0:sublang:xslt1.0\"/&gt;\n&lt;/tibex:inputBindings&gt;\n&lt;tibex:config&gt;\n&lt;bwext:BWActivity\nactivityTypeID=\"bw.http.sendHTTPResponse\"\nversion=\"6.0.0.20132205\"\nxmlns:ResponseActivityInput=\"http://tns.tibco.com/bw/activity/sendhttpresponse/xsd/input+3847aa9b-8275-4b15-9ea8-812816768fa4+ResponseActivityInput\"\nxmlns:activityconfig=\"http://tns.tibco.com/bw/model/activityconfig\"\nxmlns:bwext=\"http://tns.tibco.com/bw/model/core/bwext\"\nxmlns:http=\"http://ns.tibco.com/bw/palette/http\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt;\n&lt;activityConfig&gt;\n&lt;properties name=\"config\" xsi:type=\"activityconfig:EMFProperty\"&gt;\n&lt;type href=\"http://ns.tibco.com/bw/palette/http#//SendHTTPResponse\"/&gt;\n&lt;value closeConnection=\"true\"\ninputHeadersQName=\"ResponseActivityInput:headersType\"\nreplyFor=\"HTTPReceiver\" xsi:type=\"http:SendHTTPResponse\"/&gt;\n&lt;/properties&gt;\n&lt;/activityConfig&gt;\n&lt;/bwext:BWActivity&gt;\n&lt;/tibex:config&gt;\n&lt;/tibex:activityExtension&gt;\n&lt;/bpws:extensionActivity&gt;\n&lt;/bpws:flow&gt;\n&lt;/bpws:scope&gt;\n&lt;/bpws:onMessage&gt;\n&lt;/bpws:pick&gt;\n&lt;/bpws:flow&gt;\n&lt;/bpws:scope&gt;\n&lt;/bpws:process&gt;\n</code></pre> </li> <li> <p>Execute the following command. This will create the <code>converted</code> directory and create a Ballerina package inside it.</p> <pre><code>bal migrate-tibco &lt;tibco-hello-world&gt; -o converted\n</code></pre> </li> </ol>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#step-3-open-in-bi_1","title":"Step 3: Open in BI","text":"<ol> <li>Open VS Code inside the <code>converted</code> directory     <pre><code>$ code ./converted\n</code></pre></li> <li>Click the BI icon on the left side bar to open the Ballerina package in BI.</li> </ol>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#output","title":"Output","text":""},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#migration-summary","title":"Migration summary","text":"<ul> <li>When you run the tool, it will generate <code>report.html</code> file in the output directory with a summary containing information about activities it failed to convert and time estimation for manually converting them.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#limitations","title":"Limitations","text":""},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#ballerina-compiler-version","title":"Ballerina compiler version","text":"<ul> <li>Tool generates code assuming target compiler version is 2201.12.0 or later.</li> </ul>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#unhandled-activities","title":"Unhandled activities","text":"<ul> <li> <p>If the tool encounters any activity which it does not know how to convert it will generate a placeholder \"unhandled\" function with a comment containing the relevant part of the process file.</p> <pre><code>function unhandled(map&lt;xml&gt; context) returns xml|error {\n    //FIXME: [ParseError] : Unknown activity\n    //&lt;bpws:empty name=\"OnMessageStart\" xmlns:tibex=\"http://www.tibco.com/bpel/2007/extensions\" tibex:constructor=\"onMessageStart\" tibex:xpdlId=\"c266c167-7a80-40cc-9db2-60739386deeb\" xmlns:bpws=\"http://docs.oasis-open.org/wsbpel/2.0/process/executable\"/&gt;\n\n    //&lt;bpws:empty name=\"OnMessageStart\" xmlns:tibex=\"http://www.tibco.com/bpel/2007/extensions\" tibex:constructor=\"onMessageStart\" tibex:xpdlId=\"c266c167-7a80-40cc-9db2-60739386deeb\" xmlns:bpws=\"http://docs.oasis-open.org/wsbpel/2.0/process/executable\"/&gt;\n    return xml `&lt;root&gt;&lt;/root&gt;`;\n}\n</code></pre> </li> </ul>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#partially-supported-activities","title":"Partially supported activities","text":"<ul> <li> <p>In case of activities that are only partially supported you will see a log message with the activity name.     <pre><code>WARNING: Partially supported activity: JMS Send\n</code></pre></p> </li> <li> <p>They will also be listed in the report under heading \"Activities that need manual validation\". For most typical use cases, you can use the converted source as is, but we highly encourage users to check the converted code. There will be comments explaining any limitations/assumptions the tool has made.     <pre><code>    // WARNING: using default destination configuration\n    jms:MessageProducer var4 = check var3.createProducer(destination = {\n        'type: jms:TOPIC,\n        name: \"TOPIC\"\n    });\n</code></pre></p> </li> </ul>"},{"location":"developer-guides/tools/migration-tools/tibco-businessworks-migration-tool/#supported-tibco-businessworks-activities","title":"Supported TIBCO BusinessWorks activities","text":"<ul> <li><code>invoke</code></li> <li><code>pick</code></li> <li><code>empty</code></li> <li><code>reply</code></li> <li><code>throw</code></li> <li><code>assign</code></li> <li><code>forEach</code></li> <li><code>extensionActivity</code></li> <li><code>receiveEvent</code></li> <li><code>activityExtension</code><ul> <li><code>bw.internal.end</code></li> <li><code>bw.http.sendHTTPRequest</code></li> <li><code>bw.restjson.JsonRender</code></li> <li><code>bw.restjson.JsonParser</code></li> <li><code>bw.http.sendHTTPResponse</code></li> <li><code>bw.file.write</code></li> <li><code>bw.generalactivities.log</code></li> <li><code>bw.xml.renderxml</code></li> <li><code>bw.generalactivities.mapper</code></li> <li><code>bw.internal.accumulateend</code></li> </ul> </li> <li><code>extActivity</code></li> <li><code>com.tibco.plugin.mapper.MapperActivity</code></li> <li><code>com.tibco.plugin.http.HTTPEventSource</code></li> <li><code>com.tibco.pe.core.AssignActivity</code></li> <li><code>com.tibco.plugin.http.HTTPResponseActivity</code></li> <li><code>com.tibco.plugin.xml.XMLRendererActivity</code></li> <li><code>com.tibco.plugin.xml.XMLParseActivity</code></li> <li><code>com.tibco.pe.core.LoopGroup</code></li> <li><code>com.tibco.pe.core.WriteToLogActivity</code></li> <li><code>com.tibco.pe.core.CatchActivity</code></li> <li><code>com.tibco.plugin.file.FileReadActivity</code></li> <li><code>com.tibco.plugin.file.FileWriteActivity</code></li> <li><code>com.tibco.plugin.jdbc.JDBCGeneralActivity</code></li> <li><code>com.tibco.plugin.json.activities.RestActivity</code></li> <li><code>com.tibco.pe.core.CallProcessActivity</code></li> <li><code>com.tibco.plugin.soap.SOAPSendReceiveActivity</code></li> <li><code>com.tibco.plugin.json.activities.JSONParserActivity</code></li> <li><code>com.tibco.plugin.json.activities.JSONRenderActivity</code></li> <li><code>com.tibco.plugin.soap.SOAPSendReplyActivity</code></li> <li><code>com.tibco.plugin.jms.JMSQueueEventSource</code></li> <li><code>com.tibco.plugin.jms.JMSQueueSendActivity</code></li> <li><code>com.tibco.plugin.jms.JMSQueueGetMessageActivity</code></li> <li><code>com.tibco.plugin.jms.JMSTopicPublishActivity</code></li> <li><code>com.tibco.pe.core.GenerateErrorActivity</code></li> <li><code>com.tibco.plugin.timer.NullActivity</code></li> <li><code>com.tibco.plugin.timer.SleepActivity</code></li> <li><code>com.tibco.pe.core.GetSharedVariableActivity</code></li> <li><code>com.tibco.pe.core.SetSharedVariableActivity</code></li> <li><code>com.tibco.plugin.file.FileEventSource</code></li> <li><code>com.tibco.pe.core.OnStartupEventSource</code></li> <li><code>com.tibco.plugin.file.ListFilesActivity</code></li> <li><code>com.tibco.plugin.xml.XMLTransformActivity</code></li> </ul> Disclaimer<p>TIBCO: \"TIBCO\", \u201cTIBCO BusinessWorks\u201d, and \u201cTIBCO Flogo\u201d are trademarks, or registered trademarks, of TIBCO Software Inc. a business unit of Cloud Software Group. All product, company names and marks mentioned herein are the property of their respective owners and are mentioned for identification purposes only.</p>"},{"location":"get-started/develop-ai-agent/","title":"Develop AI Agent","text":""},{"location":"get-started/develop-ai-agent/#overview","title":"Overview","text":"<p>In this guide, you will: Create a simple AI agent that provides personal assistance. We will define a GraphQL schema with a query that invokes the inline agent to generate dynamic responses based on input parameters. The agent runs within the resolver logic and returns results directly as part of the GraphQL response.</p>"},{"location":"get-started/develop-ai-agent/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have the following:</p> <ul> <li>Visual Studio Code: Install Visual Studio Code if you don't have it already.</li> <li>WSO2 Integrator: BI Extension: Install the WSO2 Integrator: BI extension. Refer to Install WSO2 Integrator: BI for detailed instructions.</li> <li>Get OpenAI key:<ol> <li>Sign up at OpenAI.</li> <li>Get an API key from the API section.</li> </ol> </li> </ul>"},{"location":"get-started/develop-ai-agent/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon in the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>GraphqlService</code>.</li> <li>Select the project directory by clicking on the Select Location button.</li> <li> <p>Click the Create New Integration button to generate the integration project.</p> <p></p> </li> </ol>"},{"location":"get-started/develop-ai-agent/#step-2-create-a-graphql-service","title":"Step 2: Create a GraphQL service","text":"<ol> <li>Click the + button on the WSO2 Integrator: BI side panel or navigate back to the design screen and click on Add Artifact.</li> <li>Select GraphQL Service under the Integration as API artifacts.</li> <li> <p>Keep the default Listener and Service base path configurations, and click Create.</p> <p></p> </li> </ol>"},{"location":"get-started/develop-ai-agent/#step-3-create-a-graphql-resolver","title":"Step 3: Create a GraphQL resolver","text":"<ol> <li>Click the + Create Operations button in the GraphQL design view.</li> <li>In the side panel, click the + button in the Mutation section to add a mutation operation.</li> <li>Provide <code>task</code> as the value for the Field name.</li> <li>Click the Add Argument button to add a GraphQL input<ul> <li>Provide <code>query</code> for the Argument name.</li> <li>Provide <code>string</code> for the Argument type.</li> <li>Click Add to save the argument.</li> </ul> </li> <li> <p>Provide <code>string|error</code> for the Field type, as this will be used as the return type of the resolver.</p> <p></p> </li> </ol>"},{"location":"get-started/develop-ai-agent/#step-4-implement-the-resolving-logic-with-an-inline-agent","title":"Step 4: Implement the resolving logic with an inline agent","text":"<ol> <li>Click the created <code>task</code> operation in the side panel to navigate to the resolver editor view.</li> <li>Click the + button in the flow to open the side panel.</li> <li>Click Agent under Statement, which will navigate you to the agent creation panel.</li> <li>Update Variable Name to <code>response</code>. This is the variable where the agent's output will be stored.</li> <li>Update the Role and Instructions to configure the agent\u2019s behavior.</li> <li>Provide the query parameter as the input for Query. This will serve as the command that the agent will execute.</li> <li>Click Save.</li> <li>Next, configure the agent\u2019s memory, model, and tools. For guidance, refer to the Chat Agent configuration steps and the Personal Assistant setup guide to make the agent function as a personal assistant.</li> <li>After configuring the agent, click the + button on the flow and select Return under Control from the side panel.</li> <li> <p>For the Expression, provide the <code>response</code> variable as the input.</p> <p></p> </li> </ol> <p>At this point, we've created a GraphQL resolver that takes a user-provided <code>query</code> as input, passes it to an inline agent for processing, and returns the agent\u2019s <code>response</code> as the result of the resolver.</p> <p>Note</p> <p>You must implement a query operation to have a valid GraphQL service. Similar to creating the <code>task</code> operation in Step 3, add an operation named <code>greet</code> by pressing the + button in the Query section, without any input parameters. For the implementation, you can simply return a string literal saying <code>\"welcome\"</code>.</p>"},{"location":"get-started/develop-ai-agent/#step-5-run-the-integration-and-query-the-agent","title":"Step 5: Run the integration and query the agent","text":"<ol> <li>Click on the Run button in the top-right corner to run the integration.</li> <li> <p>Query the agent by sending the mutation request below.     <pre><code>curl -X POST http://localhost:8080/graphql \\\n-H \"Content-Type: application/json\" \\\n-d '{ \"query\": \"mutation Task { task(query: \\\"Summarize latest emails\\\") }\" }'\n</code></pre></p> <p></p> </li> </ol>"},{"location":"get-started/develop-automation/","title":"Develop Automation","text":""},{"location":"get-started/develop-automation/#overview","title":"Overview","text":"<p>In this guide, you will create a simple automation that prints <code>\"Hello World\"</code>.</p>"},{"location":"get-started/develop-automation/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have the following:</p> <ul> <li>Visual Studio Code: Install Visual Studio Code if you don't have it already.</li> <li>WSO2 Integrator: BI Extension: Install the WSO2 Integrator: BI extension. Refer to Install WSO2 Integrator: BI for detailed instructions.</li> </ul>"},{"location":"get-started/develop-automation/#step-1-develop-automation-in-wso2-integrator-bi","title":"Step 1: Develop automation in WSO2 Integrator: BI","text":"<ol> <li>In WSO2 Integrator: BI design view, click Add Artifact.</li> <li>Select Automation from the Constructs menu.</li> <li>Click Create to create an automation. This directs you to the automation diagram view.</li> <li>Click + after the Start node to open the node panel.</li> <li>Select Call Function and select println.</li> <li>Click + Add Another Value, type <code>\"Hello World\"</code> and click Save.</li> </ol>"},{"location":"get-started/develop-automation/#step-2-run-automation-in-wso2-integrator-bi","title":"Step 2: Run automation in WSO2 Integrator: BI","text":"<ol> <li> <p>Click Run in the top right corner to run the automation. This compiles the automation and runs it in the embedded Ballerina runtime.</p> <p></p> </li> </ol>"},{"location":"get-started/develop-event-integration/","title":"Develop Event Integration","text":""},{"location":"get-started/develop-event-integration/#overview","title":"Overview","text":"<p>In this guide, you will build a simple event integration that monitors RabbitMQ for new messages and displays them once they become available.</p>"},{"location":"get-started/develop-event-integration/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have the following:</p> <ul> <li>Visual Studio Code: Install Visual Studio Code if you don't have it already.</li> <li>WSO2 Integrator: BI Extension: Install the WSO2 Integrator: BI extension. Refer to Install WSO2 Integrator: BI for detailed instructions.</li> <li>Set up RabbitMQ:<ol> <li>Use an existing RabbitMQ instance or start a new RabbitMQ instance on a server that can be accessed via the internet.</li> <li>Obtain the <code>host</code>, <code>port</code>, <code>username</code>, and <code>password</code> from the RabbitMQ instance.</li> </ol> </li> </ul>"},{"location":"get-started/develop-event-integration/#step-1-develop-event-integration-in-wso2-integrator-bi","title":"Step 1: Develop Event Integration in WSO2 Integrator: BI","text":"<ol> <li>In WSO2 Integrator: BI design view, click Add Artifact.</li> <li>Select Event Integration from the Constructs menu.</li> <li>Click Create to create an event integration. This directs you to the event integration diagram view.</li> <li> <p>From the left side panel, click + on the Configurations, and add the following configurables.</p> Configurable Type <code>host</code> <code>string</code> <code>port</code> <code>int</code> <code>username</code> <code>string</code> <code>password</code> <code>string</code> <p></p> </li> <li> <p>Go to the Design View by clicking the Home icon on the top left corner and click Add Artifact.</p> </li> <li>Select RabbitMQ Event Handler. Choosing the Event Integration from the Devant console disables the other options.</li> <li>Provide the name of the RabbitMQ Configuration as <code>eventListener</code>.</li> <li>Select previously defined <code>host</code> and <code>port</code> configuration variables for the Host and Port.</li> <li> <p>Then, expand the Advanced Configurations and enter the following configurables. Then click Next.</p> Field Value username <code>username</code> password <code>password</code> </li> <li> <p>Add <code>Orders</code> as the Queue Name and click Create. If there is no queue named <code>Orders</code> in RabbitMQ server, this will create a new queue with this name. </p> <p></p> </li> <li> <p>In the Design view, click the <code>onMessage</code> function box. It will redirect you to the flow diagram view.</p> </li> <li>Click the plus icon after the Start node to open the node panel.</li> <li> <p>Add a Log Info node with the Msg as <code>message.toString()</code>. </p> <p></p> </li> </ol>"},{"location":"get-started/develop-event-integration/#step-2-run-the-integration-in-wso2-integrator-bi","title":"Step 2: Run the integration in WSO2 Integrator: BI","text":"<ol> <li>Click Run in the top right corner to run the integration. This compiles the integration and runs it in the embedded Ballerina runtime.</li> </ol>"},{"location":"get-started/develop-file-integration/","title":"Develop File Integration","text":""},{"location":"get-started/develop-file-integration/#overview","title":"Overview","text":"<p>In this guide, you will create a file integration that fetches recent weather data.</p>"},{"location":"get-started/develop-file-integration/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have the following:</p> <ul> <li>Visual Studio Code: Install Visual Studio Code if you don't have it already.</li> <li>WSO2 Integrator: BI Extension: Install the WSO2 Integrator: BI extension. Refer to Install WSO2 Integrator: BI for detailed instructions.</li> </ul>"},{"location":"get-started/develop-file-integration/#step-1-develop-file-integration-in-wso2-integrator-bi","title":"Step 1: Develop File Integration in WSO2 Integrator: BI","text":"<ol> <li>Choose the Integration Type as <code>File Integration</code> and click Create.</li> </ol> <p>This redirects you to the Create New Integration in VS Code page. </p> <ol> <li> <p>From the left side panel, click + on the Configurations, and add the following configurables.</p> Configurable Type <code>host</code> <code>string</code> <code>username</code> <code>string</code> <code>password</code> <code>string</code> <code>path</code> <code>string</code> <code>pattern</code> <code>string</code> <p></p> </li> <li> <p>Go to the Design View by clicking the Home icon on the top left corner and click Add Artifact.</p> </li> <li>Select FTP Service. Choosing the File Integration from the Devant console disables the other options.</li> <li>Provide the name of the Listener Configuration as <code>weatherListener</code>.</li> <li> <p>Then expand the Advanced Configurations and enter the following configurables:</p> Field Value Host <code>host</code> Auth <code>{ credentials: { username: username, password: password }}</code> Path <code>path</code> FileNamePattern <code>pattern</code> </li> <li> <p>Click Next, and you will see the created listener with the name <code>weatherListener</code>. </p> </li> <li> <p>Then click on Create. It will redirect you to the Service Designer view.</p> <p></p> </li> <li> <p>In the Design view, click the <code>onFileChange</code> function box. It will redirect you to the flow diagram view.</p> </li> <li>Click the plus icon after the Start node to open the node panel.</li> <li> <p>Select Foreach and enter the following values in relevant fields:</p> Field Value Variable Name <code>addFile</code> Variable Type <code>var</code> Collection <code>event.addedFiles</code> </li> <li> <p>Under the Foreach node, add a Log Info node with the Msg as <code>\"File added:\" + addedFiles.name</code>. </p> <p></p> </li> </ol>"},{"location":"get-started/develop-file-integration/#step-2-run-the-integration-in-wso2-integrator-bi","title":"Step 2: Run the integration in WSO2 Integrator: BI","text":"<ol> <li>Click Run in the top right corner to run the integration. This compiles the integration and runs it in the embedded Ballerina runtime.</li> </ol>"},{"location":"get-started/develop-integration-as-api/","title":"Develop Integration as API","text":""},{"location":"get-started/develop-integration-as-api/#overview","title":"Overview","text":"<p>In this guide, you will create a simple integration as an API that acts as a service that calls a third-party endpoint and returns its response to the client.</p> <p></p>"},{"location":"get-started/develop-integration-as-api/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have the following:</p> <ul> <li>Visual Studio Code: Install Visual Studio Code if you don't have it already.</li> <li>WSO2 Integrator: BI Extension: Install the WSO2 Integrator: BI extension. Refer to Install WSO2 Integrator: BI for detailed instructions.</li> </ul>"},{"location":"get-started/develop-integration-as-api/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the Integration Name as <code>HelloWorld</code>.</li> <li>Select the project directory by clicking on the Select Path button.</li> <li> <p>Click on the Create Integration button to create the integration project.</p> <p></p> </li> </ol>"},{"location":"get-started/develop-integration-as-api/#step-2-create-an-integration-service","title":"Step 2: Create an integration service","text":"Generate with AI<p>The integration service can also be generated using the AI-assistant. Click on the Generate with AI button and enter the following prompt, then press Add to Integration to generate the integration service.</p> <p><code>Create an http service that has base path as /hello, and 9090 as the port. Add GET resource on /greeting that invokes https://apis.wso2.com/zvdz/mi-qsg/v1.0 endpoint and forward the response to the caller.</code></p> <ol> <li>In the design view, click on the Add Artifact button.</li> <li>Select HTTP Service under the Integration as API category.</li> <li>Select the Create and use the default HTTP listener option from the Listeners dropdown.</li> <li>Select the Design From Scratch option as the Service Contract.</li> <li>Specify the Service base path as <code>/hello</code>.</li> <li> <p>Click on the Create button to create the new service with the specified configurations.</p> <p></p> </li> </ol>"},{"location":"get-started/develop-integration-as-api/#step-3-design-the-integration","title":"Step 3: Design the integration","text":"<ol> <li>The generated service will have a default resource named <code>greeting</code> with the <code>GET</code> method.</li> <li>Click on the <code>greeting</code> resource to view the resource details. Let's modify the resource to invoke the <code>HelloWorld</code> API endpoint.</li> <li>Hover over the arrow after start and click the \u2795 button to add a new action to the resource.</li> <li>Select Add Connection from the node panel. </li> <li>Search for <code>HTTP</code> in the search bar and select HTTP as the connection type.</li> <li>Change the Connection Name to <code>externalEP</code>.</li> <li> <p>Add the URL <code>\"https://apis.wso2.com\"</code> to the connection URL field and click Save.</p> <p></p> </li> <li> <p>Click the \u2795 button again and select Connections -&gt; externalEP -&gt; get from the node panel.</p> </li> <li> <p>Fill in the request details as below and click Save.</p> Field Value Variable Name <code>epResponse</code> Variable Type <code>string</code> Connection <code>externalEp</code> Target Type <code>string</code> Path <code>\"/zvdz/mi-qsg/v1.0\"</code> </li> <li> <p>Click \u2795 button again and select Return from the node panel.  </p> </li> <li> <p>Select the <code>epResponse</code> variable as the Expression from the dropdown and click Save. This step will return the response from the <code>HelloWorld</code> API endpoint.      </p> <p></p> </li> </ol>"},{"location":"get-started/develop-integration-as-api/#step-4-run-the-integration","title":"Step 4: Run the integration","text":"<ol> <li>Click on the Run button in top right corner to run the integration.</li> <li>The integration will be compiled and started in the embedded Ballerina runtime.</li> <li>Once the integration is started, click on the Test button to open the embedded HTTP client.</li> <li> <p>Click on the Send button to invoke the <code>greeting</code> resource.</p> <p></p> </li> <li> <p>Additionally, you can test the integration using REST clients like Postman or curl.</p> <pre><code>curl http://localhost:9090/hello/greeting\n{\"message\":\"Hello World!!!\"}%\n</code></pre> </li> <li> <p>Click on the \u23f9\ufe0f button or press <code>Shift + F5</code> shortcut to stop the integration.</p> <p></p> </li> </ol>"},{"location":"get-started/install-wso2-integrator-bi/","title":"Install WSO2 Integrator: BI","text":""},{"location":"get-started/install-wso2-integrator-bi/#step-1-install-visual-studio-code","title":"Step 1: Install Visual Studio Code","text":"<p>Download and install Visual Studio Code.</p>"},{"location":"get-started/install-wso2-integrator-bi/#step-2-install-the-wso2-integrator-bi-extension","title":"Step 2: Install the WSO2 Integrator: BI extension","text":"<ol> <li>Go to the Extensions view by clicking on the extension icon on the sidebar or pressing <code>Ctrl + Shift + X</code> on Windows and Linux, or <code>Shift + \u2318 + X</code> on a Mac.</li> <li>Search for <code>WSO2 Integrator: BI</code> in the extensions view search box.</li> <li> <p>Click on the Install button to install the <code>WSO2 Integrator: BI</code> extension.</p> <p></p> </li> <li> <p>This will install the WSO2 Integrator: BI and Ballerina extensions on VS Code.</p> </li> </ol>"},{"location":"get-started/install-wso2-integrator-bi/#step-3-set-up-wso2-integrator-bi-for-the-first-time","title":"Step 3: Set up WSO2 Integrator: BI for the first time","text":"<ol> <li> <p>Click on the BI icon on the sidebar.  </p> <p></p> </li> <li> <p>Click on the Set up Ballerina distribution button.</p> </li> <li>The setup wizard will install and configure the Ballerina distribution required for WSO2 Integrator: BI.</li> <li> <p>Click on the Restart VS Code button to complete the setup.</p> <p></p> </li> </ol>"},{"location":"get-started/quick-start-guide/","title":"Quick Start Guide","text":"<p>WSO2 Integrator: BI is a powerful low-code integration platform built on top of the Ballerina programming language. It\u2019s designed to help developers quickly build, deploy, and manage integration solutions with minimal boilerplate and maximum productivity.</p> <p>BI combines a visual design interface, AI-assisted development, and seamless low-code\u2013to\u2013pro-code transitions. With built-in connectors, flexible deployment options, and support for patterns like APIs, events, and automations, BI empowers teams to integrate faster and smarter.</p> <p>Whether you\u2019re modernizing legacy systems or building cloud-native services, BI provides a productive and scalable path to integration, helping teams drive digital transformation with clarity, speed, and confidence.</p> <p></p> <p>This quick start guide introduces five core integration types, each with a dedicated hands-on walkthrough.</p>"},{"location":"get-started/quick-start-guide/#automation","title":"Automation","text":"<p>Create integrations that run on a timer\u2014for example, to sync data, generate reports, or perform routine jobs. Follow Develop your first automation to get started.</p>"},{"location":"get-started/quick-start-guide/#ai-agent","title":"AI agent","text":"<p>Build agents that reason and act using GenAI models. Use them to respond to user input, access tools, or make decisions dynamically. Follow Develop your first AI agent to get started. </p>"},{"location":"get-started/quick-start-guide/#integrations-as-apis","title":"Integrations as APIs","text":"<p>Expose your integration as a real-time API that handles incoming requests and returns results. Follow Develop your first integration as API to get started.</p>"},{"location":"get-started/quick-start-guide/#event-integration","title":"Event Integration","text":"<p>Trigger your integration when messages arrive from sources like Kafka or RabbitMQ, enabling reactive workflows. Follow Develop your first event integration to get started.</p>"},{"location":"get-started/quick-start-guide/#file-integration","title":"File Integration","text":"<p>Run your integration when files appear in a folder or FTP location\u2014ideal for batch uploads or scheduled file processing. Follow Develop your first file integration to get started.</p> <p>Explore one or more quick start guides to experience how fast and flexible integration can be with BI.</p>"},{"location":"integration-guides/ai/agents/","title":"Agents Overview","text":"<p>The Ballerina Integrator (BI) enables developers to easily create intelligent AI agents powered by large language models (LLMs) and integrated with external APIs and services. These AI agents can automate complex workflows, interact with users through natural language, and seamlessly connect with systems like Gmail, Google Calendar, and more. Designed for low-code development and rapid integration, BI makes it simple to embed AI-driven logic into your applications, services, and business processes.</p> <p>There are two main types of AI agents in BI:</p>"},{"location":"integration-guides/ai/agents/#chat-agents","title":"Chat Agents","text":"<p>Chat agents are exposed through HTTP endpoints as REST APIs and are designed to interact with users or external systems. These agents are ideal when you need a chatbot-like experience, where users can type questions or commands and receive intelligent responses powered by an LLM.</p>"},{"location":"integration-guides/ai/agents/#inline-agents","title":"Inline Agents","text":"<p>Inline agents are embedded within service logic (e.g., REST APIs, GraphQL resolvers) and invoked programmatically as part of a backend workflow. These agents are ideal for automation, enrichment, or dynamic processing tasks within your services or business logic.</p> <p>Both Chat and Inline agents can be extended with tools that connect to real-world systems via BI's built-in connectors. You can easily integrate agents with services like Gmail, Google Calendar, databases, or custom APIs\u2014allowing agents to perform actions beyond reasoning, such as reading emails, sending messages, creating events, or fetching records.</p> <p>To get started with agents, visit the following tutorial examples:</p> <ul> <li>Introduction to Chat Agents</li> <li>Introduction to Inline Agents</li> <li>Integrating Agents with External Endpoints</li> </ul>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/","title":"Integrating Agents with External Endpoints","text":"<p>In this tutorial, you\u2019ll create an AI-powered personal assistant agent that integrates with Gmail and Google Calendar to help you efficiently manage emails, tasks, and schedules. You'll use the prebuilt WSO2 Integrator: BI connectors for seamless integration by turning their actions into agent tools.</p>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#prerequisites","title":"Prerequisites","text":"<p>To get started, you\u2019ll need to configure Google API credentials:</p> <ol> <li>Go to the Google Cloud Console and sign in.</li> <li>Follow this guide to generate your Client ID, Client Secret, and Refresh Token.</li> <li>Make sure the necessary scopes and permissions are enabled for both the Gmail and Calendar APIs.</li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#create-the-agent","title":"Create the agent","text":"<p>Before adding tools, make sure you\u2019ve set up your agent by completing steps 1 to 5 in the Introduction to Chat Agents guide. For this tutorial, you may use the following role and instructions when configuring the agent's behavior.</p> <p>Role <pre><code>Personal AI Assistant\n</code></pre></p> <p>Instructions <pre><code>You are Nova, a smart AI assistant helping me stay organized and efficient.\n\nYour primary responsibilities include:\n- Calendar Management: Scheduling, updating, and retrieving events from the calendar as per the user's needs.\n- Email Assistance: Reading, summarizing, composing, and sending emails while ensuring clarity and professionalism.\n- Context Awareness: Maintaining a seamless understanding of ongoing tasks and conversations to \n  provide relevant responses.\n- Privacy &amp; Security: Handling user data responsibly, ensuring sensitive information is kept confidential,\n  and confirming actions before executing them.\n\nGuidelines:\n- Respond in a natural, friendly, and professional tone.\n- Always confirm before making changes to the user's calendar or sending emails.\n- Provide concise summaries when retrieving information unless the user requests details.\n- Prioritize clarity, efficiency, and user convenience in all tasks.\n</code></pre></p>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#use-connector-actions-as-agent-tools","title":"Use connector actions as agent tools","text":"<p>BI includes prebuilt connectors for many external services like Gmail and Google Calendar. You can directly use their actions as tools for your agent\u2014no need to write custom integration code. This significantly reduces the manual effort typically required when working with external APIs.</p>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#add-gmail-tools-to-the-agent","title":"Add Gmail tools to the agent","text":""},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#tool-1-list-unread-emails","title":"Tool 1: List unread emails","text":""},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-1-add-the-gmail-connector","title":"Step 1: Add the Gmail connector","text":"<ol> <li>In Agent Flow View, click the + button at the bottom-left of the <code>AI Agent</code> box.</li> <li>Click the + button next to Tools \u2192 Create New Tool.</li> <li>Click Add Connection under the Connections section.</li> <li> <p>Search for and select the Gmail connector.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-2-configure-the-gmail-connector","title":"Step 2: Configure the Gmail connector","text":"<ol> <li> <p>In the configuration panel:</p> <ul> <li>Click Config to open the Expression Helper.</li> <li>Under the Construct Record tab, select ConnectionConfig.</li> <li>Set the <code>auth</code> type to OAuth2RefreshTokenGrantType.</li> <li>Fill in your clientId, clientSecret, and refreshToken.</li> </ul> <p>Note</p> <p>Externalize credentials using configurable values to avoid exposing them in your version control system. </p> </li> <li> <p>Save the configuration. You\u2019ll now see the Gmail connection listed under Connections.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-3-create-the-tool","title":"Step 3: Create the tool","text":"<ol> <li>Select the Gmail connection \u2192 choose the action List messages in user\u2019s mailbox.</li> <li> <p>Provide the required Tool Name input as <code>listUnreadEmails</code>, and optionally add a meaningful Description to help the LLM better understand the tool's purpose.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-4-customize-the-tool","title":"Step 4: Customize the tool","text":"<ol> <li>Click on the circular <code>listUnreadEmails</code> tool node.</li> <li>Click \u22ee &gt; View to open the tool function.</li> <li>Click the Gmail connector action node (the rectangle connected to the Gmail connection) to open the configuration panel for that specific connector action.</li> <li>Update these inputs:<ul> <li>Set userId to <code>me</code>. The value <code>\"me\"</code> represents the authenticated user.</li> <li>Under Advanced Configurations, set the q input to <code>\"is:unread\"</code> to filter unread emails only.</li> </ul> </li> <li> <p>Click Save.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-5-clean-up","title":"Step 5: Clean up","text":"<p>Remove the <code>userId</code> parameter from the function as it is no longer used in the tool:</p> <ul> <li>Click Edit in the top-right of the function panel.</li> <li>Click the Trash icon next to <code>userId</code>.</li> <li> <p>Click Save.</p> <p></p> </li> </ul> <p>You\u2019ve now created a tool that lists unread emails in the user\u2019s Gmail inbox.</p>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#tool-2-read-a-specific-email","title":"Tool 2: Read a specific email","text":""},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-1-create-the-tool","title":"Step 1: Create the tool","text":"<ol> <li>In Agent Flow View, click + under Tools \u2192 Create New Tool.</li> <li>Select the existing gmailClient connection.</li> <li>Choose the action Gets the specified message.</li> <li> <p>Name the tool as <code>readSpecificEmail</code> and optionally add a description.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-2-customize-the-tool","title":"Step 2: Customize the tool","text":"<ol> <li>Open the <code>readSpecificEmail</code> tool node \u2192 \u22ee &gt; View.</li> <li>Click the Gmail action node and update inputs:<ul> <li>Set userId to <code>\"me\"</code>. The value <code>\"me\"</code> represents the authenticated user.</li> <li>Under Advanced Configurations, set the format input to <code>full</code> to get the full email message data with the body content parsed.</li> </ul> </li> <li> <p>Click Save.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-3-clean-up","title":"Step 3: Clean up","text":"<p>Remove <code>userId</code> from parameters (as done previously) and save the tool.</p> <p></p>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#tool-3-send-an-email","title":"Tool 3: Send an email","text":""},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-1-create-the-tool_1","title":"Step 1: Create the tool","text":"<ol> <li>Use the existing gmailClient connection.</li> <li>Select the action Sends the specified message to the recipients.</li> <li> <p>Name the tool as <code>sendEmail</code> and optionally add a helpful description.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-2-customize-and-clean-up","title":"Step 2: Customize and clean up","text":"<ol> <li>Set <code>userId</code> to <code>\"me\"</code> in the connector action configuration (as done previously) .</li> <li>Remove <code>userId</code> from the parameters.</li> <li> <p>Save your tool.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#add-calendar-tools-to-the-agent","title":"Add calendar tools to the agent","text":""},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#tool-4-list-calendar-events","title":"Tool 4: List calendar events","text":""},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-1-add-the-google-calendar-connector","title":"Step 1: Add the google calendar connector","text":"<ol> <li>In Agent Flow View, click the + button at the bottom-left of the <code>AI Agent</code> box.</li> <li>Click the + button next to Tools \u2192 Create New Tool.</li> <li>Click + button of the Connections section.</li> <li> <p>Search for and select the Gcalendar connector.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-2-configure-the-google-calendar-connector","title":"Step 2: Configure the google calendar connector","text":"<ol> <li> <p>In the configuration panel:</p> <ul> <li>Click Config to open the Expression Helper.</li> <li>Under the Construct Record tab, select ConnectionConfig.</li> <li>Set the <code>auth</code> type to OAuth2RefreshTokenGrantType.</li> <li>Fill in your clientId, clientSecret, and refreshToken.</li> </ul> <p>Note</p> <p>Externalize credentials using configurable values to avoid exposing them in your version control system. </p> <p></p> </li> <li> <p>Save the configuration. You\u2019ll now see the Google calendar connection listed under Connections.</p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-3-create-the-tool_1","title":"Step 3: Create the tool","text":"<ol> <li>Select the Google calendar connection \u2192 choose the action Returns events on the specified calendar..</li> <li> <p>Provide the required Tool Name input as <code>listCalendarEvents</code>, and optionally add a meaningful Description.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-4-customize-the-tool_1","title":"Step 4: Customize the tool","text":"<ol> <li>Click on the circular <code>listCalendarEvents</code> tool node.</li> <li>Click \u22ee &gt; View to open the tool function.</li> <li>Click the Google calendar connector action node (the rectangle connected to the Google calendar connection) to open the configuration panel for that specific connector action.</li> <li>Update the <code>calendarId</code> input to <code>\"primary\"</code>, which allows access to the primary calendar of the authenticated user.</li> <li> <p>Click Save.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-5-clean-up_1","title":"Step 5: Clean up","text":"<p>Remove the <code>calendarId</code> parameter from the function as it is no longer used in the tool:</p> <ul> <li>Click Edit in the top-right of the function panel.</li> <li>Click the Trash icon next to <code>calendarId</code>.</li> <li> <p>Click Save.</p> <p></p> </li> </ul>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#tool-5-create-calendar-event","title":"Tool 5: Create calendar event","text":""},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-1-create-the-tool_2","title":"Step 1: Create the tool","text":"<ol> <li>In Agent Flow View, click + under Tools \u2192 Create New Tool.</li> <li>Select the existing gcalendarClient connection.</li> <li>Choose the action Creates an event.</li> <li> <p>Name the tool as <code>createCalendarEvent</code> and optionally add a helpful description.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-2-customize-the-tool_1","title":"Step 2: Customize the tool","text":"<ol> <li>Click on the circular <code>createCalendarEvent</code> tool node.</li> <li>Click \u22ee &gt; View to open the tool function.</li> <li>Click the Google calendar connector action node to open the configuration panel for that specific connector action.</li> <li>Update the <code>calendarId</code> input to <code>\"primary\"</code>.</li> <li> <p>Click Save.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#step-3-clean-up_1","title":"Step 3: Clean up","text":"<p>Remove the <code>calendarId</code> parameter from the function as it is no longer used in the tool:</p> <ul> <li>Click Edit in the top-right of the function panel.</li> <li>Click the Trash icon next to <code>calendarId</code>.</li> <li> <p>Click Save.</p> <p></p> </li> </ul>"},{"location":"integration-guides/ai/agents/integrating-agents-with-external-endpoints/#interact-with-the-agent","title":"Interact with the agent","text":"<p>After completing the above steps, your personal AI assistant agent is now ready to assist you with necessary tasks. WSO2 Integrator: BI provides a built-in chat interface to interact with the agent.</p> <p>To start chatting with the agent:</p> <ol> <li>Click the Chat button located at the top-left corner of the interface.</li> <li>You will be prompted to run the integration. Click Run Integration.</li> <li>If you have added any variables to the project, you\u2019ll be prompted to update their values in the Config.toml file. Configure them to continue with the execution of the agent.</li> <li> <p>Start chatting with your assistant.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/","title":"Introduction to Chat Agents","text":"<p>In this tutorial, you'll create an AI-powered math tutor assistant capable of handling a variety of mathematical queries. The agent will be equipped with tools to perform fundamental arithmetic operations and intelligently combine and execute these tools to address user questions. By the end of this tutorial, you'll have built an interactive math assistant that can help users solve problems and provide clear, step-by-step explanations.</p> <p>Note</p> <p>This math tutor agent can technically be implemented using just an LLM, without any agent capabilities. However, the purpose of this tutorial is to help you understand the essential concepts required to build an AI agent using WSO2 Integrator: BI. By following this guide, you'll gain hands-on experience with agent creation in WSO2 Integrator: BI, setting the foundation for developing more powerful and tailored AI agents in the future.</p>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#prerequisites","title":"Prerequisites","text":"<ul> <li>Sign up at OpenAI.</li> <li>Get an API key from the API section.</li> </ul>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon in the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>MathTutor</code>.</li> <li>Select the project directory location by clicking on the Select Location button.</li> <li> <p>Click the Create New Integration button to generate the integration project.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#step-2-create-an-agent","title":"Step 2: Create an agent","text":"<ol> <li>Click the + button on the BI side panel or navigate back to the design screen and click on Add Artifact.</li> <li>Select AI Chat Agent under the AI Agent artifacts.</li> <li>Provide a Name for the agent. It will take a moment to create an agent with the default configuration.</li> <li> <p>After creating the agent, you can configure it with a model provider, memory, tools, roles, and instructions.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#step-3-configure-the-agent-behavior","title":"Step 3: Configure the agent behavior","text":"<ol> <li>Click on the AI Agent box to open the agent configuration settings.</li> <li>Define the agent's Role and provide Instructions in natural language. These instructions will guide the agent\u2019s behavior and tasks.</li> <li> <p>Click Save to finalize and complete the agent behavior configuration.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#step-4-configure-the-agent-model","title":"Step 4: Configure the agent model","text":"<ol> <li>Locate the circle with OpenAI logo which is connected to the AI Agent box. This circle represents the LLM model used by the agent.</li> <li>Click on the circle to open the model configuration options.</li> <li>In the Select Model Provider dropdown, choose OpenAiProvider. By default, OpenAiProvider is selected.</li> <li> <p>Next, provide the OpenAI API key in the API Key input field.</p> <p>Note</p> <p>Since the API key is sensitive, it\u2019s recommended to externalize it by using a configurable value. This helps prevent accidentally committing it to your version control system and ensures it\u2019s kept secure without being exposed. To learn more, see Configurations.</p> <ul> <li>Click the API Key input field to open the Expression Helper window.  </li> <li>In the top bar, go to the Configurables tab (the third option).  </li> <li>Click + Create New Configurable Variable to define a new configurable.  </li> <li>Set the Name to <code>openAiApiKey</code> and the Type to <code>string</code>.  </li> <li>Click Save to create the configurable.</li> </ul> </li> <li> <p>In the Model Type dropdown, select <code>ai:GPT_40</code>.</p> </li> <li> <p>Click Save to complete the LLM model configuration.    </p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#step-5-configure-agent-memory","title":"Step 5: Configure agent memory","text":"<ol> <li>By default, the agent comes preconfigured with an in-memory implementation.</li> <li>For this tutorial, we will keep the default memory configuration and not make any changes.</li> <li>If you prefer to run the agent without memory (in a stateless fashion), follow these steps:<ul> <li>Click on the three vertical dots in the Memory box.</li> <li>Select the Delete option to remove the memory.</li> </ul> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#step-6-add-tools-to-the-agent","title":"Step 6: Add tools to the agent","text":"<p>BI allows you to create tools using existing functions. It also supports automatically generating tools from connector actions or OpenAPI specifications by leveraging BI\u2019s capability to generate local connectors from an OpenAPI spec.</p> <p>However, in this tutorial, we will create simple functions to perform arithmetic operations and use them as tools.</p>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#create-a-function","title":"Create a function","text":"<ol> <li>Click the + button in the BI side panel under the Functions section.</li> <li>Provide the required details to create the function. For this example, use <code>sum</code> as the function name, and specify the parameters and return types.</li> <li>Implement the function logic in the flow node editor that opens.</li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#add-the-created-function-as-a-tool","title":"Add the created function as a tool","text":"<ol> <li>Go to the agent flow view.</li> <li>Click the + button at the bottom-right corner of the <code>AI Agent</code> box.</li> <li>Click the + button under the Tools section.</li> <li>Select the created function from the Current Integration list \u2014 in this case, <code>sum</code>.</li> <li>Then provide the Tool Name and Description of the tool</li> </ol> <p>Follow steps 1 to 3 to create functions named subtract, multiply and divide to perform subtraction, multiplication, and division operations respectively. Define the appropriate parameters and return types, and implement the corresponding logic in the flow node editor. Then repeat steps 4 to 8 to add each of these functions as tools in the agent by selecting them from the Current Integration list and providing a relevant tool name and description for each.    </p> <p></p>"},{"location":"integration-guides/ai/agents/introduction-to-chat-agents/#step-7-interact-with-the-agent","title":"Step 7: Interact with the agent","text":"<p>After completing the above steps, your math tutor assistant is now ready to answer questions. BI provides a built-in chat interface to interact with the agent.</p> <p>To start chatting with the agent:</p> <ol> <li>Click the Chat button located at the top-left corner of the interface.</li> <li>You will be prompted to run the integration. Click Run Integration.</li> <li>Since we have created a configurable variable for <code>openAiApiKey</code> in step 4, provide it in the <code>Config.toml</code> file.</li> </ol> <p>Note</p> <p>A temporary OpenAI API key is used in the GIF below to showcase the steps.  </p> <p></p>"},{"location":"integration-guides/ai/agents/introduction-to-inline-agents/","title":"Introduction to Inline Agents","text":"<p>In this tutorial, you'll learn how to connect an AI agent to a GraphQL service, enabling the agent to be invoked directly within a GraphQL resolver. This demonstrates the use of an inline agent\u2014a powerful capability in the WSO2 Integrator: BI.</p> <p>Unlike chat agents, which are exposed as REST APIs for external interaction, inline agents are not tied to an API endpoint. Instead, they can be invoked programmatically from anywhere within your integration logic, just like a regular function call.</p> <p>In this example, we'll define a GraphQL schema with a query that invokes the inline agent to generate dynamic responses based on input parameters. The agent runs within the resolver logic and returns results directly as part of the GraphQL response.</p>"},{"location":"integration-guides/ai/agents/introduction-to-inline-agents/#prerequisites","title":"Prerequisites","text":"<ul> <li>Sign up at OpenAI.</li> <li>Get an API key from the API section.</li> </ul>"},{"location":"integration-guides/ai/agents/introduction-to-inline-agents/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon in the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>GraphqlService</code>.</li> <li>Select the project directory by clicking on the Select Location button.</li> <li> <p>Click the Create New Integration button to generate the integration project.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-inline-agents/#step-2-create-a-graphql-service","title":"Step 2: Create a GraphQL service","text":"<ol> <li>Click the + button on the WSO2 Integrator: BI side panel or navigate back to the design screen and click on Add Artifact.</li> <li>Select GraphQL Service under the Integration as API artifacts.</li> <li> <p>Keep the default Listener and Service base path configurations, and click Create.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-inline-agents/#step-3-create-a-graphql-resolver","title":"Step 3: Create a GraphQL resolver","text":"<ol> <li>Click the + Create Operations button in the GraphQL design view.</li> <li>In the side panel, click the + button in the Mutation section to add a mutation operation.</li> <li>Provide <code>task</code> as the value for the Field name.</li> <li>Click the Add Argument button to add a GraphQL input<ul> <li>Provide <code>query</code> for the Argument name.</li> <li>Provide <code>string</code> for the Argument type.</li> <li>Click Add to save the argument.</li> </ul> </li> <li> <p>Provide <code>string|error</code> for the Field type, as this will be used as the return type of the resolver.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/agents/introduction-to-inline-agents/#step-4-implement-the-resolving-logic-with-an-inline-agent","title":"Step 4: Implement the resolving logic with an inline agent","text":"<ol> <li>Click the created <code>task</code> operation in the side panel to navigate to the resolver editor view.</li> <li>Click the + button in the flow to open the side panel.</li> <li>Click Agent under Statement, which will navigate you to the agent creation panel.</li> <li>Update Variable Name to <code>response</code>. This is the variable where the agent's output will be stored.</li> <li>Update the Role and Instructions to configure the agent\u2019s behavior.</li> <li>Provide the query parameter as the input for Query. This will serve as the command that the agent will execute.</li> <li>Click Save.</li> <li>Next, configure the agent\u2019s memory, model, and tools. For guidance, refer to the Chat Agent configuration steps and the Personal Assistant setup guide to make the agent function as a personal assistant.</li> <li>After configuring the agent, click the + button on the flow and select Return under Control from the side panel.</li> <li> <p>For the Expression, provide the <code>response</code> variable as the input.</p> <p></p> </li> </ol> <p>At this point, we've created a GraphQL resolver that takes a user-provided <code>query</code> as input, passes it to an inline agent for processing, and returns the agent\u2019s <code>response</code> as the result of the resolver.</p> <p>Note</p> <p>You must implement a query operation to have a valid GraphQL service. Similar to creating the <code>task</code> operation in Step 3, add an operation named <code>greet</code> by pressing the + button in the Query section, without any input parameters. For the implementation, you can simply return a string literal saying <code>\"welcome\"</code>.</p>"},{"location":"integration-guides/ai/agents/introduction-to-inline-agents/#step-5-run-the-integration-and-query-the-agent","title":"Step 5: Run the integration and query the agent","text":"<ol> <li>Click on the Run button in the top-right corner to run the integration.</li> <li> <p>Query the agent by sending the mutation request below.     <pre><code>curl -X POST http://localhost:8080/graphql \\\n-H \"Content-Type: application/json\" \\\n-d '{ \"query\": \"mutation Task { task(query: \\\"Summarize latest emails\\\") }\" }'\n</code></pre></p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/natural-functions/natural-functions/","title":"Natural Functions","text":"<p>In this tutorial, you will create and use a natural function using the WSO2 Integrator: BI. A natural function allows the logic of the function to be described in natural language and is executed at runtime with a call to a Large Language Model (LLM), with the natural language instructions as the prompt. The tutorial uses a natural function to analyze blog content to suggest a suitable category and rate it on a scale of 1 to 10 based on specified criteria.</p> Natural Programming<p>To learn more about natural programming and natural functions, see Natural Language is Code: A hybrid approach with Natural Programming.</p>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#implementation","title":"Implementation","text":"<p>Follow the steps below to implement the integration.</p>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the <code>Create New Integration</code> button.</li> <li>Enter <code>BlogReviewer</code> as the project name.</li> <li>Select Project Directory and click on the <code>Select Location</code> button.</li> <li>Click on the <code>Create New Integration</code> button to create the integration project.</li> </ol>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#step-2-define-types","title":"Step 2: Define Types","text":"<ol> <li>Click on the <code>Add Artifacts</code> button and select <code>Type</code> in the <code>Other Artifacts</code> section.</li> <li>Click on <code>+ Add Type</code> to add a new type.</li> <li> <p>Use <code>Blog</code> as the <code>Name</code>. Then click on the <code>JSON</code> button and paste the following JSON payload. Tick <code>Is Closed</code> and click on the <code>Import</code> button. Then click the <code>Save</code> button.</p> <pre><code>{\n\"title\": \"Tips for Growing a Beautiful Garden\",\n\"content\": \"Spring is the perfect time to start your garden. Begin by preparing your soil with organic compost and ensure proper drainage. Choose plants suitable for your climate zone, and remember to water them regularly. Don't forget to mulch to retain moisture and prevent weeds.\"\n}\n</code></pre> </li> <li> <p>Add another type with <code>Review</code> as the <code>Name</code> and paste the following JSON payload. Select <code>Is Closed</code> and click on the <code>Import</code> button. Then click the <code>Save</code> button.</p> <pre><code>{\n\"suggestedCategory\": \"Gardening\",\n\"rating\": 5\n}\n</code></pre> </li> <li> <p>The types are now available in the project. <code>Blog</code> and <code>Review</code> are the types that represent the blog content and review respectively.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#step-3-add-a-natural-function","title":"Step 3: Add a Natural Function","text":"<ol> <li>Click on the <code>Add Artifact</code> button and select <code>Natural Function</code> under the <code>Other Artifacts</code> category.</li> <li> <p>Use <code>reviewBlog</code> as the name of the function. Then click the <code>Add Parameter</code> button to add a parameter of type <code>Blog</code> named <code>blog</code>. Use <code>Review</code> as the return type and convert it to nilable type using type operators. Then click on the <code>Create</code> button.</p> <p></p> </li> <li> <p>Click on the <code>Edit</code> button to specify the requirement in natural language (i.e., the prompt).</p> </li> <li> <p>Use the following prompt and click on the <code>Save</code> button. Note how interpolations refer to the <code>blog</code> parameter.</p> <pre><code>You are an expert content reviewer for a blog site that \n    categorizes posts under the following categories: \"Gardening\", \"Sports\", \"Health\", \"Technology\", \"Travel\"\n\n    Your tasks are:\n    1. Suggest a suitable category for the blog from exactly the specified categories. \n       If there is no match, use null.\n\n    2. Rate the blog post on a scale of 1 to 10 based on the following criteria:\n    - **Relevance**: How well the content aligns with the chosen category.\n    - **Depth**: The level of detail and insight in the content.\n    - **Clarity**: How easy it is to read and understand.\n    - **Originality**: Whether the content introduces fresh perspectives or ideas.\n    - **Language Quality**: Grammar, spelling, and overall writing quality.\n\nHere is the blog post content:\n\n    Title: ${blog.title}\n    Content: ${blog.content}\n</code></pre> <p></p> </li> </ol>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#step-4-create-an-http-service","title":"Step 4: Create an HTTP service","text":"<ol> <li>In the design view, click on the <code>Add Artifact</code> button.</li> <li>Select <code>HTTP Service</code> under the <code>Integration as API</code> category.</li> <li>Select the <code>Create and use the default HTTP listener (port: 9090)</code> option from the <code>Listeners</code> dropdown.</li> <li>Select the <code>Design from Scratch</code> option as the <code>Service Contract</code> and use <code>/blogs</code> as the <code>Service base path</code>.</li> <li> <p>Click on the <code>Create</code> button to create the new service with the specified configurations.</p> <p></p> </li> <li> <p>The service will have a default resource named <code>greeting</code> with the <code>GET</code> method. Click on the three dots that appear in front of the <code>/blogs</code> service and select <code>Edit</code> from the menu.</p> </li> <li>Then click the <code>Edit</code> button in front of <code>/greeting</code> resource.</li> <li>Change the resource HTTP method to <code>POST</code>.</li> <li>Change the resource name to <code>review</code>.</li> <li>Click on <code>Add Payload</code> and specify <code>blog</code> as the name and <code>Blog</code> as the type.</li> <li>Change the 201 response return type to <code>Review</code>.</li> <li> <p>Click on the <code>Save</code> button to update the resource with the specified configurations.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#step-5-implement-the-resource-logic","title":"Step 5: Implement the resource logic","text":"<ol> <li>Click on the <code>review</code> resource to navigate to the resource implementation designer view.</li> <li>Hover over the arrow after start and click the \u2795 button to add a new action to the resource.</li> <li>Select <code>Call Natural Function</code> from the node panel.</li> <li>Select the <code>reviewBlog</code> function from the suggestions.</li> <li> <p>For the <code>Blog</code> parameter, use <code>blog</code> as the argument and click on the <code>Save</code> button.</p> <p></p> </li> <li> <p>Add a new node after the <code>reviewBlog</code> function call and select <code>Return</code> from the node panel.</p> </li> <li> <p>Select the <code>review</code> variable from the dropdown and click <code>Save</code>.</p> <p></p> </li> <li> <p>The resource implementation is now complete. The function <code>reviewBlog</code> is called with the <code>blog</code> content as input, and the <code>review</code> is returned as the response.</p> </li> </ol>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#step-6-configure-model-for-natural-function","title":"Step 6: Configure model for natural function","text":"<ol> <li> <p>Press <code>Ctrl + Shift + P</code> on Windows and Linux, or <code>Shift + \u2318 + P</code> on a Mac, and type <code>&gt;Ballerina: Configure default model for natural functions (Experimental)</code> to configure the default model for natural functions. </p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/natural-functions/natural-functions/#step-7-run-the-integration","title":"Step 7: Run the integration","text":"<p>Response May Vary</p> <p>Since this integration involves an LLM (Large Language Model) call, the response values may not always be identical across different executions.</p> <ol> <li>Click on the <code>Run</code> button in the top-right corner to run the integration.</li> <li>The integration will start and the service will be available at <code>http://localhost:9090/blogs</code>.</li> <li>Click on the <code>Try it</code> button to open the embedded HTTP client.</li> <li> <p>Enter the blog content in the request body and click on the \u25b6\ufe0f button to send the request.</p> <pre><code>{\n\"title\": \"The Healthy Maven\",\n\"content\": \"For those who want a 360-degree approach to self-care, with advice for betterment in the workplace, home, gym, and on the go, look no further. The Healthy Maven offers recipes for every type of meal under the sun (salads, sides, soups, and more), DIY tips (you\u2019ll learn how to make your own yoga mat spray), and quick workouts. If you like where all this is going, there\u2019s a supplementary podcast run by blogger Davida with guest wellness experts.\"\n}\n</code></pre> </li> <li> <p>The blog content is analyzed by the natural function to suggest a category and rate it based on predefined criteria.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/","title":"Build a RAG Application","text":"<p>This tutorial guides you through creating a Retrieval-Augmented Generation (RAG) system using the Ballerina Integrator. While there are several ways to structure a RAG workflow, we\u2019ll focus on a typical two-phase approach: ingestion and retrieval.</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#rag-ingestion","title":"RAG ingestion","text":"<p>This step is managed through Devant and it focuses on preparing documents for efficient retrieval in the RAG system.</p> <ul> <li>Chunk the information into smaller, meaningful sections</li> <li>Convert each chunk into embeddings using an embedding model</li> <li>Store embeddings in the vector database for efficient retrieval</li> </ul> <p>We assume that you've already used Devant to process and ingest the documents. Devant handles the entire ingestion process independently of the main application flow. The following steps of the tutorial focus solely on RAG retrieval.</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#rag-retrieval","title":"RAG retrieval","text":"<p>This tutorial focuses on implementing the rag retrieval component of a Retrieval-Augmented Generation (RAG) system using the Ballerina Integrator.</p> <ul> <li>Convert the user's question into embeddings</li> <li>Perform a similarity search in the vector database</li> <li>Fetch the most relevant chunks</li> <li>Include only the relevant data in the prompt</li> <li>Generate a fact-grounded answer using the LLM</li> </ul> <p>By the end of this tutorial, you'll have a working RAG system that can retrieve relevant information and generate accurate, grounded responses using pre-ingested documents.</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#prerequisites","title":"Prerequisites","text":"<ul> <li>Access to Pinecone vector database (requires API key and service URL)</li> <li>Access to Azure OpenAI (requires API key and endpoint URL)</li> <li>Access to Devant</li> </ul>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#step-1-create-an-http-service","title":"Step 1: Create an HTTP service","text":"<ol> <li>In the design view, click on the Add Artifact button.</li> <li>Select HTTP Service under the Integration as API category.</li> <li>Select the Create and use the default HTTP listener (port:9090) option from the Listeners dropdown.</li> <li>Select the Design from Scratch option as the Service Contract and use <code>/personalAssitant</code> as the Service base path.</li> <li> <p>Click on the Create button to create the new service with the specified configurations.</p> <p></p> </li> <li> <p>The service will have a default resource named <code>greeting</code> with the GET method.</p> </li> <li>Click the Edit FunctionModel button in front of <code>/greeting</code> resource.</li> <li>Change the resource HTTP method to POST.</li> <li>Change the resource name to <code>chat</code>.</li> <li>Click on Add Parameter under the Parameters and specify the parameters you need. We used to select the Param Type as QUERY and specify <code>request</code> as the name and <code>ChatRequestMessage</code> as the type.</li> <li>Change the 200 response return type to <code>string</code>.</li> <li> <p>Click on the Save button to update the resource with the specified configurations.</p> <p></p> </li> </ol> <p>Note</p> <p>Here we use a modular approach for the resource logic for the <code>/chat</code> resource. You may use your own logic calling directly in the <code>/chat</code> service without creating functions separately.</p> <p>This approach allows for flexibility in implementation - you can either:</p> <ul> <li>Follow the modular pattern shown in this tutorial for better organization and maintainability</li> <li>Implement your logic directly within the <code>/chat</code> resource function based on your specific requirements</li> </ul>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#step-2-implementation-of-rag","title":"Step 2: Implementation of RAG","text":""},{"location":"integration-guides/ai/rag/build-a-rag-application/#21-retrieve-embeddings-for-user-query","title":"2.1 Retrieve embeddings for user query","text":"<p>Follow these steps to create a function that retrieves embeddings using Azure OpenAI:</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#211-create-an-embeddings-function","title":"2.1.1 Create an embeddings function","text":"<ol> <li>Click the + button in the Integrator side panel under the Functions section.</li> <li> <p>Provide the required details to create the function. Use <code>getEmbeddings</code> as the function name and specify the parameters and return types.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#212-add-embeddings-connection","title":"2.1.2 Add embeddings connection","text":"<ol> <li>Click the + button and select the + Add Connection the side panel.</li> <li>Select the connector Embeddings - ballerinax/azure.openai.embeddings.</li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#213-configure-the-embeddings-connector","title":"2.1.3 Configure the embeddings connector","text":"<ol> <li>In the configuration of the connector, under the Config select the Add Expression to open the Expression Helper window.</li> <li>In the Expression Helper, navigate to Configurables, click the Create new configurable variable. Here we create <code>azure_api_key</code> and <code>azure_service_url</code>.</li> <li>Select the ConnectionConfig under the Construct Record in the Expression Helper window.</li> <li>Change the BearerTokenConfig to ApiKeysConfig in the auth.</li> <li>Select the Configurables and click the <code>azure_api_key</code>.</li> <li>Expand the Advanced Configurations section. Under the ServiceUrl select the Add Expression to open the Expression Helper window.</li> <li> <p>In the Expression Helper, navigate to Configurables, select on <code>azure_service_url</code> as the value for ServiceUrl and click Save button.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#214-implement-the-embeddings-function-logic","title":"2.1.4 Implement the embeddings function logic","text":"<ol> <li>Click the + button and select the Declare Variable under the Statement.</li> <li>Create variable name as <code>embeddingsBody</code> and specify its type and expression.</li> <li>Click the + button and select the <code>embeddingsClient</code>.</li> <li>Configure the client with the DeploymentId, payload and API version.</li> <li>Configure the function to convert the returned decimal embeddings to float values.</li> <li>Return the final float array.</li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#22-retrieve-relevant-chunks-from-vector-database","title":"2.2 Retrieve relevant chunks from vector database","text":"<p>Follow these steps to create a function that retrieves similar vectors from Pinecone using vector embeddings:</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#221-add-pinecone-vector-connection","title":"2.2.1 Add Pinecone vector connection","text":"<ol> <li>Click the + button in the Integrator side panel under the Connections section.</li> <li>Select the connector Vector - ballerinax/pinecone.vector.</li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#222-configure-the-connector","title":"2.2.2 Configure the connector","text":"<ol> <li>In the configuration of the connector, under the ApiKeyConfig select the Add Expression to open the Expression Helper window.</li> <li>Select the Configurables and click the Create new configurable variable. Here we create <code>pinecone_api_key</code> and <code>pinecone_url</code>.</li> <li>Select the ConnectionConfig under the Construct Record in the Expression Helper window.</li> <li>Click the ApiKeysConfig in the auth, select the Configurables and click the <code>pinecone_api_key</code>.</li> <li> <p>Enter the <code>pinecone_url</code> as ServiceUrl and save it.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#223-create-a-retriever-function","title":"2.2.3 Create a retriever function","text":"<ol> <li>Click the + button in the Integrator side panel under the Functions section.</li> <li> <p>Provide the required details to create the function. Use <code>retrieveData</code> as the function name and specify the parameters and return types.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#224-implement-the-retriever-function-logic","title":"2.2.4 Implement the retriever function logic","text":"<ol> <li>Click the + button and select the <code>vectorClient</code>.</li> <li>Select Query from the vectorClient dropdown.</li> <li>Configure the vector client and specify the payload. Here, we use <code>{ topK: 4}</code> for the record QueryRequest.</li> <li>Extract the matches array from the QueryResponse.</li> <li>Handle null response scenarios with appropriate error handling.</li> <li> <p>Return the relevant matching array from the client response.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#23-augment-queries-with-relevant-chunks","title":"2.3 Augment queries with relevant chunks","text":"<p>Follow these steps to create a function that augments queries with relevant text chunks from vector search results:</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#231-create-an-augment-function","title":"2.3.1 Create an augment function","text":"<ol> <li>Click the + button in the Integrator side panel under the Functions section.</li> <li>Create the function with <code>augment</code> as the function name and specify the parameter type and return type.</li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#232-implement-the-augment-function-logic","title":"2.3.2 Implement the augment function logic","text":"<ol> <li>Create an empty string variable named <code>context</code>.</li> <li>Add a foreach loop to process each match in the input array.</li> <li>Extract metadata from each match and convert to the appropriate type.</li> <li>Concatenate the text from metadata to the context string.</li> <li> <p>Return the aggregated context string with all relevant text chunks.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#24-generate-response-using-the-context","title":"2.4 Generate response Using the context","text":""},{"location":"integration-guides/ai/rag/build-a-rag-application/#241-add-chat-client-connection","title":"2.4.1 Add chat client connection","text":"<ol> <li>Click the + button in the Integrator side panel under the Connections section.</li> <li>Select the connector Chat - ballerinax/azure.openai.chat.</li> <li>In the configuration of the connector, under the Config select the ConnectionConfig under the Construct Record in the Expression Helper window.</li> <li>Change the BearerTokenConfig to ApiKeysConfig in the auth.</li> <li>Select the Configurables and click the <code>azure_api_key</code>.</li> <li> <p>Expand the Advanced Configurations and Enter the <code>azure_service_url</code> as ServiceUrl and save it.</p> <p></p> </li> </ol> Model Flexibility<p>While this tutorial demonstrates Azure OpenAI integration, the same principles apply to other AI providers. You can adapt this implementation to work with:</p> <ul> <li>OpenAI API </li> <li>Anthropic's Claude API</li> <li>Google's PaLM API</li> <li>Local models (via APIs like Ollama)</li> <li>Other cloud AI services</li> </ul> <p>Simply replace the connector and adjust the API configuration parameters according to your chosen provider's requirements.</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#242-create-a-generate-function","title":"2.4.2 Create a generate function","text":"<ol> <li>Click the + button in the Integrator side panel under the Functions section.</li> <li>Create the function with <code>generateText</code> as the function name and specify the parameters and return types.</li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#243-implement-the-generate-function-logic","title":"2.4.3 Implement the generate function logic","text":"<ol> <li>Create variables such as <code>systemPrompt</code> and <code>chatRequest</code>.</li> <li>Click the + button and select the <code>chatClient</code>.</li> <li>Select Creates a completion for the chat message from the chatClient dropdown.</li> <li>Configure the client and specify the DeploymentId, API version, and payload.</li> <li>Return the chat response from the client.</li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#step-3-create-the-combined-llm-function","title":"Step 3: Create the combined LLM function","text":""},{"location":"integration-guides/ai/rag/build-a-rag-application/#31-create-the-llm-function","title":"3.1 Create the LLM function","text":"<ol> <li>Click the + button in the Integrator side panel under the Functions section.</li> <li> <p>Create the function with <code>llmChat</code> as the function name and specify the parameters and return types.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#32-implement-the-function-logic","title":"3.2 Implement the function logic","text":"<p>This function orchestrates the entire RAG (Retrieval-Augmented Generation):</p> <ol> <li>Get Embeddings: Call the <code>getEmbeddings</code> function with the user query to convert it into vector embeddings.</li> <li>Retrieve Data: Use the embeddings to query the vector database through the <code>retrieveData</code> function to get relevant document chunks.</li> <li>Augment Context: Process the retrieved chunks using the <code>augment</code> function to create a consolidated context string.</li> <li>Generate Response: Call the <code>generateText</code> function with both the original query and the augmented context to generate the final response.</li> <li> <p>Return Result: Return the generated response string.</p> <p></p> </li> </ol> <p>This completes the end-to-end RAG where user queries are processed through embeddings, vector search, context augmentation, and LLM generation before returning intelligent responses through the HTTP API.</p>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#step-4-integrate-with-http-service","title":"Step 4: Integrate with HTTP service","text":""},{"location":"integration-guides/ai/rag/build-a-rag-application/#41-update-the-chat-resource","title":"4.1 Update the chat resource","text":"<p>Go back to the HTTP service created in Step 1. In the <code>/chat</code> resource implementation:</p> <ol> <li>Call the <code>llmChat</code> function with the user's query.</li> <li> <p>Return the chat response.</p> <p></p> </li> </ol>"},{"location":"integration-guides/ai/rag/build-a-rag-application/#step-5-run-the-integration-and-query-the-rag","title":"Step 5: Run the integration and query the RAG","text":"<ol> <li>Click on the Run button in the top-right corner to run the integration.</li> <li>If you have added any variables to the project, you\u2019ll be prompted to update their values in the <code>Config.toml</code> file. Configure them to continue with the execution of the request.</li> <li> <p>Query the rag by sending the curl request below.</p> <pre><code>curl --location 'http://localhost:9090/personalAssistant/chat' \\\n--header 'Content-Type: application/json' \\\n--data '{\"message\": \"What is the process for reporting safety concerns?\"}'\n</code></pre> <p></p> </li> </ol> <p>Response May Vary</p> <p>Since this integration involves an LLM (Large Language Model) call, the response values may not always be identical across different executions.</p> <p>Your RAG system is now ready to answer questions using retrieved context from your vector database!</p>"},{"location":"integration-guides/file-integration/file-integration-with-directory-service/","title":"File Integration With Directory Service","text":"<p>In this section, we will learn how to create a file integration using the WSO2 Integrator: BI. The integration will listen to events in a directory and will be triggered when an file related event occurs.</p>"},{"location":"integration-guides/file-integration/file-integration-with-directory-service/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>FileIntegration</code>.</li> <li>Select Project Directory and click on the Select Location button.</li> <li>Click on the Create New Integration button to create the integration project.</li> </ol>"},{"location":"integration-guides/file-integration/file-integration-with-directory-service/#step-2-create-an-directory-service","title":"Step 2: Create an Directory service","text":"<ol> <li>In the design view, click on the Add Artifact button.</li> <li>Select Directory Service under the File Integration category.</li> <li>Enter the listener name as <code>directoryListener</code>.</li> <li>Enter the path to the directory you want to monitor. For example, <code>\"/home/user/Downloads\"</code>.</li> <li>Click on the Next button to create the directory service.</li> <li> <p>Keep the default listener in the Listener Configuration window and click on the Create button to create the directory service.</p> <p></p> </li> </ol>"},{"location":"integration-guides/file-integration/file-integration-with-directory-service/#step-3-configure-file-event-resources","title":"Step 3: Configure file event resources","text":"<ol> <li>Navigate to the <code>directoryListener</code> service  under the Entry Points section and click on the +Function  button.</li> <li>Select onCreate from Available Functions dropdown and click on the Save button.</li> <li>Click on the onCreate function to navigate to the function implementation designer view.</li> <li>Click on + and select Log Info from the node panel under Logging category.</li> <li>Add the log message as <code>\"File created \"+ event.name</code> in the Msg field.</li> <li> <p>Click on the Save button to add the log action to the function.</p> <p></p> </li> <li> <p>Repeat the above steps to add the onDelete and onModify functions to the service.</p> </li> <li>Add the log message as <code>\"File deleted \"+ event.name</code> in the Msg field for the onDelete function.</li> <li>Add the log message as <code>\"File modified \"+ event.name</code> in the Msg field for the onModify function.</li> <li> <p>The final service will look like this:      </p> <p></p> </li> </ol>"},{"location":"integration-guides/file-integration/file-integration-with-directory-service/#step-4-run-the-integration","title":"Step 4: Run the integration","text":"<ol> <li>Click on the Run button in the top-right corner to run the integration.</li> <li>The integration will start listening to the events in the directory specified in step 2. </li> <li>Create a new file in the directory to trigger the onCreate event.</li> <li>Modify the file to trigger the onModify event.</li> <li>Delete the file to trigger the onDelete event.</li> <li> <p>The log messages will be displayed in the console.   </p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/","title":"Content-Based Message Routing","text":""},{"location":"integration-guides/integration-as-api/message-routing/#overview","title":"Overview","text":"<p>In this tutorial, you'll create a service that allows users to reserve appointments at various hospitals. Requests will be directed to the appropriate hospital based on the request payload's content. To accomplish this, you\u2019ll build a REST service with a single resource in WSO2 Integrator: BI extension. The resource will handle user requests, identify the hospital endpoint based on the hospital ID, forward the request to the specified hospital service to make the reservation, and return the reservation details.</p> <p>Here\u2019s an overview of the process flow.</p> <p></p> <ol> <li> <p>Receive a request with a JSON payload similar to the following.</p> <p>ReservationRequest.json<pre><code>{\n\"patient\": {\n\"name\": \"John Doe\",\n\"dob\": \"1940-03-19\",\n\"ssn\": \"234-23-525\",\n\"address\": \"California\",\n\"phone\": \"8770586755\",\n\"email\": \"johndoe@gmail.com\"\n},\n\"doctor\": \"thomas collins\",\n\"hospital\": \"grand oak community hospital\",\n\"hospital_id\": \"grandoak\",\n\"appointment_date\": \"2023-10-02\"\n}\n</code></pre> 2. Extract the <code>hospital_id</code> field and select the corresponding hospital service endpoint.</p> <ul> <li>grandoak -&gt; <code>http://localhost:9090/grandoak/categories</code></li> <li>clemency -&gt; <code>http://localhost:9090/clemency/categories</code></li> <li>pinevalley -&gt; <code>http://localhost:9090/pinevalley/categories</code> </li> </ul> </li> <li> <p>Forward the request to the selected hospital service and retrieve the response which will be similar to the following.</p> ReservationResponse.json<pre><code>{\n\"appointmentNumber\": 8,\n\"doctor\": {\n\"name\": \"thomas collins\",\n\"hospital\": \"grand oak community hospital\",\n\"category\": \"surgery\",\n\"availability\": \"9.00 a.m - 11.00 a.m\",\n\"fee\": 7000.0\n},\n\"patientName\": \"John Doe\",\n\"hospital\": \"grand oak community hospital\",\n\"confirmed\": false,\n\"appointmentDate\": \"2023-10-02\"\n}\n</code></pre> </li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker installed on your machine.</li> </ul>"},{"location":"integration-guides/integration-as-api/message-routing/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>MessageRouting</code>.</li> <li>Select Project Directory and click on the Select Location button.</li> <li>Click on the Create New Integration button to create the integration project.</li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/#step-2-create-an-http-service","title":"Step 2: Create an HTTP service","text":"<ol> <li>In the design view, click on the Add Artifact button.</li> <li>Select HTTP Service under the Integration as API category.</li> <li>Select the + Listeners option from the Listeners dropdown to add a new listener.</li> <li>Enter the listener name as <code>healthListener</code>, <code>8290</code> as the port and click on the Save button. </li> <li>Add the service base path as <code>/healthcare</code> and select the Design from Scratch option as the The contract of the service.</li> <li>Click on the Create button to create the new service with the specified configurations.</li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/#step-3-define-types","title":"Step 3: Define types","text":"<ol> <li>Click on the Add Artifacts button and select Type in the Other Artifacts section.</li> <li>Click on + Add Type to add a new type</li> <li>Add the Record Name as <code>ReservationRequest</code> and paste the following JSON payload. Select Make Separate Record Definitions and click on the Import button.    <pre><code> {\n\"patient\": {\n\"name\": \"John Doe\",\n\"dob\": \"1940-03-19\",\n\"ssn\": \"234-23-525\",\n\"address\": \"California\",\n\"phone\": \"8770586755\",\n\"email\": \"johndoe@gmail.com\"\n},\n\"doctor\": \"thomas collins\",\n\"hospital\": \"grand oak community hospital\",\n\"hospital_id\": \"grandoak\",\n\"appointment_date\": \"2023-10-02\"\n}\n</code></pre></li> <li>Repeat the above steps to add a new type named <code>ReservationResponse</code> with the following JSON payload.     <pre><code>{\n\"appointmentNumber\": 8,\n\"doctor\": {\n\"name\": \"thomas collins\",\n\"hospital\": \"grand oak community hospital\",\n\"category\": \"surgery\",\n\"availability\": \"9.00 a.m - 11.00 a.m\",\n\"fee\": 7000.0\n},\n\"patientName\": \"John Doe\",\n\"hospital\": \"grand oak community hospital\",\n\"confirmed\": false,\n\"appointmentDate\": \"2023-10-02\"\n}\n</code></pre></li> <li> <p>The final Type diagram will look like below.     </p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/#step-4-add-connectors","title":"Step 4: Add connectors","text":"<ol> <li>Navigate to design view and click on the Add Artifacts button and select Connection in the Other Artifacts section.</li> <li>Search and select the HTTP Client connector.</li> <li>Enter the connector name as <code>grandOakEp</code>, URL as <code>\"http://localhost:9090/grandoak/categories\"</code>.</li> <li> <p>Click on the Save button to create the new connector with the specified configurations.</p> <p> 5. Repeat the above steps to add connectors for the <code>clemency</code> and <code>pinevalley</code> hospitals with the following configurations.</p> Connector Name URL clemencyEp <code>\"http://localhost:9090/clemency/categories\"</code> pineValleyEp <code>\"http://localhost:9090/pinevalley/categories\"</code> </li> <li> <p>The final connectors will look like below.     </p> <p></p> </li> </ol> HTTP Connector<p>To learn more about HTTP client, see Ballerina HTTP Client. See supported advanced client configurations in the HTTP Client Configurations.</p>"},{"location":"integration-guides/integration-as-api/message-routing/#step-5-add-a-resource-method","title":"Step 5: Add a resource method","text":"<ol> <li>The service will have a default resource named <code>greeting</code> with the GET method. Click on three dots appear in front of the <code>/healthCare</code> service resource and select Edit from menu.</li> <li>Then click the edit button in front of <code>/greeting</code> resource to edit the resource.</li> <li>Change the resource HTTP method to POST.</li> <li>Change the resource name as <code>categories/[string category]/reserve</code>.</li> <li>Add a payload parameter named <code>reservation</code> to the resource of type <code>ReservationRequest</code>.</li> <li>Change the 201 response return type to <code>ReservationResponse</code>.</li> <li>Add a new response of type HttpNotFound under the responses.</li> <li> <p>Click on the Save button to update the resource with the specified configurations.</p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/#step-6-add-the-routing-logic","title":"Step 6: Add the routing logic","text":"<ol> <li>Click on the <code>categories/[string category]/reserve</code> resource to navigate to the resource implementation designer view.</li> <li>Delete the default <code>Return</code> action from the resource.</li> <li>Hover to the arrow after start and click the \u2795 button to add a new action to the resource.</li> <li>Select Declare Variable from the node panel on the left. This variable will be used to store the request payload for the hospital service.</li> <li>Change the variable name to <code>hospitalRequset</code>, type as <code>json</code> and expression as below and click Save.     <pre><code>{\n    patient: reservation.patient.toJson(),\n    doctor: reservation.doctor,\n    hospital: reservation.hospital,\n    appointment_date: reservation.appointment_date\n}\n</code></pre></li> <li> <p>Add If from the node panel after <code>hospitalRequest</code> variable. Enter the conditions as If Else If blocks as below for each hospital.</p> <ul> <li>grandOak -&gt; <code>reservation.hospital_id == \"grandoak\"</code></li> <li>clemency -&gt; <code>reservation.hospital_id == \"clemency\"</code></li> <li>pineValley -&gt; <code>reservation.hospital_id == \"pinevalley\"</code> </li> </ul> <p></p> </li> <li> <p>Select the <code>grandOakEP</code> condition true path \u2795 sign and select grandOakEP connector from the node panel.</p> <p></p> </li> <li> <p>Select post from the dropdown. Then, fill in the required fields with the values given below and click Save.</p> Field Value Variable Name <code>oakEPResponse</code> Variable Type <code>ReservationResponse</code> Resource Path <code>string `/${category}/reserve`</code> message <code>hospitalRequset</code> </li> <li> <p>Click on the \u2795 sign again and select Return from the node panel. Select the <code>oakEPResponse</code> variable from the dropdown and click Save.</p> <p></p> </li> <li> <p>The steps above will add the routing logic for the <code>grandoak</code> hospital. A variable named <code>oakEPResponse</code> will store the response from the <code>grandoak</code> hospital service. The response will be returned to the client.</p> </li> <li> <p>Repeat the 7,8,9 steps for the <code>clemency</code> and <code>pinevalley</code> hospitals with the following configurations.</p> <p>clemency:</p> Field Value Variable Name <code>clemencyEPResponse</code> Variable Type <code>ReserveResponse</code> Resource Path <code>string `/${category}/reserve`</code> message <code>hospitalRequset</code> <p>pinevalley:</p> Field Value Variable Name <code>pineValleyEPResponse</code> Variable Type <code>ReserveResponse</code> Resource Path <code>string `/${category}/reserve`</code> message <code>hospitalRequset</code> </li> <li> <p>For the else condition, click on the <code>If</code> condition <code>Else</code> path \u2795 sign and add a Return from the node panel. Enter <code>http:NOT_FOUND</code> as the value and click Save.             </p> </li> <li> <p>The final design will look like below.             </p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/#step-7-run-the-service","title":"Step 7: Run the service","text":"<ol> <li>Start the backend service by executing the following command in a terminal.     <pre><code>docker run --name hospital-backend -p 9090:9090 -d anuruddhal/kola-hospital-backend\n</code></pre></li> <li>Click on the Run on the run button in the top right corner to run the service.</li> <li>The service will start and the service will be available at <code>http://localhost:8290/healthcare/categories/[category]/reserve</code>.</li> <li>Click on the Try it button to open the embedded HTTP client.</li> <li> <p>Replace the {category} with <code>surgery</code> in the resource path and enter the following JSON payload in the request body and click on the \u25b6\ufe0f button to send the request.     <pre><code>{\n\"patient\":{\n\"name\": \"John Doe\",\n\"dob\": \"1940-03-19\",\n\"ssn\": \"234-23-525\",\n\"address\": \"California\",\n\"phone\": \"8770586755\",\n\"email\": \"johndoe@gmail.com\"\n},\n\"doctor\": \"thomas collins\",\n\"hospital_id\": \"grandoak\",\n\"hospital\": \"grand oak community hospital\",\n\"appointment_date\": \"2023-10-02\"\n}\n</code></pre> </p> </li> <li> <p>The response will be similar to the following.    <pre><code>{\n\"appointmentNumber\": 1,\n\"doctor\": {\n\"name\": \"thomas collins\",\n\"hospital\": \"grand oak community hospital\",\n\"category\": \"surgery\",\n\"availability\": \"9.00 a.m - 11.00 a.m\",\n\"fee\": 7000.0\n},\n\"patient\": {\n\"name\": \"John Doe\",\n\"dob\": \"1940-03-19\",\n\"ssn\": \"234-23-525\",\n\"address\": \"California\",\n\"phone\": \"8770586755\",\n\"email\": \"johndoe@gmail.com\"\n},\n\"hospital\": \"grand oak community hospital\",\n\"confirmed\": false,\n\"appointmentDate\": \"2023-10-02\"\n}\n</code></pre></p> </li> <li>Optionally, you can test the service using curl command as below.    <pre><code> curl -X POST \"http://localhost:8290/healthcare/categories/surgery/reserve\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n \"patient\": {\n \"name\": \"John Doe\",\n \"dob\": \"1940-03-19\",\n \"ssn\": \"234-23-525\",\n \"address\": \"California\",\n \"phone\": \"8770586755\",\n \"email\": \"johndoe@gmail.com\"\n },\n \"doctor\": \"thomas collins\",\n \"hospital_id\": \"grandoak\",\n \"hospital\": \"grand oak community hospital\",\n \"appointment_date\": \"2023-10-02\"\n }'\n</code></pre></li> </ol>"},{"location":"integration-guides/integration-as-api/message-routing/#step-8-stop-the-integration","title":"Step 8: Stop the integration","text":"<ol> <li>Click on the Stop button to stop the integration.</li> <li>Stop the hospital backend server by running the following command:    <pre><code>docker stop hospital-backend\n</code></pre></li> </ol>"},{"location":"integration-guides/integration-as-api/message-transformation/","title":"Message Transformation","text":""},{"location":"integration-guides/integration-as-api/message-transformation/#overview","title":"Overview","text":"<p>This guide explains how to create a simple integration to convert a JSON payload to an XML payload using WSO2 Integrator: BI. An HTTP service with a single resource (<code>toXml</code>) will be created to accept a JSON payload and return the XML representation of the payload.</p> <p></p>"},{"location":"integration-guides/integration-as-api/message-transformation/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the Create Integration button.</li> <li>Enter the project name as <code>JsonToXml</code>.</li> <li>Select project directory location by clicking on the Select Location button.</li> <li> <p>Click on the Create Integration button to create the integration project.</p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/message-transformation/#step-2-create-a-http-service","title":"Step 2: Create a HTTP service","text":"<ol> <li>In the design view, click on the Add Artifact button.</li> <li>Select HTTP Service under the Integration as API category.</li> <li>Select the Create and use the default HTTP listener option from the Listener dropdown.</li> <li>Select Design from Scratch option as the The contract of the service.</li> <li>Specify the Service base path as <code>/convert</code>.</li> <li>Click on the Create button to create the new service with the specified configurations.</li> </ol>"},{"location":"integration-guides/integration-as-api/message-transformation/#step-3-update-the-resource-method","title":"Step 3: Update the resource method","text":"<ol> <li>The service will have a default resource named <code>greeting</code> with the GET method. Click on three dots appear in front of the <code>/convert</code> service resource and select Edit from menu.</li> <li> <p>Then click the edit button in front of <code>/greeting</code> resource.  </p> <p></p> </li> <li> <p>Change the resource HTTP method to POST.</p> </li> <li>Change the resource name as <code>toXml</code>.</li> <li>Add a payload parameter named <code>input</code> to the resource of type <code>json</code>. </li> <li>Change the 201 response return type to <code>xml</code>.</li> <li> <p>Click on the Save button to update the resource with the specified configurations.</p> <p></p> </li> </ol> <p>Resource Method</p> <p>To learn more about resources, see Ballerina Resources.</p>"},{"location":"integration-guides/integration-as-api/message-transformation/#step-4-add-the-transformation-logic","title":"Step 4: Add the transformation logic","text":"<ol> <li>Click on the <code>toXml</code> resource to navigate to the resource implementation designer view.</li> <li>Delete the default <code>Return</code> action from the resource.</li> <li>Hover to the arrow after start and click the \u2795 button to add a new action to the resource.</li> <li>Select Function Call from the node panel.</li> <li>Search for <code>json to xml</code> and select the fromJson function from the suggestions.</li> <li>Change the Variable Name to <code>xmlResult</code>, Variable Type as <code>xml</code> and JsonValue to <code>input</code>.</li> <li> <p>Click on the Save button to add the function call to the resource.</p> <p></p> </li> <li> <p>Add a new node after the <code>fromJson</code> function call and select Return from the node panel.</p> </li> <li> <p>Select the <code>xmlResult</code> variable from the dropdown and click Save.</p> <p></p> </li> </ol> <p>JSON to XML Conversion</p> <p>To learn more about json to xml conversion, see Ballerina JSON to XML conversion.</p>"},{"location":"integration-guides/integration-as-api/message-transformation/#step-5-run-the-integration","title":"Step 5: Run the integration","text":"<ol> <li>Click on the Run button in the top-right corner to run the integration.</li> <li>The integration will start and the service will be available at <code>http://localhost:9090/convert</code>.</li> <li>Click on the Try it button to open the embedded HTTP client.</li> <li>Enter the JSON payload in the request body and click on the \u25b6\ufe0f button to send the request.     <pre><code>{\n\"name\": \"John\",\n\"age\": 30,\n\"car\": \"Honda\"\n}\n</code></pre></li> <li> <p>The response will be an XML representation of the JSON payload. <code>&lt;root&gt;         &lt;name&gt;John&lt;/name&gt;         &lt;age&gt;30&lt;/age&gt;         &lt;car&gt;Honda&lt;/car&gt;     &lt;/root&gt;</code> </p> </li> <li> <p>Additionally, the service can be tested using tools like Postman or curl by sending a POST request with a JSON payload to the service endpoint.    <pre><code>curl -X POST \"http://localhost:9090/convert/toXml\" -H \"Content-Type: application/json\" -d '{\"name\":\"John\", \"age\":30, \"car\":\"Honda\"}'\n</code></pre></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/","title":"Service Orchestration","text":""},{"location":"integration-guides/integration-as-api/service-orchestration/#overview","title":"Overview","text":"<p>In this tutorial, you\u2019ll create a service to process appointment requests for hospitals. The service will call multiple backend services sequentially, using data from each call to inform the next. This approach integrates several services into one, known as service orchestration. To implement this, you\u2019ll build a REST service with a single resource in WSO2 Integrator: BI extension and then run the service. The resource will receive user requests, make the necessary backend calls, and respond with the appointment details.</p> <p>The flow is as follows.</p> <ol> <li>The user sends an appointment request to the service.     <pre><code>  {\n\"patient\": {\n\"name\": \"John Doe\",\n\"dob\": \"1940-03-19\",\n\"ssn\": \"234-23-525\",\n\"address\": \"California\",\n\"phone\": \"8770586755\",\n\"email\": \"johndoe@gmail.com\",\n\"cardNo\": \"7844481124110331\"\n},\n\"doctor\": \"thomas collins\",\n\"hospital_id\": \"grandoaks\",\n\"hospital\": \"grand oak community hospital\",\n\"appointment_date\": \"2024-11-06\"\n}\n</code></pre></li> <li>Extract necessary details from the request (e.g., hospital, patient, doctor, etc.) and make a call to the hospital backend service to request an appointment. A response similar to the following will be returned from the hospital backend service on success.      <pre><code>  {\n\"appointmentNumber\": 1,\n\"doctor\": {\n\"name\": \"thomas collins\",\n\"hospital\": \"grand oak community hospital\",\n\"category\": \"surgery\",\n\"availability\": \"9.00 a.m - 11.00 a.m\",\n\"fee\": 7000\n},\n\"patient\": {\n\"name\": \"John Doe\",\n\"dob\": \"1940-03-19\",\n\"ssn\": \"234-23-525\",\n\"address\": \"California\",\n\"phone\": \"8770586755\",\n\"email\": \"johndoe@gmail.com\"\n},\n\"hospital\": \"grand oak community hospital\",\n\"confirmed\": false,\n\"appointmentDate\": \"2023-10-02\"\n}\n</code></pre></li> <li>Use the hospital ID and the appointment number and call the hospital backend service to retrieve the fee for the appointment. The response will be similar to the following.     <pre><code>  {\n\"patientName\": \"John Doe\",\n\"doctorName\": \"thomas collins\",\n\"actualFee\": \"7000\"\n}\n</code></pre></li> <li>Finally, call the payment backend service to make the payment and retrieve the reservation status.    <pre><code>  {\n\"appointmentNo\": 2,\n\"doctorName\": \"thomas collins\",\n\"patient\": \"John Doe\",\n\"actualFee\": 7000,\n\"discount\": 20,\n\"discounted\": 5600.0,\n\"paymentID\": \"f130e2ed-a34e-4434-9b40-6a0a8054ee6b\",\n\"status\": \"settled\"\n}\n</code></pre></li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker installed on the machine.</li> </ul>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-1-create-a-new-integration-project","title":"Step 1: Create a new integration project","text":"<ol> <li>Click on the BI icon on the sidebar.</li> <li>Click on the Create New Integration button.</li> <li>Enter the project name as <code>ServiceOrchestration</code>.</li> <li>Select project directory location by clicking on the Select Location button.</li> <li>Click on the Create New Integration button to create the integration project.</li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-2-create-an-http-service","title":"Step 2: Create an HTTP service","text":"<ol> <li>In the design view, click on the Add Artifact button.</li> <li>Select HTTP Service under the Integration as API category.</li> <li>Select the + Listeners option from the Listeners dropdown to add a new listener.</li> <li>Enter the listener name as <code>healthListener</code>, <code>8290</code> as the port and click on the Save button.</li> <li>Add the service base path as <code>/healthcare</code> and select the Design from Scratch option as the The contract of the service.</li> <li> <p>Click on the Create button to create the new service with the specified configurations.</p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-3-define-types","title":"Step 3: Define types","text":"<ol> <li> <p>Click on the Add Artifacts button and select Type in the Other Artifacts section.</p> <p></p> </li> <li> <p>Click on + Add Type to add a new type  Generate record types corresponding to the response from the hospital backend service by providing a sample of the expected JSON payload. The values are given below.</p> Type Name Sample JSON value Make Separate Record Definition Record ReservationRequest <code>{\"patient\":{\"name\":\"John Doe\",\"dob\":\"1940-03-19\",\"ssn\":\"234-23-525\",\"address\":\"California\",\"phone\":\"8770586755\",\"email\":\"johndoe@gmail.com\",\"cardNo\":\"7844481124110331\"},\"doctor\":\"thomas collins\",\"hospital_id\":\"grandoaks\",\"hospital\":\"grand oak community hospital\",\"appointment_date\":\"2024-11-06\"}</code> \u2611\ufe0f Record ReservationStatus <code>{\"appointmentNo\":1, \"doctorName\":\"thomas collins\", \"patient\":\"John Doe\", \"actualFee\":7000.0, \"discount\":20, \"discounted\":5600.0, \"paymentID\":\"e560ea82-1c42-4972-a471-af5c1ad4995f\", \"status\":\"settled\"}</code> \u2611\ufe0f Record Appointment <code>{\"appointmentNumber\":12345,\"doctor\":{\"name\":\"Dr. Alice Carter\",\"hospital\":\"Green Valley Hospital\",\"category\":\"Cardiology\",\"availability\":\"Mon-Fri, 9 AM - 5 PM\",\"fee\":200},\"patientName\":\"Emma Johnson\",\"hospital\":\"Green Valley Hospital\",\"confirmed\":true,\"appointmentDate\":\"2024-11-20T10:00:00\"}</code> \u2611\ufe0f Record Fee <code>{\"patientName\":\"Emma Johnson\",\"doctorName\":\"Dr. Alice Carter\",\"actualFee\":\"150.00\"}</code> </li> <li> <p>The final types will look like the following.   </p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-4-add-connections","title":"Step 4: Add connections","text":"<ol> <li>Navigate to design view and click on the Add Artifacts button and select Connection in the Other Artifacts section.</li> <li>Search and select the HTTP Client connector.</li> <li> <p>Enter the connector name as <code>hospitalEp</code>, URL as <code>http://localhost:9090</code> and click on the Save button.</p> <p></p> </li> <li> <p>Add another connector for the payment backend service with the URL <code>http://localhost:9090/healthcare/payments</code> and the name <code>paymentEp</code>.    </p> <p></p> </li> </ol> HTTP Connector<p>To learn more about HTTP client, see Ballerina HTTP Client. See supported client configurations in the HTTP Client Configurations.</p>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-5-design-the-resource","title":"Step 5: Design the resource","text":"<ol> <li>The service will have a default resource named <code>greeting</code> with the GET method. Click on three dots appear in front of the <code>/healthCare</code> service resource and select Edit from menu.</li> <li>Change the resource HTTP method to POST.</li> <li>Change the resource name as <code>categories/[string category]/reserve</code>.</li> <li>Add a payload parameter named <code>reservation</code> to the resource of type <code>ReservationRequest</code>.</li> <li>Change the 201 response return type to <code>ReservationStatus</code>.</li> <li> <p>Add a new response of type HttpNotFound under the responses.   </p> <p></p> </li> <li> <p>Click on the Save button to save the resource.   </p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-6-make-the-appointment-request","title":"Step 6: Make the appointment request","text":"<ol> <li>Click on the <code>categories/[string category]/reserve</code> resource to navigate to the resource implementation designer view.</li> <li>Delete the default <code>Return</code> action from the resource.</li> <li>Hover to the arrow after start and click the \u2795 button to add a new action to the resource.</li> <li>Select Declare Variable from the node panel on the left. This variable will be used to store the request payload for the hospital service.</li> <li>Change the variable name to <code>hospitalRequest</code>, type as <code>json</code> and expression as below.     <pre><code>     {\n     patient:{\n         name: reservation.patient.name,\n         dob: reservation.patient.dob,\n         ssn: reservation.patient.ssn,\n         address: reservation.patient.address,\n         phone: reservation.patient.phone,\n         email: reservation.patient.email\n      },\n     doctor: reservation.doctor,\n     hospital: reservation.hospital,\n     appointment_date: reservation.appointment_date\n    }\n</code></pre></li> <li> <p>Click on the Save button to add the variable.   </p> <p></p> </li> <li> <p>Click \u2795 sign and select hospitalServicesEp connector from the node panel and select post from the dropdown. Then, fill in the required fields with the values given below and click Save.</p> Field Value Variable Name <code>appointment</code> Variable Type <code>Appointment</code> Resource Path <code>string `/${reservation.hospital_id}/categories/${category}/reserve`</code> message <code>hospitalRequest</code> </li> <li> <p>The connector action will look like the following.   </p> <p> </p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-7-get-the-fee","title":"Step 7: Get the fee","text":"<ol> <li> <p>Declare an int  variable named <code>appointmentNumber</code> with expression <code>appointment.appointmentNumber</code> after the hospital service request.  </p> <p> </p> </li> <li> <p>Let's add another connector invocation to get the fee for the appointment. Click on the \u2795 sign and select hospitalServicesEp connector from the node panel.  </p> </li> <li> <p>Select get from the dropdown. Then, fill in the required fields with the values given below and click Save.</p> Field Value Variable Name <code>fee</code> Variable Type <code>Fee</code> Resource Path <code>string `/${reservation.hospital_id}/categories/appointments/${appointmentNumber}/fee`</code> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-8-make-the-payment","title":"Step 8: Make the payment","text":"<ol> <li>Declare a decimal type variable named <code>actualFee</code> with expression <code>check decimal:fromString(fee.actualFee)</code> after the fee request. </li> <li> <p>Create another new to prepare the payment request. Click on the \u2795 sign and select Declare Variable from the node panel. Add a variable named <code>paymentRequest</code> with the type json and expression as below.    <pre><code>{\n  appointmentNumber: appointmentNumber,\n  doctor: appointment.doctor.toJson(),\n  patient: check hospitalRequest.patient,\n  fee: actualFee,\n  confirmed: false,\n  card_number: reservation.patient.cardNo\n }\n</code></pre> </p> </li> <li> <p>Let's add another connector action to make the payment. Click on the \u2795 sign and select paymentEP connector from the node panel. Select post from the dropdown.   </p> <p></p> </li> <li> <p>Then, fill in the required fields with the values given below and click Save.</p> Field Value Variable Name <code>status</code> Variable Type <code>ReservationStatus</code> Resource Path <code>\"/\"</code> message <code>paymentRequest</code> </li> <li> <p>Click on the \u2795 sign and select Return from the node panel. Add the <code>status</code> variable to the return node.</p> </li> <li> <p>The final integration will look like the following.   </p> <p></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-9-run-the-service","title":"Step 9: Run the service","text":"<ol> <li>Click on the Run button to start the service.</li> <li>Start the backend service by executing the following command in a terminal.     <pre><code>docker run --name hospital-backend -p 9090:9090 -d anuruddhal/kola-hospital-backend\n</code></pre></li> <li>Click on the Run  on the run button (\u25b6\ufe0f) in the top right corner to run the service.</li> <li>The service will start and the service will be available at <code>http://localhost:8290/healthcare/categories/[category]/reserve</code>.</li> <li>Click on the Try it button to open the embedded HTTP client.</li> <li>Replace the {category} with <code>surgery</code> in the resource path and enter the following JSON payload in the request body and click on the \u25b6\ufe0f button to send the request.     <pre><code>    {\n\"patient\": {\n\"name\": \"John Doe\",\n\"dob\": \"1940-03-19\",\n\"ssn\": \"234-23-525\",\n\"address\": \"California\",\n\"phone\": \"8770586755\",\n\"email\": \"johndoe@gmail.com\",\n\"cardNo\": \"7844481124110331\"\n},\n\"doctor\": \"thomas collins\",\n\"hospital_id\": \"grandoak\",\n\"hospital\": \"grand oak community hospital\",\n\"appointment_date\": \"2023-10-02\"\n}\n</code></pre></li> <li> <p>The response will be similar to the following.    <pre><code> {\n\"appointmentNo\": 1,\n\"doctorName\": \"thomas collins\",\n\"patient\": \"John Doe\",\n\"actualFee\": 7000,\n\"discount\": 20,\n\"discounted\": 5600,\n\"paymentID\": \"b219c4ad-5365-4a22-ae35-048bb8e570e7\",\n\"status\": \"settled\"\n}\n</code></pre></p> <p> </p> </li> <li> <p>You can also test the service using the curl command.    <pre><code> curl -X POST \"http://localhost:8290/healthcare/categories/surgery/reserve\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n   \"patient\": {\n     \"name\": \"John Doe\",\n     \"dob\": \"1940-03-19\",\n     \"ssn\": \"234-23-525\",\n     \"address\": \"California\",\n     \"phone\": \"8770586755\",\n     \"email\": \"johndoe@gmail.com\",\n     \"cardNo\": \"7844481124110331\"\n   },\n   \"doctor\": \"thomas collins\",\n   \"hospital_id\": \"grandoak\",\n   \"hospital\": \"grand oak community hospital\",\n   \"appointment_date\": \"2023-10-02\"\n }'\n</code></pre></p> </li> </ol>"},{"location":"integration-guides/integration-as-api/service-orchestration/#step-10-stop-the-integration","title":"Step 10: Stop the integration","text":"<ol> <li>Click on the Stop button to stop the integration or press <code>Shift</code> + <code>F5</code>.</li> <li>Stop the hospital backend server by running the following command:    <pre><code>docker stop hospital-backend\n</code></pre></li> </ol>"},{"location":"observability-and-monitoring/monitoring-with-wso2-integrator-icp/","title":"Monitoring with WSO2 Integrator: ICP","text":"<p>The WSO2 Integrator: ICP monitors the runtime artifacts in a deployment. It provides a graphical view of the integration artifacts that are deployed. In this guide, you will learn how to enable ICP for an integration developed using WSO2 Integrator: BI.</p>"},{"location":"observability-and-monitoring/monitoring-with-wso2-integrator-icp/#prerequisites","title":"Prerequisites","text":"<ol> <li>Java 11 or later versions should be installed on your machine.</li> <li>You must set your <code>JAVA_HOME</code> environment variable to point to the directory where the Java Development Kit (JDK) is installed on the computer.</li> </ol>"},{"location":"observability-and-monitoring/monitoring-with-wso2-integrator-icp/#step-1-download-and-start-icp-server","title":"Step 1: Download and start ICP server","text":"<ol> <li>Go to the WSO2 Integrator: ICP web page. </li> <li>Click Download. </li> <li>Provide the necessary details. </li> <li>Click Zip Archive to download the ICP as a ZIP file. </li> <li>Extract the archive file to a dedicated directory for the ICP, which will hereafter be referred to as <code>&lt;ICP_HOME&gt;</code>.</li> <li>Open a terminal and navigate to the <code>&lt;ICP_HOME&gt;/bin</code> folder.</li> <li>Execute one of the commands given below.</li> </ol> On MacOS/LinuxOn Windows <pre><code>./dashboard.sh\n</code></pre> <pre><code>dashboard.bat\n</code></pre>"},{"location":"observability-and-monitoring/monitoring-with-wso2-integrator-icp/#step-2-access-the-icp-dashboard","title":"Step 2: Access the ICP dashboard","text":"<ol> <li>Open a web browser and navigate to https://localhost:9743/dashboard.</li> <li> <p>Log in using the default credentials: </p> <ul> <li>Username: <code>admin</code></li> <li>Password: <code>admin</code></li> </ul> <p></p> </li> </ol>"},{"location":"observability-and-monitoring/monitoring-with-wso2-integrator-icp/#step-3-deploy-the-integration","title":"Step 3: Deploy the integration","text":"<ol> <li>Navigate to the Visualizer view by clicking on the BI icon on the sidebar.</li> <li> <p>Check Enable ICP under the Integration Control Plane section in the right panel.</p> <p></p> </li> <li> <p>Click on the Run button to start the integration. </p> </li> <li> <p>Click on the Create Config.toml on the prompt to create the <code>Config.toml</code> file.</p> <p></p> </li> <li> <p>Replace the <code>Config.toml</code> file content with the following configurations.   </p> <pre><code>  [ballerinax.wso2.controlplane.dashboard]\nurl = \"https://localhost:9743/dashboard/api\"\nheartbeatInterval = 10\ngroupId = \"cluster1\"\nmgtApiUrl =\"https://localhost:9264/management/\"\n</code></pre> </li> <li> <p>Click on the Run button to start the integration.  </p> <p></p> </li> <li> <p>A log message will be displayed in the console indicating that the integration is connected to the ICP dashboard.  </p> <pre><code>time=2025-03-17T15:14:59.970+05:30 level=INFO module=ballerinax/wso2.controlplane message=\"Connected to dashboard server https://localhost:9743/dashboard/api\"\n</code></pre> </li> </ol>"},{"location":"observability-and-monitoring/monitoring-with-wso2-integrator-icp/#step-4-view-the-integration-in-the-icp-dashboard","title":"Step 4: View the integration in the ICP dashboard","text":"<ol> <li>Go to the ICP dashboard and log in https://localhost:9743/dashboard.</li> <li>In the dashboard, you will see the integration details.</li> <li> <p>Click on the node to view the node details.   </p> <p></p> </li> <li> <p>Click on the Services to view the listener and resources of the service. </p> <p></p> </li> <li> <p>Click on the Listeners to view details of the listener.</p> <p></p> </li> </ol>"},{"location":"observability-and-monitoring/observability-with-devant/","title":"Observability with Devant","text":"<p>Integrations developed with WSO2 Integrator: BI can be deployed to Devant, where built-in observability tools provide deep insights into service behavior and performance. Refer to the Deploy to Devant guide for instructions on deploying to Devant. The Devant observability dashboard provides a comprehensive interface to visualize and monitor the performance of services deployed on Devant.</p> <p> </p> <p>The Observability dashboard allows you to:</p> <ul> <li>View runtime logs generated over a specific timeframe.</li> <li>Observe the throughput and latencies of requests served over a given period.</li> <li>Observe the CPU and memory usage over a given period.</li> <li>Compare metrics side-by-side to facilitate efficient diagnosis.</li> </ul>"},{"location":"observability-and-monitoring/observability-with-devant/#logs","title":"Logs","text":"<p>The Logs pane serves as a centralized view to observe logs of the integrations you deploy on Devant. This facilitates rigorous troubleshooting and analysis.</p> <p> </p>"},{"location":"observability-and-monitoring/observability-with-devant/#metrics","title":"Metrics","text":"<p>The Metrics pane provides a graphical representation of the following metrics:</p> <ul> <li>Request per minute</li> <li>Latency</li> <li>Memory usage</li> <li>CPU usage</li> <li>Data transfer</li> <li>Disk usage</li> </ul> <p> </p> <p>By default, Devant renders this graph for the data generated within the past 24 hours. You can change the default time window by selecting the time range and zone from the options bar. To expand the graph, click and drag the cursor over the period you want to drill down.</p> <p>You can view the Devant service logs in the Runtime Logs pane below the metrics. Clicking on a graph updates the Runtime Logs view to contain the corresponding log entries generated at that time. You can use these logs to identify the reasons for any anomalies you detect using the graph.</p>"},{"location":"observability-and-monitoring/overview/","title":"Overview of Observability and Monitoring","text":"<p>Observability is a measure of how well the internal states of a system can be understood from its external outputs.</p> <p>In BI, observability is a core feature that helps monitor, debug, and optimize integration services. It focuses on the following three key pillars:</p> <p>Metrics \u2013 Numeric data collected and aggregated over time to monitor system performance.</p> <p>Tracing \u2013 Tracking the flow of requests or messages through various services and components, from entry to exit.</p> <p>Logging \u2013 Text-based records of application behavior, annotated with timestamps and contextual information.</p> <p>Observability platforms allow developers and operators to gain insight into system behavior, troubleshoot issues, and ensure reliability in production deployments.</p>"},{"location":"observability-and-monitoring/overview/#observability-in-bi","title":"Observability in BI","text":"<p>BI provides built-in support for observability across its runtime. Integration services, APIs, and connectors emit rich telemetry data that can be exported to standard monitoring tools.</p>"},{"location":"observability-and-monitoring/overview/#available-observability-options","title":"Available Observability Options","text":"<p>BI supports multiple options for observing and monitoring deployed integrations. Depending on the deployment environment and the level of visibility required, you can choose from the following observability solutions.</p>"},{"location":"observability-and-monitoring/overview/#1-wso2-integrator-icp-integration-control-plane","title":"1. WSO2 Integrator: ICP (Integration Control Plane)","text":"<p>The WSO2 Integrator: ICP provides centralized monitoring and management of runtime artifacts across a deployment. It offers a graphical interface to view deployed integration artifacts and their relationships, enabling teams to,</p> <ul> <li>Track the status and availability of deployed services.</li> <li>View runtime metadata and node-level details.</li> <li>Manage and visualize the health of integration components across environments.</li> </ul> <p>This is ideal for teams that manage integrations across hybrid or distributed environments and require control-plane-level visibility. Refer to Monitoring with WSO2:Integrator ICP for further details.</p>"},{"location":"observability-and-monitoring/overview/#2-devant-by-wso2","title":"2. Devant by WSO2","text":"<p>Devant is WSO2\u2019s AI-powered Integration Platform as a Service (iPaaS). When BI integrations are deployed to Devant, the platform provides built-in observability capabilities, including the following.</p> <ul> <li>A unified dashboard for visualizing service performance and metrics.</li> <li>Insight into request flow, throughput, latency, and error rates.</li> <li>AI-powered analytics to detect anomalies and optimize system performance.</li> </ul> <p>Devant observability is suitable for cloud-native teams looking for a fully managed, intelligent monitoring experience. Refer to Observability with Devant for further details.</p>"},{"location":"observability-and-monitoring/overview/#3-integration-with-third-party-observability-tools","title":"3. Integration with Third-Party Observability Tools","text":"<p>BI is designed to work seamlessly with standard observability stacks. You can integrate your deployments with tools like,</p> <ul> <li>Prometheus and Grafana for metrics collection and visualization.</li> <li>Jaeger for distributed tracing.</li> <li>ELK for centralized logging.</li> </ul> <p>These integrations provide flexibility for teams already invested in their own observability ecosystems and allow for consistent monitoring practices across different services and platforms. Refer to Supported Observability Tools and Platforms for further details.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/","title":"Observe metrics and tracing using Datadog","text":"<p>The sample shop service will be used in this guide. Follow the steps given below to observe BI tracing and metrics in Datadog.</p> <p>Create a new account in Datadog. Select a billing plan according to your needs (A free plan is also included).</p> <p>Then follow the steps below to set up your Datadog account to view metrics and tracing provided by Ballerina.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-1-create-a-datadog-account-and-an-api-key","title":"Step 1 - Create a Datadog account and  an API key","text":"<ol> <li> <p>Add Prometheus to the Integrations for your account</p> <p>You need to add Prometheus in the Integrations. Please go to the Integrations tab and search for Prometheus.</p> <p></p> </li> <li> <p>Create an API key</p> <p>You need to create an API key for the Datadog agent. To create an API key, <code>Click Profile \u2192 Organization Settings \u2192 API keys</code></p> <p></p> </li> </ol>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-2-set-up-the-datadog-agent","title":"Step 2 - Set up the Datadog agent","text":"<p>After setting up your Datadog account, you need to set up a Datadog Agent in your instance.</p> <p>You can follow this documentation to get started with the Datadog agent on your local machine.</p> <p>You need to include the API key you generated in your Datadog account to <code>datadog.yaml</code> in the <code>datadog-agent/etc</code> folder.</p> <p>Then follow the steps below to configure metrics and tracing data publishing to Datadog.</p> <ol> <li> <p>Add configuration for metrics</p> <p>Once you add Prometheus by following <code>step 1</code>, you will get a guide to configure a Datadog agent in your instance.</p> <p></p> <p>You can follow the instructions given in the above configuration to set up a Datadog agent.</p> <p>A sample of the <code>conf.yaml</code> file which you should include in the prometheus.d folder can be found here.</p> <pre><code>```yaml\ninit_config:\n\ninstances:\n- prometheus_url: http://localhost:9797/metrics\n    namespace: ballerina\n    metrics:\n    - response_time_seconds_value\n    - response_time_seconds_max\n    - response_time_seconds_min \n    - response_time_seconds_mean  \n    - response_time_seconds_stdDev\n    - response_time_seconds\n    - response_time_nanoseconds_total_value\n    - requests_total_value\n    - response_errors_total_value \n    - inprogress_requests_value\n    - kafka_publishers_value\n    - kafka_consumers_value\n    - kafka_errors_value  \n    headers:\n    Accept: \"text/plain; version=0.0.4\"\n```</code></pre> </li> <li> <p>Add configuration for tracing</p> <p>You need to use the following configurations in the <code>datadog.yaml</code>.</p> <p>To view traces in Datadog, we need to enable the APM (Application Performance Monitoring) in your Datadog agent.</p> <pre><code>apm_config:\nenabled: true\n</code></pre> <p>BI uses OpenTelemetry to provide traces. Therefore, we need to set up OpenTelemetry configurations as follows.</p> <pre><code>otlp_config:\nreceiver:\nprotocols:\ngrpc:\nendpoint: 0.0.0.0:4317\n</code></pre> </li> </ol>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-3-import-prometheus-and-jaeger-extensions-for-bi","title":"Step 3 - Import Prometheus and Jaeger extensions for BI","text":"<p>To include the Prometheus and Jaeger extensions into the executable, the <code>ballerinax/prometheus</code> and <code>ballerinax/jaeger</code> modules need to be imported into your BI project. Navigate to <code>file explorer</code> and add the following to the <code>main.bal</code> file.</p> <pre><code>import ballerinax/prometheus as _;\nimport ballerinax/jaeger as _;\n</code></pre> <p>To support Prometheus as the metrics reporter, an HTTP endpoint starts with the context of <code>/metrics</code> in default port 9797 when starting the Ballerina service.</p> <p>Jaeger extension has an <code>Opentelemetry GRPC Span Exporter</code> which will push tracing data as batches to the endpoint (default - http://localhost:4317) in opentelemetry format.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-4-configure-bi-runtime-configurations","title":"Step 4 - Configure BI runtime configurations","text":"<p>Tracing and metrics can be enabled in your BI project using configurations similar to the following.  Navigate to <code>file explorer</code> and add the following to the <code>Config.toml</code> file.</p> <pre><code>[ballerina.observe]\ntracingEnabled=true\ntracingProvider=\"jaeger\"\nmetricsEnabled=true\nmetricsReporter=\"prometheus\"\n\n[ballerinax.prometheus]\nport=9797\nhost=\"0.0.0.0\"\n\n[ballerinax.jaeger]\nagentHostname=\"localhost\"\nagentPort=4317\nsamplerType=\"const\"\nsamplerParam=1.0\nreporterFlushInterval=2000\nreporterBufferSize=1000\n</code></pre> <p>The table below provides the descriptions of each configuration option and possible values that can be assigned.</p> Configuration key Description Default value Possible values ballerinax.prometheus. port The value of the port to which the '/metrics' service will bind. This service will be used by Prometheus to scrape the information of the Ballerina service. <code>9797</code> Any suitable value for port 0 - 0 - 65535. However, within that range, ports 0 - 1023 are generally reserved for specific purposes, therefore it is advisable to select a port without that range. ballerinax.prometheus. host The name of the host to which the '/metrics' service will bind. This service will be used by Prometheus to scrape the information of the Ballerina service. <code>0.0.0.0</code> IP or Hostname or 0.0.0.0 of the node in which the Ballerina service is running. ballerinax.jaeger. agentHostname Hostname of the Jaeger agent localhost IP or hostname of the Jaeger agent. If it is running on the same node as Ballerina, it can be localhost. ballerinax.jaeger. agentPort Port of the Jaeger agent 4317 The port on which the Jaeger agent is listening. ballerinax.jaeger. samplerType Type of the sampling methods used in the Jaeger tracer. const <code>const</code>, <code>probabilistic</code>, or <code>ratelimiting</code>. ballerinax.jaeger. samplerParam It is a floating value. Based on the sampler type, the effect of the sampler param varies 1.0 For <code>const</code> <code>0</code> (no sampling) or <code>1</code> (sample all spans), for <code>probabilistic</code> <code>0.0</code> to <code>1.0</code>, for <code>ratelimiting</code> any positive integer (rate per second). ballerinax.jaeger. reporterFlushInterval The Jaeger client will be sending the spans to the agent at this interval. 2000 Any positive integer value. ballerinax.jaeger. reporterBufferSize Queue size of the Jaeger client. 1000 Any positive integer value."},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-5-run-the-service","title":"Step 5 - Run the service","text":"<p>When observability is enabled, the BI runtime collects tracing and metrics data and will be published to Datadog.</p> <p>Start the BI service using the <code>Run</code> option in the top right corner. You will see the following logs.</p> <pre><code>Compiling source\n\nRunning executable\n\nballerina: started Prometheus HTTP listener 0.0.0.0:9797\nballerina: started publishing traces to Jaeger on localhost:4317\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-6-send-requests","title":"Step 6 - Send requests","text":"<p>Send requests to http://localhost:8090/shop/products.</p> <p>Example cURL commands:</p> <p><pre><code>$ curl -X GET http://localhost:8090/shop/products\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/product \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"id\": 4, \n    \"name\": \"Laptop Charger\", \n    \"price\": 50.00\n}'\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/order \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"productId\": 1, \n    \"quantity\": 1\n}'\n</code></pre> <pre><code>$ curl -X GET http://localhost:8090/shop/order/0\n</code></pre></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-7-view-metrics-on-datadog","title":"Step 7 - View metrics on Datadog","text":"<p>You can observe the metrics in the Datadog platform under the <code>Metrics</code> tab in the left navigation.</p> <p></p> <p>You can add filters and use functions in the Datadog to visualize what you want with the metrics provided by BI.</p> <p>Ballerina provides a dashboard in the Datadog to observe metrics in Ballerina applications.</p> <p>You can add a new dashboard in the Datadog under the <code>Dashboards</code> tab in the left navigation. After creating the new dashboard, go to the <code>Configure</code> tab in the dashboard. Import the <code>dashboard.json</code> file provided above.</p> <p></p> <p>The Ballerina Dashboard in the Datadog will be displayed as below.</p> <p></p> <p></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/datadog/#step-8-view-tracing-on-datadog","title":"Step 8 - View tracing on Datadog","text":"<p>To view traces of the BI application, go to APM \u2192 Traces in the Datadog.</p> <p></p> <p>You can filter the traces with the service name, resource, operation name, span kind, etc.</p> <p></p> <p>Once you select a trace, you can get more information with the tags attached to the span.</p> <p></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/elastic-stack/","title":"Observe logs using Elastic Stack","text":"<p>In BI, distributed logging and analysis are supported by the Elastic Stack. BI has a log module for logging into the console. To monitor the logs, the BI standard output needs to be redirected to a file.</p> <p>The Elastic Stack comprises the following components.</p> <ol> <li>Beats - Multiple agents that ship data to Logstash or Elasticsearch. In our context, Filebeat will ship the BI logs to Logstash. Filebeat should be a container running on the same host as the BI service. This is so that the log file (ballerina.log) can be mounted to the Filebeat container.</li> <li>Logstash - Used to process and structure the log files received from Filebeat and send them to Elasticsearch.</li> <li>Elasticsearch - Storage and indexing of the logs sent by Logstash.</li> <li>Kibana - Visualizes the data stored in Elasticsearch.</li> </ol> <p>The sample shop service will be used in this guide. Follow the steps given below to observe BI logs in Elastic Stack.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/elastic-stack/#step-1-set-up-elastic-stack","title":"Step 1 - Set up Elastic Stack","text":"<p>Elasticsearch and Kibana are provided as Cloud services. Alternatively, Docker containers can be used to set up Elasticsearch and Kibana as well.</p> <ol> <li> <p>Download the Docker images using the following commands.</p> <pre><code># Elasticsearch Image\n$ docker pull docker.elastic.co/elasticsearch/elasticsearch:8.15.2\n# Kibana Image\n$ docker pull docker.elastic.co/kibana/kibana:8.15.2\n# Filebeat Image\n$ docker pull docker.elastic.co/beats/filebeat:8.15.2\n# Logstash Image\n$ docker pull docker.elastic.co/logstash/logstash:8.15.2\n</code></pre> </li> <li> <p>Start Elasticsearch and Kibana containers by executing the following commands.</p> <pre><code>$ docker run -p 9200:9200 -p 9300:9300 -it -h elasticsearch --name elasticsearch docker.elastic.co/elasticsearch/elasticsearch:8.15.2\n$ docker run -p 5601:5601 -h kibana --name kibana --link elasticsearch:elasticsearch docker.elastic.co/kibana/kibana:8.15.2\n</code></pre> <p>If you are using Linux, you may have to increase the <code>vm.max_map_count</code> for the Elasticsearch container to start.  Execute the following command to do that.</p> <pre><code>$ sudo sysctl -w vm.max_map_count=262144\n</code></pre> </li> <li> <p>Create a <code>logstash.conf</code> file in the <code>/tmp/pipeline/</code> directory and include the following content in the file.</p> <pre><code>input {\n  beats {\n    port =&gt; 5044\n    }\n}\nfilter {\n  grok  {\n    match =&gt; { \"message\" =&gt; \"%{TIMESTAMP_ISO8601:date}%{SPACE}%{WORD:logLevel}%{SPACE}\\[%{GREEDYDATA:module}\\]%{SPACE}\\-%{SPACE}%{GREEDYDATA:logMessage}\"}\n  }\n}\noutput {\n    elasticsearch {\n        hosts =&gt; \"elasticsearch:9200\"\n        index =&gt; \"ballerina\"\n      document_type =&gt; \"ballerina_logs\"\n    }\n}\n</code></pre> <p>Here, the 3 stages are specified in the pipeline. Input is specified as beats and listens to port 5044.  A Grok filter is used to structure the Ballerina logs and the output is specified to push to Elasticsearch on <code>elasticsearch:9200</code>.</p> </li> <li> <p>Start the Logstash container by executing the following command.</p> <pre><code>$ docker run -h logstash --name logstash --link elasticsearch:elasticsearch -it --rm -v /tmp/pipeline:/usr/share/logstash/pipeline/ -p 5044:5044 docker.elastic.co/logstash/logstash:8.15.2\n</code></pre> </li> <li> <p>Configure Filebeat to ship the Ballerina logs. Create a <code>filebeat.yml</code> file in the <code>/tmp/</code> directory and include the following content in the file.</p> <pre><code>filebeat.prospectors:\n- type: log\n  paths:\n    - /usr/share/filebeat/ballerina.log\noutput.logstash:\n  hosts: [\"logstash:5044\"]\n</code></pre> </li> <li> <p>Start the Filebeat container with the following command.</p> <pre><code>$ docker run -v /tmp/filebeat.yml:/usr/share/filebeat/filebeat.yml -v /&lt;path-to-ballerina.log&gt;/ballerina.log:/usr/share/filebeat/ballerina.log --link logstash:logstash docker.elastic.co/beats/filebeat:8.15.2\n</code></pre> <p>The <code>-v</code> flag is used for bind mounting, where the container will read the file from the host machine. Provide the path to the <code>ballerina.log</code> file to be bind-mounted to the filebeat container.</p> </li> </ol>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/elastic-stack/#step-2-run-ballerina-service","title":"Step 2 - Run Ballerina Service","text":"<p>This can be done by running the Ballerina service using the <code>Run</code> option in BI.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/elastic-stack/#step-3-send-requests","title":"Step 3 - Send requests","text":"<p>Send requests to <code>http://localhost:8090/shop/products</code>.</p> <p>Example cURL commands:</p> <p><pre><code>$ curl -X GET http://localhost:8090/shop/products\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/product \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"id\": 4, \n    \"name\": \"Laptop Charger\", \n    \"price\": 50.00\n}'\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/order \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"productId\": 1, \n    \"quantity\": 1\n}'\n</code></pre> <pre><code>$ curl -X GET http://localhost:8090/shop/order/0\n</code></pre></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/elastic-stack/#step-4-view-logs-on-kibana","title":"Step 4 - View logs on Kibana","text":"<p>Access Kibana to visualize the logs at <code>http://localhost:5601</code>. Add an index named <code>ballerina</code> and click on <code>Discover</code> to visualize the logs.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/jaeger/","title":"Observe tracing using Jaeger","text":"<p>The sample shop service will be used in this guide. Follow the steps given below to observe tracing for BI application in Jaeger.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/jaeger/#step-1-set-up-jaeger","title":"Step 1 - Set up Jaeger","text":"<p>You can configure BI project to support distributed tracing with Jaeger. This section focuses on configuring Jaeger with Docker as a quick installation.</p> Tip<p>There are many possible ways to deploy Jaeger. For more information, see Jaeger Deployment. The easiest option is to use executable binaries listed in Downloads.</p> <p>Install Jaeger via Docker and start the Docker container by executing the command below.</p> <pre><code>$ docker run -d -p 13133:13133 -p 16686:16686 -p 4317:4317 jaegertracing/opentelemetry-all-in-one\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/jaeger/#step-2-import-ballerina-jaeger-extension","title":"Step 2 - Import Ballerina Jaeger extension","text":"<p>To include the Jaeger extension into the executable, the <code>ballerinax/jaeger</code> module needs to be imported into your Ballerina project <code>main.bal</code> file.</p> <pre><code>import ballerinax/jaeger as _;\n</code></pre> <p>Jaeger extension has an <code>Opentelemetry GRPC Span Exporter</code> which will push tracing data as batches to the Jaeger server endpoint (default - http://localhost:4317) in opentelemetry format.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/jaeger/#step-3-configure-ballerina-runtime-configurations","title":"Step 3 - Configure Ballerina runtime configurations","text":"<p>Tracing can be enabled in your Ballerina project using configurations similar to the following in your <code>Config.toml</code> file.</p> <pre><code>[ballerina.observe]\ntracingEnabled=true\ntracingProvider=\"jaeger\"\n\n[ballerinax.jaeger]\nagentHostname=\"localhost\"\nagentPort=4317\nsamplerType=\"const\"\nsamplerParam=1.0\nreporterFlushInterval=2000\nreporterBufferSize=1000\n</code></pre> <p>The table below provides the descriptions of each configuration option and possible values that can be assigned.</p> Configuration key Description Default value Possible values ballerinax.jaeger. agentHostname Hostname of the Jaeger agent localhost IP or hostname of the Jaeger agent. If it is running on the same node as BI, it can be localhost. ballerinax.jaeger. agentPort Port of the Jaeger agent 4317 The port on which the Jaeger agent is listening. ballerinax.jaeger. samplerType Type of the sampling methods used in the Jaeger tracer. const <code>const</code>, <code>probabilistic</code>, or <code>ratelimiting</code>. ballerinax.jaeger. samplerParam It is a floating value. Based on the sampler type, the effect of the sampler param varies 1.0 For <code>const</code> <code>0</code> (no sampling) or <code>1</code> (sample all spans), for <code>probabilistic</code> <code>0.0</code> to <code>1.0</code>, for <code>ratelimiting</code> any positive integer (rate per second). ballerinax.jaeger. reporterFlushInterval The Jaeger client will be sending the spans to the agent at this interval. 2000 Any positive integer value. ballerinax.jaeger. reporterBufferSize Queue size of the Jaeger client. 1000 Any positive integer value."},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/jaeger/#step-4-run-the-bi-service","title":"Step 4 - Run the BI service","text":"<p>When observability is enabled, the BI runtime collects tracing data and traces will be published to Jaeger.</p> <p>Run the BI service and you will see an output as follows.</p> <pre><code>Compiling source\n\nRunning executable\n\nballerina: started publishing traces to Jaeger on localhost:4317\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/jaeger/#step-5-send-requests","title":"Step 5 - Send requests","text":"<p>Send requests to http://localhost:8090/shop/products.</p> <p>Example cURL commands:</p> <p><pre><code>$ curl -X GET http://localhost:8090/shop/products\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/product \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"id\": 4, \n    \"name\": \"Laptop Charger\", \n    \"price\": 50.00\n}'\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/order \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"productId\": 1, \n    \"quantity\": 1\n}'\n</code></pre> <pre><code>$ curl -X GET http://localhost:8090/shop/order/0\n</code></pre></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/jaeger/#step-6-view-distributed-tracing-on-the-jaeger-server","title":"Step 6 - View distributed tracing on the Jaeger server","text":"<p>Go to http://localhost:16686 and load the web UI of Jaeger to make sure it is functioning properly. You can select the service for which you need tracing information find traces.</p> <p>The image below is the sample tracing information you can see in Jaeger.</p> <p></p> <p></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/","title":"Observe metrics and tracing using New Relic","text":"<p>The sample shop service will be used in this guide. Follow the steps given below to observe BI tracing and metrics in New Relic.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/#step-1-create-a-new-relic-account-and-an-api-key","title":"Step 1 - Create a New Relic account and  an API key","text":"<p>Sign up and Generate an API Key in New Relic.</p> <p>To configure the API key in Newrelic:</p> <p>Go to Profile -&gt; API keys -&gt; Insights Insert key -&gt; Insert keys to create an account in New Relic.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/#step-2-import-the-new-relic-extension","title":"Step 2 - Import the New Relic extension","text":"<p>To include the New Relic extension into the executable, the <code>ballerinax/newrelic</code> module needs to be imported into your BI project. Navigate to <code>file explorer</code> and add the following to <code>main.bal</code> file.</p> <pre><code>import ballerinax/newrelic as _;\n</code></pre> <p>New Relic extension has an <code>Opentelemetry GRPC Span Exporter</code> which will push tracing data as batches to the New Relic server endpoint (https://otlp.nr-data.net:4317) in opentelemetry format.</p> <p>New Relic extension pushes metrics in New Relic metric format to the New Relic server endpoint (https://metric-api.newrelic.com/metric/v1).</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/#step-3-configure-runtime-configurations-for-observability","title":"Step 3 - Configure runtime configurations for Observability","text":"<p>Tracing and metrics can be enabled in your BI project using configurations similar to the following. Navigate to <code>file explorer</code> and add the following to <code>Config.toml</code> file.</p> <pre><code>[ballerina.observe]\ntracingEnabled=true\ntracingProvider=\"newrelic\"\nmetricsEnabled=true\nmetricsReporter=\"newrelic\"\n\n[ballerinax.newrelic]\napiKey=\"&lt;NEW_RELIC_LICENSE_KEY&gt;\"    tracingSamplerType=\"const\"          tracingSamplerParam=1               tracingReporterFlushInterval=15000  tracingReporterBufferSize=10000     metricReporterFlushInterval=15000   metricReporterClientTimeout=10000\n</code></pre> <p>The table below provides the descriptions of each configuration option and possible values that can be assigned.</p> Configuration key Description Default value Possible values ballerinax.newrelic. apiKey API key generated by the user in the New Relic platform. This configuration is mandatory. <code>None</code> ballerinax.newrelic. tracingSamplerType Type of the sampling methods used in the New Relic tracer. const <code>const</code>, <code>probabilistic</code>, or <code>ratelimiting</code>. ballerinax.newrelic. tracingSamplerParam It is a floating value. Based on the sampler type, the effect of the sampler param varies 1.0 For <code>const</code> <code>0</code> (no sampling) or <code>1</code> (sample all spans), for <code>probabilistic</code> <code>0.0</code> to <code>1.0</code>, for <code>ratelimiting</code> any positive integer (rate per second). ballerinax.newrelic. tracingReporterFlushInterval The New Relic tracing client will be sending the spans to the agent at this interval. 15000 Any positive integer value. ballerinax.newrelic. tracingReporterBufferSize Queue size of the New Relic tracing client. 10000 Any positive integer value. ballerinax.newrelic. metricReporterFlushInterval The New Relic client will be sending the metrics to the agent at this interval. 15000 Any positive integer value. ballerinax.newrelic. metricReporterClientTimeout Queue size of the New Relic metric client. 10000 Any positive integer value."},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/#step-4-run-the-bi-service","title":"Step 4 - Run the BI service","text":"<p>When observability is enabled, the BI runtime collects tracing and metrics data and both metrics and traces will be published to New Relic.</p> <p>Start the service.</p> <pre><code>Compiling source\n\nRunning executable\n\nballerina: started publishing traces to New Relic on https://otlp.nr-data.net:4317\nballerina: started publishing metrics to New Relic on https://metric-api.newrelic.com/metric/v1\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/#step-5-send-requests","title":"Step 5 - Send requests","text":"<p>Send requests to http://localhost:8090/shop/products.</p> <p>Example cURL commands:</p> <p><pre><code>$ curl -X GET http://localhost:8090/shop/products\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/product \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"id\": 4, \n    \"name\": \"Laptop Charger\", \n    \"price\": 50.00\n}'\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/order \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"productId\": 1, \n    \"quantity\": 1\n}'\n</code></pre> <pre><code>$ curl -X GET http://localhost:8090/shop/order/0\n</code></pre></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/#step-6-view-metrics-on-the-new-relic-platform","title":"Step 6 - View metrics on the New Relic platform","text":"<p>You can view the metrics that were published to the New Relic platform in the New Relic query builder. You can view the metrics query data in graphical format, as shown below.</p> <p></p> <p>You can create a dashboard from the metrics provided by BI in the New Relic platform.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/new-relic/#step-7-view-tracing-on-the-new-relic-platform","title":"Step 7 - View tracing on the New Relic platform","text":"<p>You can view the traces that were published to the New Relic platform in New Relic traces. </p> <p></p> <p></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/overview/","title":"Supported Observability Tools and Platforms","text":"<p>Observability is a measure of how well the internal states of a system can be understood from its external outputs.</p> <p>In BI, observability is a core feature that helps monitor, debug, and optimize integration services. It focuses on the following three key pillars:</p> <p>Metrics \u2013 Numeric data collected and aggregated over time to monitor system performance.</p> <p>Tracing \u2013 Tracking the flow of requests or messages through various services and components, from entry to exit.</p> <p>Logging \u2013 Text-based records of application behavior, annotated with timestamps and contextual information.</p> <p>Observability platforms allow developers and operators to gain insight into system behavior, troubleshoot issues, and ensure reliability in production deployments.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/overview/#observability-in-bi","title":"Observability in BI","text":"<p>BI provides built-in support for observability across its runtime. Integration services, APIs, and connectors emit rich telemetry data that can be exported to standard monitoring tools.</p> <p>This guide explains how to enable and configure observability in BI using a simplified integration example.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/overview/#example-observing-a-sample-integration-service","title":"Example: Observing a Sample Integration Service","text":""},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/overview/#create-a-sample-service","title":"Create a sample service","text":"<p>Let\u2019s consider an example where an integration service handles product management and ordering. The goal is to observe how it behaves under real-world usage.</p> <ol> <li>Create a new integration on BI</li> <li> <p>Define types to hold the <code>Product</code>, <code>Order</code> and <code>OrderRequest</code></p> <p>You can do this by navigating to the <code>types.bal</code> from the <code>File Explorer</code> view and copying the following content.</p> <pre><code>type Product record {|\n    int id;\n    string name;\n    float price;\n|};\n\ntype OrderRequest record {|\n    int productId;\n    int quantity;\n|};\n\ntype Order record {|\n    int orderId;\n    int productId;\n    int quantity;\n    float totalPrice;\n|};\n</code></pre> </li> <li> <p>Create an HTTP service with base path <code>/shop</code> that has the following resources.</p> <ul> <li>List available products <code>get products()</code></li> <li>Add a new product <code>post product(Product product)</code></li> <li>Place a new order <code>'order(OrderRequest orderRequest)</code></li> <li>Get order details by ID <code>'order/[int orderId]()</code></li> </ul> <p>You can add the service related logic by navigating to the <code>main.bal</code> from the <code>File Explorer</code> view and copying the following content. </p> <pre><code>import ballerina/http;\nimport ballerina/log;\n\n// Sample data\nmap&lt;Product&gt; products = {\n    \"1\": {id: 1, name: \"Laptop\", price: 1200.00},\n    \"2\": {id: 2, name: \"Smartphone\", price: 800.00},\n    \"3\": {id: 3, name: \"Headphones\", price: 150.00}\n};\n\nmap&lt;Order&gt; orders = {};\nint orderCount = 0;\n\n@display {\n    label: \"Shopping Service\"\n}\nservice /shop on new http:Listener(8090) {\n\n    // List available products.\n    resource function get products() returns Product[] {\n        log:printInfo(\"Fetching product list\");\n        return products.toArray();\n    }\n\n    // Add a new product.\n    resource function post product(Product product) returns http:Created|http:Conflict|error? {\n        log:printInfo(\"Adding a new product\");\n\n        if products.hasKey(product.id.toString()) {\n            log:printError(\"Product already exists with product ID\", id =product.id);\n            http:Conflict errorResponse = {\n                body:  string `Product already exists with product ID: ${product.id}`\n            };\n            return errorResponse;\n        }\n\n        products[product.id.toString()] = product;\n        log:printInfo(\"Product added successfully.\", product = product);\n        http:Created response = {\n            body: string `Product added successfully with product ID: ${product.id}`\n        };\n        return response;   \n    }\n\n    // Place a new order.\n    resource function post 'order(OrderRequest orderRequest) returns http:Accepted|http:NotFound|error? {\n        log:printInfo(\"Received order request\");\n\n        if !products.hasKey(orderRequest.productId.toString()) {\n            log:printError(\"Product not found with product ID\", id = orderRequest.productId);\n            http:NotFound errorResponse = {\n                body:  string `Product not found with product ID: ${orderRequest.productId.toString()}`\n            };\n            return errorResponse;\n        }\n        Product product = products.get(orderRequest.productId.toString());\n        Order newOrder = {orderId: orderCount, productId: orderRequest.productId, quantity: orderRequest.quantity, totalPrice: product.price * orderRequest.quantity};\n        orders[orderCount.toString()] = newOrder;\n        orderCount += 1;\n\n        log:printInfo(\"Order placed successfully.\", 'order = newOrder);\n        http:Accepted response = {\n            body:  newOrder\n        };\n        return response;\n    }\n\n    // Get order details by ID.\n    resource function get 'order/[int orderId]() returns http:Ok|http:NotFound|error? {\n        log:printInfo(\"Fetching order details\");\n\n        if !orders.hasKey(orderId.toString()) {\n            log:printError(\"Order not found with order ID\", id = orderId);\n            http:NotFound errorResponse = {\n                body: string `Order not found with order ID: ${orderId}`\n            };\n            return errorResponse;\n        }\n\n        Order 'order =  orders.get(orderId.toString());\n        log:printInfo(\"Order details fetched successfully\", 'order = 'order);\n        http:Ok response = {\n            body:  'order\n        };\n        return response;\n    }\n}\n</code></pre> </li> </ol> <p></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/overview/#enable-observability-for-the-project","title":"Enable Observability for the project","text":"<p>Observability can be enabled in a BI project by adding the following section to the <code>Ballerina.toml</code> file by navigating to the <code>File Explorer</code> view.</p> <pre><code>[build-options]\nobservabilityIncluded=true\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/overview/#setting-up-runtime-configurations-for-observability","title":"Setting up runtime configurations for Observability","text":"<p>To enable observability (both metrics and tracing) in the BI runtime, use the following configurations in the <code>Ballerina.toml</code> file.</p> <pre><code>[ballerina.observe]\nenabled = true\nprovider = &lt;PROVIDER&gt;\n</code></pre> <p>Metrics and tracing can be enabled separately as well by using the following configurations. Add additional configurations specific to the tool or platform you are using.</p> <pre><code>[ballerina.observe]\nmetricsEnabled=true\nmetricsReporter=&lt;METRICS_REPORTER&gt;\ntracingEnabled=true\ntracingProvider=&lt;TRACING_PROVIDER&gt;\n</code></pre> Configuration key Description Default value Possible values <code>ballerina.observe.metricsEnabled</code> Whether metrics monitoring is enabled (true) or disabled (false) false <code>true</code> or <code>false</code> <code>ballerina.observe.metricsReporter</code> Reporter name that reports the collected Metrics to the remote metrics server. This is only required to be modified if a custom reporter is implemented and needs to be used. <code>None</code> <code>prometheus</code>, <code>newrelic</code>, or if any custom implementation, the name of the reporter. <code>ballerina.observe.tracingEnabled</code> Whether tracing is enabled (true) or disabled (false) false <code>true</code> or <code>false</code> <code>ballerina.observe.tracingProvider</code> The tracer name, which implements the tracer interface. <code>None</code> <code>jaeger</code>, <code>zipkin</code>, <code>newrelic</code> or the name of the tracer of any custom implementation."},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/overview/#observability-tools-and-platforms-supported-by-bi","title":"Observability tools and platforms supported by BI","text":"<p>This outlines how to enable and configure observability in BI for various tools and platforms. It provides a step-by-step guide for setting up monitoring, tracing, and logging using widely used observability solutions.</p> <p>Observability tools and platforms help monitor and analyze application performance, identify issues, and ensure reliability. The following are the main observability tools and platforms supported by BI:</p> <ul> <li> <p>Prometheus: A monitoring system and time-series database for metrics collection and alerting.</p> </li> <li> <p>Jaeger: A distributed tracing platform for monitoring and debugging microservices.</p> </li> <li> <p>Zipkin: A distributed tracing system to collect and look up trace data.</p> </li> <li> <p>New Relic: A full-stack observability platform for application performance monitoring (APM) and telemetry.</p> </li> <li> <p>Datadog: A cloud-based observability service offering monitoring, metrics, traces, and logging.</p> </li> <li> <p>Elastic Stack: A collection of tools (Elasticsearch, Logstash, Kibana) for centralized logging and analytics.</p> </li> </ul> <p>The following sections contain guides to set up and observe BI programs in each of the observability tools or platforms mentioned above.</p> <ul> <li>Observe metrics using Prometheus</li> <li>Observe tracing using Jaeger</li> <li>Observe tracing using Zipkin</li> <li>Observe metrics and tracing using New Relic</li> <li>Observe metrics and tracing using Datadog</li> <li>Observe logs using Elastic Stack</li> </ul>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/","title":"Observe metrics using Prometheus","text":"<p>The sample shop service will be used in this guide. Follow the steps given below to observe BI metrics in Prometheus.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/#step-1-set-up-prometheus","title":"Step 1 - Set up Prometheus","text":"<p>Prometheus is used as the monitoring system, which pulls out the metrics collected from the <code>/metrics</code> service exposed by BI runtime. This section focuses on the quick installation of Prometheus with Docker and the configuration required to collect metrics from the metrics service with the default configurations. Follow the steps below to configure Prometheus. </p> Tip<p>There are many other ways to install Prometheus and you can find possible options from the installation guide. The easiest option is to use precompiled binaries listed in Downloads.</p> <ol> <li> <p>Create a <code>prometheus.yml</code> file in a directory.</p> </li> <li> <p>Add the following content to the <code>prometheus.yml</code> file.</p> <pre><code>global:\nscrape_interval:     15s\nevaluation_interval: 15s\n\nscrape_configs:\n- job_name: 'prometheus'\nstatic_configs:\n- targets: ['a.b.c.d:9797']\n</code></pre> <p>Here, the <code>'a.b.c.d:9797'</code> targets should contain the host and port of the <code>/metrics</code> service that is exposed from  BI runtime for metrics collection. Add the IP of the host in which the BI service is running as <code>a.b.c.d</code> and its port (default <code>9797</code>). If you need more information, go to the Prometheus documentation. If your BI metrics service is running on localhost and Prometheus in a Docker container, add the target as <code>host.docker.internal:9797</code> to access the localhost from Docker.</p> </li> <li> <p>Start the Prometheus server in a Docker container with the command below.</p> <pre><code>$ docker run -p 9090:9090 -v &lt;path_to_prometheus.yml&gt;:/etc/prometheus/ prom/prometheus\n</code></pre> </li> </ol>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/#step-2-import-prometheus-extension-for-bi","title":"Step 2 - Import Prometheus extension for BI","text":"<p>To include the Prometheus extension into the executable, the <code>ballerinax/prometheus</code> module needs to be imported into your BI project. Navigate to <code>file explorer</code> and add the following to the <code>main.bal</code> file.</p> <pre><code>import ballerinax/prometheus as _;\n</code></pre> <p>To support Prometheus as the metrics reporter, an HTTP endpoint starts with the context of <code>/metrics</code> in the default port <code>9797</code> when starting the service in BI.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/#step-3-configure-runtime-configurations-for-observability","title":"Step 3 - Configure runtime configurations for observability","text":"<p>You can set up Prometheus for your BI project using configurations similar to the following in the <code>Config.toml</code> file. Navigate to <code>file explorer</code> and add the following to the <code>Config.toml</code> file.</p> <pre><code>[ballerina.observe]\nmetricsEnabled=true\nmetricsReporter=\"prometheus\"\n\n[ballerinax.prometheus]\nport=9797\nhost=\"0.0.0.0\"\n</code></pre> Configuration key Description Default value Possible values <code>ballerinax.prometheus.port</code> The value of the port to which the '/metrics' service will bind. This service will be used by Prometheus to scrape the information of the BI service. <code>9797</code> Any suitable value for port 0 - 0 - 65535. However, within that range, ports <code>0</code> - <code>1023</code> are generally reserved for specific purposes. Therefore, it is advisable to select a port outside that range. <code>ballerinax.prometheus.host</code> The name of the host to which the '/metrics' service will bind. This service will be used by Prometheus to scrape the information of the BI service. <code>0.0.0.0</code> IP or Hostname or <code>0.0.0.0</code> of the node in which the BI service is running."},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/#step-4-run-the-bi-service","title":"Step 4 - Run the BI service","text":"<p>When observability is enabled, the BI runtime exposes internal metrics via an HTTP endpoint (<code>/metrics</code>) for metrics monitoring, and the metrics will be published to Prometheus. Prometheus should be configured to scrape metrics from the metrics HTTP endpoint in BI.</p> <p>Start the BI service and you'll notice an output similar to the following.</p> <pre><code>Compiling source\n\nRunning executable\n\nballerina: started Prometheus HTTP listener 0.0.0.0:9797\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/#step-5-send-requests","title":"Step 5 - Send requests","text":"<p>Send requests to <code>http://localhost:8090/shop/products</code>.</p> <p>Example cURL commands:</p> <p><pre><code>$ curl -X GET http://localhost:8090/shop/products\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/product \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"id\": 4, \n    \"name\": \"Laptop Charger\", \n    \"price\": 50.00\n}'\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/order \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"productId\": 1, \n    \"quantity\": 1\n}'\n</code></pre> <pre><code>$ curl -X GET http://localhost:8090/shop/order/0\n</code></pre></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/#step-6-view-metrics-on-the-prometheus-server","title":"Step 6 - View metrics on the Prometheus server","text":"<p>Go to http://localhost:19090/ and check whether you can see the Prometheus graph. BI metrics should appear in the Prometheus graph's metrics list when the BI service is started.</p> <p></p> <p></p> <p>You can also use the following command to get the metrics.</p> <pre><code>$ curl http://localhost:9797/metrics\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/prometheus/#set-up-grafana","title":"Set up Grafana","text":"<p>Grafana can be used to visualize BI metrics provided for Prometheus. First, users need to set up the BI project to observe metrics in Prometheus and follow the steps mentioned above.</p> <p>Let\u2019s use Grafana to visualize metrics in a dashboard. For this, we need to install Grafana and configure Prometheus as a data source. Follow the steps below to configure Grafana.</p> <ol> <li> <p>Start Grafana as a Docker container with the command below.</p> <p><pre><code>$ docker run -d --name=grafana -p 3000:3000 grafana/grafana\n</code></pre> For more information, go to Grafana in Docker Hub.</p> </li> <li> <p>Go to http://localhost:3000/ to access the Grafana dashboard running on Docker.</p> </li> <li> <p>Login to the dashboard with the default user, username: <code>admin</code> and password: <code>admin</code></p> </li> <li> <p>Add Prometheus as a data source with the <code>Browser</code> access configuration as provided below.</p> </li> </ol> <p></p> <ol> <li>Import the Grafana dashboard designed to visualize BI metrics from https://grafana.com/dashboards/5841 as shown below.</li> </ol> <p></p> <p>This dashboard consists of service and client invocation level metrics in near real-time view. </p> <p>The BI HTTP service metrics dashboard panel will be as shown below.</p> <p></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/zipkin/","title":"Observe tracing using Zipkin","text":"<p>The sample shop service will be used in this guide. Follow the steps given below to observe BI tracing in Zipkin.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/zipkin/#step-1-set-up-zipkin","title":"Step 1 - Set up Zipkin","text":"<p>You can configure BI to support distributed tracing with Zipkin. This section focuses on configuring Zipkin with Docker as a quick installation.</p> Tip<p>There are many possible ways to deploy Zipkin. For more information, see Zipkin Quickstart.</p> <p>Install Zipkin via Docker and start the Docker container by executing the command below.</p> <pre><code>$ docker run -d -p 9411:9411 openzipkin/zipkin\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/zipkin/#step-2-import-ballerina-zipkin-extension","title":"Step 2 - Import Ballerina Zipkin extension","text":"<p>To include the Zipkin extension into the executable, the <code>ballerinax/zipkin</code> module needs to be imported into your BI project by navigating to <code>file explorer</code> and adding the following to <code>main.bal</code> file.</p> <pre><code>import ballerinax/zipkin as _;\n</code></pre> <p>Zipkin extension has a <code>Zipkin Span Exporter</code> which will push tracing data as batches to the Zipkin server endpoint (default - http://localhost:9411) in Zipkin format.</p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/zipkin/#step-3-configure-runtime-configurations-for-observability","title":"Step 3 - Configure runtime configurations for observability","text":"<p>Tracing can be enabled in your BI project using configurations similar to the following in your <code>Config.toml</code> file.</p> <pre><code>[ballerina.observe]\ntracingEnabled=true\ntracingProvider=\"zipkin\"\n\n[ballerinax.zipkin]\nagentHostname=\"localhost\"\nagentPort=9411\nsamplerType=\"const\"\nsamplerParam=1.0\nreporterFlushInterval=1000\nreporterBufferSize=10000\n</code></pre> <p>The table below provides the descriptions of each configuration option and possible values that can be assigned.</p> Configuration key Description Default value Possible values ballerinax.zipkin. agentHostname Hostname of the Zipkin agent localhost IP or hostname of the Zipkin agent. If it is running on the same node as Ballerina, it can be localhost. ballerinax.zipkin. agentPort Port of the Zipkin agent 4317 The port on which the Zipkin agent is listening. ballerinax.zipkin. samplerType Type of the sampling methods used in the Zipkin tracer. const <code>const</code>, <code>probabilistic</code>, or <code>ratelimiting</code>. ballerinax.zipkin. samplerParam It is a floating value. Based on the sampler type, the effect of the sampler param varies 1.0 For <code>const</code> <code>0</code> (no sampling) or <code>1</code> (sample all spans), for <code>probabilistic</code> <code>0.0</code> to <code>1.0</code>, for <code>ratelimiting</code> any positive integer (rate per second). ballerinax.zipkin. reporterFlushInterval The Zipkin client will be sending the spans to the agent at this interval. 2000 Any positive integer value. ballerinax.zipkin. reporterBufferSize Queue size of the Zipkin client. 2000 Any positive integer value."},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/zipkin/#step-4-run-the-bi-service","title":"Step 4 - Run the BI service","text":"<p>When BI observability is enabled, the BI runtime collects tracing data and traces will be published to Zipkin.</p> <p>Run the the BI service. </p> <pre><code>Compiling source\n\nRunning executable\n\nballerina: started publishing traces to Zipkin on http://localhost:9411\n</code></pre>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/zipkin/#step-5-send-requests","title":"Step 5 - Send requests","text":"<p>Send requests to http://localhost:8090/shop/products.</p> <p>Example cURL commands:</p> <p><pre><code>$ curl -X GET http://localhost:8090/shop/products\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/product \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"id\": 4, \n    \"name\": \"Laptop Charger\", \n    \"price\": 50.00\n}'\n</code></pre> <pre><code>$ curl -X POST http://localhost:8090/shop/order \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"productId\": 1, \n    \"quantity\": 1\n}'\n</code></pre> <pre><code>$ curl -X GET http://localhost:8090/shop/order/0\n</code></pre></p>"},{"location":"observability-and-monitoring/supported-observability-tools-and-platforms/zipkin/#step-6-view-distributed-tracing-on-the-zipkin-server","title":"Step 6 - View distributed tracing on the Zipkin server","text":"<p>Go to http://localhost:9411 and load the web UI of Zipkin to make sure it is functioning properly. You can select the service for which you need tracing information find traces.</p> <p>The image below is the sample tracing information you can see in Zipkin.</p> <p></p>"},{"location":"references/enterprise-integrations-patterns/","title":"Enterprise Integrations Patterns","text":"<p>The WSO2 Integrator: BI supports the implementation of key Enterprise Integration Patterns (EIPs), enabling you to build robust and scalable integrations based on proven architectural best practices. These patterns\u2014originally defined in Enterprise Integration Patterns by Gregor Hohpe and Bobby Woolf\u2014provide reusable solutions for common messaging and system integration challenges. This guide demonstrates how to implement each core pattern using the low-code capabilities and visual tools of the WSO2 Integrator: BI, helping you design clear, maintainable, and standards-based integration flows.</p> Enterprise Integration Patterns with Ballerina<p>For a code-centric implementation of Enterprise Integration Patterns using the Ballerina language, refer to the Ballerina EIP guide.</p>"},{"location":"references/enterprise-integrations-patterns/#messaging-systems","title":"Messaging systems","text":"Message How can two applications connected by a message channel exchange a piece of information Message Endpoint How an application connects to a messaging channel to send and receive messages Message Translator How systems using different data formats communicate with each other using messaging Message Router How to decouple individual processing steps so that messages can be passed to different filters depending on a set of conditions Pipes and Filters How to perform complex processing on a message while maintaining independence and flexibility"},{"location":"references/enterprise-integrations-patterns/#messaging-channels","title":"Messaging channels","text":"Channel Adapter How can two applications connected by a message channel exchange a piece of information Messaging Bridge How an application connects to a messaging channel to send and receive messages Point to Point Channel How systems using different data formats communicate with each other using messaging"},{"location":"references/enterprise-integrations-patterns/#message-construction","title":"Message construction","text":"Command Message How messaging can be used to invoke a procedure in another application Document Message How messaging can be used to transfer data between applications. Event Message How messaging can be used to transmit events from one application to another Format Indicator How a message\u2019s data format can be designed to allow for possible future changes Message Sequence How messaging can transmit an arbitrarily large amount of data"},{"location":"references/enterprise-integrations-patterns/#message-routing","title":"Message routing","text":"Content-Based Router How to handle a situation where the implementation of a single logical function is spread across multiple physical systems Aggregator How to combine the results of individual, but related messages so that they can be processed as a whole Message Filter How a component avoids receiving uninteresting messages Process Manager How to route a message through multiple processing steps, when the required steps may not be known at design time and may not be sequential Routing Slip How to route a message consecutively through a series of steps when the sequence of the steps is not known at design time and may vary for each message Splitter How to process a message if it contains multiple elements, each of which may have to be processed in a different way"},{"location":"references/enterprise-integrations-patterns/#message-transformation","title":"Message transformation","text":"Content Enricher How to communicate with another system if the message originator does not have all the required data items available Content Filter How to simplify dealing with a large message when you are interested only in a few data items Normalizer How to process messages that are semantically equivalent but arrive in a different format"},{"location":"references/enterprise-integrations-patterns/#messaging-endpoints","title":"Messaging Endpoints","text":"Idempotent Receiver How can a message receiver deal with duplicate messages"},{"location":"references/enterprise-integrations-patterns/#system-management","title":"System Management","text":"Message Store How to report against message information without disturbing the loosely coupled and transient nature of a messaging system"}]}